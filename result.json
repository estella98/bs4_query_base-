{"read_pickle": ["Load pickled pandas object (or any object) from file."], "pandas.read_pickle": ["Load pickled pandas object (or any object) from file."], "to_pickle": ["Pickle (serialize) object to file."], "DataFrame.to_pickle": ["Pickle (serialize) object to file."], "pandas.DataFrame.to_pickle": ["Pickle (serialize) object to file."], "read_table": ["Read general delimited file into DataFrame."], "pandas.read_table": ["Read general delimited file into DataFrame."], "read_csv": ["Read a comma-separated values (csv) file into DataFrame."], "pandas.read_csv": ["Read a comma-separated values (csv) file into DataFrame."], "to_csv": ["Write object to a comma-separated values (csv) file."], "DataFrame.to_csv": ["Write object to a comma-separated values (csv) file."], "pandas.DataFrame.to_csv": ["Write object to a comma-separated values (csv) file."], "read_fwf": ["Read a table of fixed-width formatted lines into DataFrame."], "pandas.read_fwf": ["Read a table of fixed-width formatted lines into DataFrame."], "read_clipboard": ["Read text from clipboard and pass to read_csv."], "pandas.read_clipboard": ["Read text from clipboard and pass to read_csv."], "to_clipboard": ["Copy object to the system clipboard."], "DataFrame.to_clipboard": ["Copy object to the system clipboard."], "pandas.DataFrame.to_clipboard": ["Copy object to the system clipboard."], "read_excel": ["Read an Excel file into a pandas DataFrame."], "pandas.read_excel": ["Read an Excel file into a pandas DataFrame."], "to_excel": ["Write object to an Excel sheet.", "Write Styler to an Excel sheet."], "DataFrame.to_excel": ["Write object to an Excel sheet."], "pandas.DataFrame.to_excel": ["Write object to an Excel sheet."], "parse": ["Parse specified sheet(s) into a DataFrame."], "ExcelFile.parse": ["Parse specified sheet(s) into a DataFrame."], "pandas.ExcelFile.parse": ["Parse specified sheet(s) into a DataFrame."], "Styler.to_excel": ["Write Styler to an Excel sheet."], "style.Styler.to_excel": ["Write Styler to an Excel sheet."], "formats.style.Styler.to_excel": ["Write Styler to an Excel sheet."], "io.formats.style.Styler.to_excel": ["Write Styler to an Excel sheet."], "pandas.io.formats.style.Styler.to_excel": ["Write Styler to an Excel sheet."], "ExcelWriter": ["Class for writing DataFrame objects into excel sheets."], "pandas.ExcelWriter": ["Class for writing DataFrame objects into excel sheets."], "read_json": ["Convert a JSON string to pandas object."], "pandas.read_json": ["Convert a JSON string to pandas object."], "json_normalize": ["Normalize semi-structured JSON data into a flat table."], "pandas.json_normalize": ["Normalize semi-structured JSON data into a flat table."], "to_json": ["Convert the object to a JSON string."], "DataFrame.to_json": ["Convert the object to a JSON string."], "pandas.DataFrame.to_json": ["Convert the object to a JSON string."], "build_table_schema": ["Create a Table schema from <code class=\"docutils literal notranslate\"><span class=\"pre\">data</span></code>."], "json.build_table_schema": ["Create a Table schema from <code class=\"docutils literal notranslate\"><span class=\"pre\">data</span></code>."], "io.json.build_table_schema": ["Create a Table schema from <code class=\"docutils literal notranslate\"><span class=\"pre\">data</span></code>."], "pandas.io.json.build_table_schema": ["Create a Table schema from <code class=\"docutils literal notranslate\"><span class=\"pre\">data</span></code>."], "read_html": ["Read HTML tables into a <code class=\"docutils literal notranslate\"><span class=\"pre\">list</span></code> of <code class=\"docutils literal notranslate\"><span class=\"pre\">DataFrame</span></code> objects."], "pandas.read_html": ["Read HTML tables into a <code class=\"docutils literal notranslate\"><span class=\"pre\">list</span></code> of <code class=\"docutils literal notranslate\"><span class=\"pre\">DataFrame</span></code> objects."], "to_html": ["Render a DataFrame as an HTML table.", "Write Styler to a file, buffer or string in HTML-CSS format."], "DataFrame.to_html": ["Render a DataFrame as an HTML table."], "pandas.DataFrame.to_html": ["Render a DataFrame as an HTML table."], "Styler.to_html": ["Write Styler to a file, buffer or string in HTML-CSS format."], "style.Styler.to_html": ["Write Styler to a file, buffer or string in HTML-CSS format."], "formats.style.Styler.to_html": ["Write Styler to a file, buffer or string in HTML-CSS format."], "io.formats.style.Styler.to_html": ["Write Styler to a file, buffer or string in HTML-CSS format."], "pandas.io.formats.style.Styler.to_html": ["Write Styler to a file, buffer or string in HTML-CSS format."], "read_xml": ["Read XML document into a <code class=\"docutils literal notranslate\"><span class=\"pre\">DataFrame</span></code> object."], "pandas.read_xml": ["Read XML document into a <code class=\"docutils literal notranslate\"><span class=\"pre\">DataFrame</span></code> object."], "to_xml": ["Render a DataFrame to an XML document."], "DataFrame.to_xml": ["Render a DataFrame to an XML document."], "pandas.DataFrame.to_xml": ["Render a DataFrame to an XML document."], "to_latex": ["Render object to a LaTeX tabular, longtable, or nested table.", "Write Styler to a file, buffer or string in LaTeX format."], "DataFrame.to_latex": ["Render object to a LaTeX tabular, longtable, or nested table."], "pandas.DataFrame.to_latex": ["Render object to a LaTeX tabular, longtable, or nested table."], "Styler.to_latex": ["Write Styler to a file, buffer or string in LaTeX format."], "style.Styler.to_latex": ["Write Styler to a file, buffer or string in LaTeX format."], "formats.style.Styler.to_latex": ["Write Styler to a file, buffer or string in LaTeX format."], "io.formats.style.Styler.to_latex": ["Write Styler to a file, buffer or string in LaTeX format."], "pandas.io.formats.style.Styler.to_latex": ["Write Styler to a file, buffer or string in LaTeX format."], "read_hdf": ["Read from the store, close it if we opened it."], "pandas.read_hdf": ["Read from the store, close it if we opened it."], "put": ["Store object in HDFStore.", "Set <code class=\"docutils literal notranslate\"><span class=\"pre\">a.flat[n]</span> <span class=\"pre\">=</span> <span class=\"pre\">values[n]</span></code> for all <em class=\"xref py py-obj\">n</em> in indices."], "HDFStore.put": ["Store object in HDFStore."], "pandas.HDFStore.put": ["Store object in HDFStore."], "append": ["Append to Table in file.", "(DEPRECATED) Concatenate two or more Series.", "(DEPRECATED) Append rows of <cite>other</cite> to the end of caller, returning a new object.", "Append a collection of Index options together.", "Append values to the end of an array."], "HDFStore.append": ["Append to Table in file."], "pandas.HDFStore.append": ["Append to Table in file."], "get": ["Retrieve pandas object stored in file.", "Get item from object for given key (ex: DataFrame column).", "Extract element from each component at specified position."], "HDFStore.get": ["Retrieve pandas object stored in file."], "pandas.HDFStore.get": ["Retrieve pandas object stored in file."], "select": ["Retrieve pandas object stored in file, optionally based on where criteria."], "HDFStore.select": ["Retrieve pandas object stored in file, optionally based on where criteria."], "pandas.HDFStore.select": ["Retrieve pandas object stored in file, optionally based on where criteria."], "info": ["Print detailed information on the store.", "Print a concise summary of a DataFrame."], "HDFStore.info": ["Print detailed information on the store."], "pandas.HDFStore.info": ["Print detailed information on the store."], "keys": ["Return a list of keys corresponding to objects stored in HDFStore.", "Return alias for index.", "Get the 'info axis' (see Indexing for more)."], "HDFStore.keys": ["Return a list of keys corresponding to objects stored in HDFStore."], "pandas.HDFStore.keys": ["Return a list of keys corresponding to objects stored in HDFStore."], "groups": ["Return a list of all the top-level nodes.", "Dict {group name -&gt; group labels}."], "HDFStore.groups": ["Return a list of all the top-level nodes."], "pandas.HDFStore.groups": ["Return a list of all the top-level nodes."], "walk": ["Walk the pytables group hierarchy for pandas objects."], "HDFStore.walk": ["Walk the pytables group hierarchy for pandas objects."], "pandas.HDFStore.walk": ["Walk the pytables group hierarchy for pandas objects."], "read_feather": ["Load a feather-format object from the file path."], "pandas.read_feather": ["Load a feather-format object from the file path."], "to_feather": ["Write a DataFrame to the binary Feather format."], "DataFrame.to_feather": ["Write a DataFrame to the binary Feather format."], "pandas.DataFrame.to_feather": ["Write a DataFrame to the binary Feather format."], "read_parquet": ["Load a parquet object from the file path, returning a DataFrame."], "pandas.read_parquet": ["Load a parquet object from the file path, returning a DataFrame."], "to_parquet": ["Write a DataFrame to the binary parquet format."], "DataFrame.to_parquet": ["Write a DataFrame to the binary parquet format."], "pandas.DataFrame.to_parquet": ["Write a DataFrame to the binary parquet format."], "read_orc": ["Load an ORC object from the file path, returning a DataFrame."], "pandas.read_orc": ["Load an ORC object from the file path, returning a DataFrame."], "read_sas": ["Read SAS files stored as either XPORT or SAS7BDAT format files."], "pandas.read_sas": ["Read SAS files stored as either XPORT or SAS7BDAT format files."], "read_spss": ["Load an SPSS file from the file path, returning a DataFrame."], "pandas.read_spss": ["Load an SPSS file from the file path, returning a DataFrame."], "read_sql_table": ["Read SQL database table into a DataFrame."], "pandas.read_sql_table": ["Read SQL database table into a DataFrame."], "read_sql_query": ["Read SQL query into a DataFrame."], "pandas.read_sql_query": ["Read SQL query into a DataFrame."], "read_sql": ["Read SQL query or database table into a DataFrame."], "pandas.read_sql": ["Read SQL query or database table into a DataFrame."], "to_sql": ["Write records stored in a DataFrame to a SQL database."], "DataFrame.to_sql": ["Write records stored in a DataFrame to a SQL database."], "pandas.DataFrame.to_sql": ["Write records stored in a DataFrame to a SQL database."], "read_gbq": ["Load data from Google BigQuery."], "pandas.read_gbq": ["Load data from Google BigQuery."], "read_stata": ["Read Stata file into DataFrame."], "pandas.read_stata": ["Read Stata file into DataFrame."], "to_stata": ["Export DataFrame object to Stata dta format."], "DataFrame.to_stata": ["Export DataFrame object to Stata dta format."], "pandas.DataFrame.to_stata": ["Export DataFrame object to Stata dta format."], "data_label": ["Return data label of Stata file."], "StataReader.data_label": ["Return data label of Stata file."], "stata.StataReader.data_label": ["Return data label of Stata file."], "io.stata.StataReader.data_label": ["Return data label of Stata file."], "pandas.io.stata.StataReader.data_label": ["Return data label of Stata file."], "value_labels": ["Return a dict, associating each variable name a dict, associating each value its corresponding label."], "StataReader.value_labels": ["Return a dict, associating each variable name a dict, associating each value its corresponding label."], "stata.StataReader.value_labels": ["Return a dict, associating each variable name a dict, associating each value its corresponding label."], "io.stata.StataReader.value_labels": ["Return a dict, associating each variable name a dict, associating each value its corresponding label."], "pandas.io.stata.StataReader.value_labels": ["Return a dict, associating each variable name a dict, associating each value its corresponding label."], "variable_labels": ["Return variable labels as a dict, associating each variable name with corresponding label."], "StataReader.variable_labels": ["Return variable labels as a dict, associating each variable name with corresponding label."], "stata.StataReader.variable_labels": ["Return variable labels as a dict, associating each variable name with corresponding label."], "io.stata.StataReader.variable_labels": ["Return variable labels as a dict, associating each variable name with corresponding label."], "pandas.io.stata.StataReader.variable_labels": ["Return variable labels as a dict, associating each variable name with corresponding label."], "write_file": ["Export DataFrame object to Stata dta format."], "StataWriter.write_file": ["Export DataFrame object to Stata dta format."], "stata.StataWriter.write_file": ["Export DataFrame object to Stata dta format."], "io.stata.StataWriter.write_file": ["Export DataFrame object to Stata dta format."], "pandas.io.stata.StataWriter.write_file": ["Export DataFrame object to Stata dta format."], "melt": ["Unpivot a DataFrame from wide to long format, optionally leaving identifiers set."], "pandas.melt": ["Unpivot a DataFrame from wide to long format, optionally leaving identifiers set."], "pivot": ["Return reshaped DataFrame organized by given index / column values."], "pandas.pivot": ["Return reshaped DataFrame organized by given index / column values."], "pivot_table": ["Create a spreadsheet-style pivot table as a DataFrame."], "pandas.pivot_table": ["Create a spreadsheet-style pivot table as a DataFrame."], "crosstab": ["Compute a simple cross tabulation of two (or more) factors."], "pandas.crosstab": ["Compute a simple cross tabulation of two (or more) factors."], "cut": ["Bin values into discrete intervals."], "pandas.cut": ["Bin values into discrete intervals."], "qcut": ["Quantile-based discretization function."], "pandas.qcut": ["Quantile-based discretization function."], "merge": ["Merge DataFrame or named Series objects with a database-style join."], "pandas.merge": ["Merge DataFrame or named Series objects with a database-style join."], "merge_ordered": ["Perform a merge for ordered data with optional filling/interpolation."], "pandas.merge_ordered": ["Perform a merge for ordered data with optional filling/interpolation."], "merge_asof": ["Perform a merge by key distance."], "pandas.merge_asof": ["Perform a merge by key distance."], "concat": ["Concatenate pandas objects along a particular axis with optional set logic along the other axes."], "pandas.concat": ["Concatenate pandas objects along a particular axis with optional set logic along the other axes."], "get_dummies": ["Convert categorical variable into dummy/indicator variables.", "Return DataFrame of dummy/indicator variables for Series."], "pandas.get_dummies": ["Convert categorical variable into dummy/indicator variables."], "factorize": ["Encode the object as an enumerated type or categorical variable."], "pandas.factorize": ["Encode the object as an enumerated type or categorical variable."], "unique": ["Return unique values based on a hash table.", "Return unique values of Series object.", "Return unique values in the index.", "Find the unique elements of an array."], "pandas.unique": ["Return unique values based on a hash table."], "wide_to_long": ["Unpivot a DataFrame from wide to long format."], "pandas.wide_to_long": ["Unpivot a DataFrame from wide to long format."], "isna": ["Detect missing values for an array-like object.", "Detect missing values."], "pandas.isna": ["Detect missing values for an array-like object."], "isnull": ["Detect missing values for an array-like object.", "Series.isnull is an alias for Series.isna.", "DataFrame.isnull is an alias for DataFrame.isna."], "pandas.isnull": ["Detect missing values for an array-like object."], "notna": ["Detect non-missing values for an array-like object.", "Detect existing (non-missing) values."], "pandas.notna": ["Detect non-missing values for an array-like object."], "notnull": ["Detect non-missing values for an array-like object.", "Series.notnull is an alias for Series.notna.", "DataFrame.notnull is an alias for DataFrame.notna."], "pandas.notnull": ["Detect non-missing values for an array-like object."], "to_numeric": ["Convert argument to a numeric type."], "pandas.to_numeric": ["Convert argument to a numeric type."], "to_datetime": ["Convert argument to datetime."], "pandas.to_datetime": ["Convert argument to datetime."], "to_timedelta": ["Convert argument to timedelta."], "pandas.to_timedelta": ["Convert argument to timedelta."], "date_range": ["Return a fixed frequency DatetimeIndex."], "pandas.date_range": ["Return a fixed frequency DatetimeIndex."], "bdate_range": ["Return a fixed frequency DatetimeIndex, with business day as the default frequency."], "pandas.bdate_range": ["Return a fixed frequency DatetimeIndex, with business day as the default frequency."], "period_range": ["Return a fixed frequency PeriodIndex."], "pandas.period_range": ["Return a fixed frequency PeriodIndex."], "timedelta_range": ["Return a fixed frequency TimedeltaIndex, with day as the default frequency."], "pandas.timedelta_range": ["Return a fixed frequency TimedeltaIndex, with day as the default frequency."], "infer_freq": ["Infer the most likely frequency given the input index."], "pandas.infer_freq": ["Infer the most likely frequency given the input index."], "interval_range": ["Return a fixed frequency IntervalIndex."], "pandas.interval_range": ["Return a fixed frequency IntervalIndex."], "eval": ["Evaluate a Python expression as a string using various backends.", "Evaluate a string describing operations on DataFrame columns."], "pandas.eval": ["Evaluate a Python expression as a string using various backends."], "hash_array": ["Given a 1d array, return an array of deterministic integers."], "util.hash_array": ["Given a 1d array, return an array of deterministic integers."], "pandas.util.hash_array": ["Given a 1d array, return an array of deterministic integers."], "hash_pandas_object": ["Return a data hash of the Index/Series/DataFrame."], "util.hash_pandas_object": ["Return a data hash of the Index/Series/DataFrame."], "pandas.util.hash_pandas_object": ["Return a data hash of the Index/Series/DataFrame."], "test": ["Run the pandas test suite using pytest."], "pandas.test": ["Run the pandas test suite using pytest."], "Series": ["One-dimensional ndarray with axis labels (including time series)."], "pandas.Series": ["One-dimensional ndarray with axis labels (including time series)."], "index": ["The index (axis labels) of the Series.", "Return lowest indexes in each string in Series/Index.", "The index (row labels) of the DataFrame.", "Like <a class=\"reference internal\" href=\"numpy.char.find.html#numpy.char.find\" title=\"numpy.char.find\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">find</span></code></a>, but raises <em class=\"xref py py-obj\">ValueError</em> when the substring is not found."], "Series.index": ["The index (axis labels) of the Series."], "pandas.Series.index": ["The index (axis labels) of the Series."], "array": ["The ExtensionArray of the data backing this Series or Index.", "Create an array.", "Construct a record array from a wide-variety of objects.", "Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "Series.array": ["The ExtensionArray of the data backing this Series or Index."], "pandas.Series.array": ["The ExtensionArray of the data backing this Series or Index."], "values": ["Return Series as ndarray or ndarray-like depending on the dtype.", "Return a Numpy representation of the DataFrame.", "Return an array representing the data in the Index."], "Series.values": ["Return Series as ndarray or ndarray-like depending on the dtype."], "pandas.Series.values": ["Return Series as ndarray or ndarray-like depending on the dtype."], "dtype": ["Return the dtype object of the underlying data.", "The <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">CategoricalDtype</span></code> for this instance.", "Data-type of the array\u2019s elements.", "Get array data-descriptor.", "Create a data type object."], "Series.dtype": ["Return the dtype object of the underlying data."], "pandas.Series.dtype": ["Return the dtype object of the underlying data."], "shape": ["Return a tuple of the shape of the underlying data.", "Return a tuple representing the dimensionality of the DataFrame.", "Tuple of array dimensions."], "Series.shape": ["Return a tuple of the shape of the underlying data."], "pandas.Series.shape": ["Return a tuple of the shape of the underlying data."], "nbytes": ["Return the number of bytes in the underlying data.", "Total bytes consumed by the elements of the array."], "Series.nbytes": ["Return the number of bytes in the underlying data."], "pandas.Series.nbytes": ["Return the number of bytes in the underlying data."], "ndim": ["Number of dimensions of the underlying data, by definition 1.", "Return an int representing the number of axes / array dimensions.", "Number of array dimensions.", "The number of array dimensions."], "Series.ndim": ["Number of dimensions of the underlying data, by definition 1."], "pandas.Series.ndim": ["Number of dimensions of the underlying data, by definition 1."], "size": ["Return the number of elements in the underlying data.", "Return an int representing the number of elements in this object.", "Compute group sizes.", "Number of elements in the array.", "The number of elements in the gentype."], "Series.size": ["Return the number of elements in the underlying data."], "pandas.Series.size": ["Return the number of elements in the underlying data."], "T": ["Return the transpose, which is by definition self.", "", "attribute", "Scalar attribute identical to the corresponding array attribute."], "Series.T": ["Return the transpose, which is by definition self."], "pandas.Series.T": ["Return the transpose, which is by definition self."], "memory_usage": ["Return the memory usage of the Series.", "Return the memory usage of each column in bytes.", "Memory usage of the values."], "Series.memory_usage": ["Return the memory usage of the Series."], "pandas.Series.memory_usage": ["Return the memory usage of the Series."], "hasnans": ["Return True if there are any NaNs."], "Series.hasnans": ["Return True if there are any NaNs."], "pandas.Series.hasnans": ["Return True if there are any NaNs."], "empty": ["Indicator whether Series/DataFrame is empty.", ""], "Series.empty": ["Indicator whether Series/DataFrame is empty."], "pandas.Series.empty": ["Indicator whether Series/DataFrame is empty."], "dtypes": ["Return the dtype object of the underlying data.", "Return the dtypes in the DataFrame.", "Return the dtypes as a Series for the underlying MultiIndex."], "Series.dtypes": ["Return the dtype object of the underlying data."], "pandas.Series.dtypes": ["Return the dtype object of the underlying data."], "name": ["Return the name of the Series.", "Return Index or MultiIndex name.", "", "A bit-width name for this data-type."], "Series.name": ["Return the name of the Series."], "pandas.Series.name": ["Return the name of the Series."], "flags": ["Get the properties associated with this pandas object.", "Information about the memory layout of the array.", "Bit-flags describing how this data type is to be interpreted."], "Series.flags": ["Get the properties associated with this pandas object."], "pandas.Series.flags": ["Get the properties associated with this pandas object."], "set_flags": ["Return a new object with updated flags."], "Series.set_flags": ["Return a new object with updated flags."], "pandas.Series.set_flags": ["Return a new object with updated flags."], "astype": ["Cast a pandas object to a specified dtype <code class=\"docutils literal notranslate\"><span class=\"pre\">dtype</span></code>.", "Create an Index with values cast to dtypes.", "Copy of the array, cast to a specified type."], "Series.astype": ["Cast a pandas object to a specified dtype <code class=\"docutils literal notranslate\"><span class=\"pre\">dtype</span></code>."], "pandas.Series.astype": ["Cast a pandas object to a specified dtype <code class=\"docutils literal notranslate\"><span class=\"pre\">dtype</span></code>."], "convert_dtypes": ["Convert columns to best possible dtypes using dtypes supporting <code class=\"docutils literal notranslate\"><span class=\"pre\">pd.NA</span></code>."], "Series.convert_dtypes": ["Convert columns to best possible dtypes using dtypes supporting <code class=\"docutils literal notranslate\"><span class=\"pre\">pd.NA</span></code>."], "pandas.Series.convert_dtypes": ["Convert columns to best possible dtypes using dtypes supporting <code class=\"docutils literal notranslate\"><span class=\"pre\">pd.NA</span></code>."], "infer_objects": ["Attempt to infer better dtypes for object columns."], "Series.infer_objects": ["Attempt to infer better dtypes for object columns."], "pandas.Series.infer_objects": ["Attempt to infer better dtypes for object columns."], "copy": ["Make a copy of this object's indices and data.", "Make a copy of this object.", "", "Return a copy of the array.", "Return an array copy of the given object."], "Series.copy": ["Make a copy of this object's indices and data."], "pandas.Series.copy": ["Make a copy of this object's indices and data."], "bool": ["Return the bool of a single element Series or DataFrame."], "Series.bool": ["Return the bool of a single element Series or DataFrame."], "pandas.Series.bool": ["Return the bool of a single element Series or DataFrame."], "to_numpy": ["A NumPy ndarray representing the values in this Series or Index.", "Convert the Timestamp to a NumPy datetime64.", "Convert the Timedelta to a NumPy timedelta64."], "Series.to_numpy": ["A NumPy ndarray representing the values in this Series or Index."], "pandas.Series.to_numpy": ["A NumPy ndarray representing the values in this Series or Index."], "to_period": ["Convert Series from DatetimeIndex to PeriodIndex.", "Cast to PeriodArray/Index at a particular frequency.", "Convert DataFrame from DatetimeIndex to PeriodIndex.", "Return an period of which this timestamp is an observation."], "Series.to_period": ["Convert Series from DatetimeIndex to PeriodIndex."], "pandas.Series.to_period": ["Convert Series from DatetimeIndex to PeriodIndex."], "to_timestamp": ["Cast to DatetimeIndex of Timestamps, at <em>beginning</em> of period.", "Cast to DatetimeIndex of timestamps, at <em>beginning</em> of period.", "Return the Timestamp representation of the Period.", "Cast to DatetimeArray/Index."], "Series.to_timestamp": ["Cast to DatetimeIndex of Timestamps, at <em>beginning</em> of period."], "pandas.Series.to_timestamp": ["Cast to DatetimeIndex of Timestamps, at <em>beginning</em> of period."], "to_list": ["Return a list of the values."], "Series.to_list": ["Return a list of the values."], "pandas.Series.to_list": ["Return a list of the values."], "__array__": ["Return the values as a NumPy array.", "The numpy array interface.", "sc.__array__(dtype) return 0-dim array from scalar with specified dtype"], "Series.__array__": ["Return the values as a NumPy array."], "pandas.Series.__array__": ["Return the values as a NumPy array."], "Series.get": ["Get item from object for given key (ex: DataFrame column)."], "pandas.Series.get": ["Get item from object for given key (ex: DataFrame column)."], "at": ["Access a single value for a row/column label pair."], "Series.at": ["Access a single value for a row/column label pair."], "pandas.Series.at": ["Access a single value for a row/column label pair."], "iat": ["Access a single value for a row/column pair by integer position."], "Series.iat": ["Access a single value for a row/column pair by integer position."], "pandas.Series.iat": ["Access a single value for a row/column pair by integer position."], "loc": ["Access a group of rows and columns by label(s) or a boolean array."], "Series.loc": ["Access a group of rows and columns by label(s) or a boolean array."], "pandas.Series.loc": ["Access a group of rows and columns by label(s) or a boolean array."], "iloc": ["Purely integer-location based indexing for selection by position."], "Series.iloc": ["Purely integer-location based indexing for selection by position."], "pandas.Series.iloc": ["Purely integer-location based indexing for selection by position."], "__iter__": ["Return an iterator of the values.", "Iterate over info axis.", "Groupby iterator."], "Series.__iter__": ["Return an iterator of the values."], "pandas.Series.__iter__": ["Return an iterator of the values."], "items": ["Lazily iterate over (index, value) tuples.", "Iterate over (column name, Series) pairs."], "Series.items": ["Lazily iterate over (index, value) tuples."], "pandas.Series.items": ["Lazily iterate over (index, value) tuples."], "iteritems": ["Lazily iterate over (index, value) tuples.", "Iterate over (column name, Series) pairs."], "Series.iteritems": ["Lazily iterate over (index, value) tuples."], "pandas.Series.iteritems": ["Lazily iterate over (index, value) tuples."], "Series.keys": ["Return alias for index."], "pandas.Series.keys": ["Return alias for index."], "pop": ["Return item and drops from series.", "Return item and drop from frame."], "Series.pop": ["Return item and drops from series."], "pandas.Series.pop": ["Return item and drops from series."], "item": ["Return the first element of the underlying data as a Python scalar.", "Copy an element of an array to a standard Python scalar and return it."], "Series.item": ["Return the first element of the underlying data as a Python scalar."], "pandas.Series.item": ["Return the first element of the underlying data as a Python scalar."], "xs": ["Return cross-section from the Series/DataFrame."], "Series.xs": ["Return cross-section from the Series/DataFrame."], "pandas.Series.xs": ["Return cross-section from the Series/DataFrame."], "add": ["Return Addition of series and other, element-wise (binary operator <cite>add</cite>).", "Get Addition of dataframe and other, element-wise (binary operator <cite>add</cite>)."], "Series.add": ["Return Addition of series and other, element-wise (binary operator <cite>add</cite>)."], "pandas.Series.add": ["Return Addition of series and other, element-wise (binary operator <cite>add</cite>)."], "sub": ["Return Subtraction of series and other, element-wise (binary operator <cite>sub</cite>).", "Get Subtraction of dataframe and other, element-wise (binary operator <cite>sub</cite>)."], "Series.sub": ["Return Subtraction of series and other, element-wise (binary operator <cite>sub</cite>)."], "pandas.Series.sub": ["Return Subtraction of series and other, element-wise (binary operator <cite>sub</cite>)."], "mul": ["Return Multiplication of series and other, element-wise (binary operator <cite>mul</cite>).", "Get Multiplication of dataframe and other, element-wise (binary operator <cite>mul</cite>)."], "Series.mul": ["Return Multiplication of series and other, element-wise (binary operator <cite>mul</cite>)."], "pandas.Series.mul": ["Return Multiplication of series and other, element-wise (binary operator <cite>mul</cite>)."], "div": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>).", "Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "Series.div": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>)."], "pandas.Series.div": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>)."], "truediv": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>).", "Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "Series.truediv": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>)."], "pandas.Series.truediv": ["Return Floating division of series and other, element-wise (binary operator <cite>truediv</cite>)."], "floordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>floordiv</cite>).", "Get Integer division of dataframe and other, element-wise (binary operator <cite>floordiv</cite>)."], "Series.floordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>floordiv</cite>)."], "pandas.Series.floordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>floordiv</cite>)."], "mod": ["Return Modulo of series and other, element-wise (binary operator <cite>mod</cite>).", "Get Modulo of dataframe and other, element-wise (binary operator <cite>mod</cite>)."], "Series.mod": ["Return Modulo of series and other, element-wise (binary operator <cite>mod</cite>)."], "pandas.Series.mod": ["Return Modulo of series and other, element-wise (binary operator <cite>mod</cite>)."], "pow": ["Return Exponential power of series and other, element-wise (binary operator <cite>pow</cite>).", "Get Exponential power of dataframe and other, element-wise (binary operator <cite>pow</cite>)."], "Series.pow": ["Return Exponential power of series and other, element-wise (binary operator <cite>pow</cite>)."], "pandas.Series.pow": ["Return Exponential power of series and other, element-wise (binary operator <cite>pow</cite>)."], "radd": ["Return Addition of series and other, element-wise (binary operator <cite>radd</cite>).", "Get Addition of dataframe and other, element-wise (binary operator <cite>radd</cite>)."], "Series.radd": ["Return Addition of series and other, element-wise (binary operator <cite>radd</cite>)."], "pandas.Series.radd": ["Return Addition of series and other, element-wise (binary operator <cite>radd</cite>)."], "rsub": ["Return Subtraction of series and other, element-wise (binary operator <cite>rsub</cite>).", "Get Subtraction of dataframe and other, element-wise (binary operator <cite>rsub</cite>)."], "Series.rsub": ["Return Subtraction of series and other, element-wise (binary operator <cite>rsub</cite>)."], "pandas.Series.rsub": ["Return Subtraction of series and other, element-wise (binary operator <cite>rsub</cite>)."], "rmul": ["Return Multiplication of series and other, element-wise (binary operator <cite>rmul</cite>).", "Get Multiplication of dataframe and other, element-wise (binary operator <cite>rmul</cite>)."], "Series.rmul": ["Return Multiplication of series and other, element-wise (binary operator <cite>rmul</cite>)."], "pandas.Series.rmul": ["Return Multiplication of series and other, element-wise (binary operator <cite>rmul</cite>)."], "rdiv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>).", "Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "Series.rdiv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>)."], "pandas.Series.rdiv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>)."], "rtruediv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>).", "Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "Series.rtruediv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>)."], "pandas.Series.rtruediv": ["Return Floating division of series and other, element-wise (binary operator <cite>rtruediv</cite>)."], "rfloordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>rfloordiv</cite>).", "Get Integer division of dataframe and other, element-wise (binary operator <cite>rfloordiv</cite>)."], "Series.rfloordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>rfloordiv</cite>)."], "pandas.Series.rfloordiv": ["Return Integer division of series and other, element-wise (binary operator <cite>rfloordiv</cite>)."], "rmod": ["Return Modulo of series and other, element-wise (binary operator <cite>rmod</cite>).", "Get Modulo of dataframe and other, element-wise (binary operator <cite>rmod</cite>)."], "Series.rmod": ["Return Modulo of series and other, element-wise (binary operator <cite>rmod</cite>)."], "pandas.Series.rmod": ["Return Modulo of series and other, element-wise (binary operator <cite>rmod</cite>)."], "rpow": ["Return Exponential power of series and other, element-wise (binary operator <cite>rpow</cite>).", "Get Exponential power of dataframe and other, element-wise (binary operator <cite>rpow</cite>)."], "Series.rpow": ["Return Exponential power of series and other, element-wise (binary operator <cite>rpow</cite>)."], "pandas.Series.rpow": ["Return Exponential power of series and other, element-wise (binary operator <cite>rpow</cite>)."], "combine": ["Combine the Series with a Series or scalar according to <cite>func</cite>.", "Perform column-wise combine with another DataFrame.", "Combine date, time into datetime with same date and time fields."], "Series.combine": ["Combine the Series with a Series or scalar according to <cite>func</cite>."], "pandas.Series.combine": ["Combine the Series with a Series or scalar according to <cite>func</cite>."], "combine_first": ["Update null elements with value in the same location in 'other'.", "Update null elements with value in the same location in <cite>other</cite>."], "Series.combine_first": ["Update null elements with value in the same location in 'other'."], "pandas.Series.combine_first": ["Update null elements with value in the same location in 'other'."], "round": ["Round each value in a Series to the given number of decimals.", "Perform round operation on the data to the specified <cite>freq</cite>.", "Round a DataFrame to a variable number of decimal places.", "Round the Timestamp to the specified resolution.", "Round the Timedelta to the specified resolution.", "Return <em class=\"xref py py-obj\">a</em> with each element rounded to the given number of decimals."], "Series.round": ["Round each value in a Series to the given number of decimals."], "pandas.Series.round": ["Round each value in a Series to the given number of decimals."], "lt": ["Return Less than of series and other, element-wise (binary operator <cite>lt</cite>).", "Get Less than of dataframe and other, element-wise (binary operator <cite>lt</cite>)."], "Series.lt": ["Return Less than of series and other, element-wise (binary operator <cite>lt</cite>)."], "pandas.Series.lt": ["Return Less than of series and other, element-wise (binary operator <cite>lt</cite>)."], "gt": ["Return Greater than of series and other, element-wise (binary operator <cite>gt</cite>).", "Get Greater than of dataframe and other, element-wise (binary operator <cite>gt</cite>)."], "Series.gt": ["Return Greater than of series and other, element-wise (binary operator <cite>gt</cite>)."], "pandas.Series.gt": ["Return Greater than of series and other, element-wise (binary operator <cite>gt</cite>)."], "le": ["Return Less than or equal to of series and other, element-wise (binary operator <cite>le</cite>).", "Get Less than or equal to of dataframe and other, element-wise (binary operator <cite>le</cite>)."], "Series.le": ["Return Less than or equal to of series and other, element-wise (binary operator <cite>le</cite>)."], "pandas.Series.le": ["Return Less than or equal to of series and other, element-wise (binary operator <cite>le</cite>)."], "ge": ["Return Greater than or equal to of series and other, element-wise (binary operator <cite>ge</cite>).", "Get Greater than or equal to of dataframe and other, element-wise (binary operator <cite>ge</cite>)."], "Series.ge": ["Return Greater than or equal to of series and other, element-wise (binary operator <cite>ge</cite>)."], "pandas.Series.ge": ["Return Greater than or equal to of series and other, element-wise (binary operator <cite>ge</cite>)."], "ne": ["Return Not equal to of series and other, element-wise (binary operator <cite>ne</cite>).", "Get Not equal to of dataframe and other, element-wise (binary operator <cite>ne</cite>)."], "Series.ne": ["Return Not equal to of series and other, element-wise (binary operator <cite>ne</cite>)."], "pandas.Series.ne": ["Return Not equal to of series and other, element-wise (binary operator <cite>ne</cite>)."], "eq": ["Return Equal to of series and other, element-wise (binary operator <cite>eq</cite>).", "Get Equal to of dataframe and other, element-wise (binary operator <cite>eq</cite>)."], "Series.eq": ["Return Equal to of series and other, element-wise (binary operator <cite>eq</cite>)."], "pandas.Series.eq": ["Return Equal to of series and other, element-wise (binary operator <cite>eq</cite>)."], "product": ["Return the product of the values over the requested axis."], "Series.product": ["Return the product of the values over the requested axis."], "pandas.Series.product": ["Return the product of the values over the requested axis."], "dot": ["Compute the dot product between the Series and the columns of other.", "Compute the matrix multiplication between the DataFrame and other."], "Series.dot": ["Compute the dot product between the Series and the columns of other."], "pandas.Series.dot": ["Compute the dot product between the Series and the columns of other."], "apply": ["Invoke function on values of Series.", "Apply a function along an axis of the DataFrame.", "", "Calculate the rolling custom aggregation function.", "Calculate the expanding custom aggregation function.", "Apply function <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> group-wise and combine the results together.", "Aggregate using one or more operations over the specified axis.", "Apply a CSS-styling function column-wise, row-wise, or table-wise."], "Series.apply": ["Invoke function on values of Series."], "pandas.Series.apply": ["Invoke function on values of Series."], "agg": ["Aggregate using one or more operations over the specified axis.", ""], "Series.agg": ["Aggregate using one or more operations over the specified axis."], "pandas.Series.agg": ["Aggregate using one or more operations over the specified axis."], "aggregate": ["Aggregate using one or more operations over the specified axis."], "Series.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.Series.aggregate": ["Aggregate using one or more operations over the specified axis."], "transform": ["Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a Series with the same axis shape as self.", "Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a DataFrame with the same axis shape as self.", "Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values.", "Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values.", "Call function producing a like-indexed Series on each group and return a Series with the transformed values."], "Series.transform": ["Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a Series with the same axis shape as self."], "pandas.Series.transform": ["Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a Series with the same axis shape as self."], "map": ["Map values of Series according to an input mapping or function.", "Map values using an input mapping or function.", "Map values using input an input mapping or function."], "Series.map": ["Map values of Series according to an input mapping or function."], "pandas.Series.map": ["Map values of Series according to an input mapping or function."], "groupby": ["Group Series using a mapper or by a Series of columns.", "Group DataFrame using a mapper or by a Series of columns."], "Series.groupby": ["Group Series using a mapper or by a Series of columns."], "pandas.Series.groupby": ["Group Series using a mapper or by a Series of columns."], "rolling": ["Provide rolling window calculations."], "Series.rolling": ["Provide rolling window calculations."], "pandas.Series.rolling": ["Provide rolling window calculations."], "expanding": ["Provide expanding window calculations."], "Series.expanding": ["Provide expanding window calculations."], "pandas.Series.expanding": ["Provide expanding window calculations."], "ewm": ["Provide exponentially weighted (EW) calculations."], "Series.ewm": ["Provide exponentially weighted (EW) calculations."], "pandas.Series.ewm": ["Provide exponentially weighted (EW) calculations."], "pipe": ["Apply chainable functions that expect Series or DataFrames.", "Apply a function <cite>func</cite> with arguments to this GroupBy object and return the function's result.", "Apply a function <cite>func</cite> with arguments to this Resampler object and return the function's result.", "Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "Series.pipe": ["Apply chainable functions that expect Series or DataFrames."], "pandas.Series.pipe": ["Apply chainable functions that expect Series or DataFrames."], "abs": ["Return a Series/DataFrame with absolute numeric value of each element."], "Series.abs": ["Return a Series/DataFrame with absolute numeric value of each element."], "pandas.Series.abs": ["Return a Series/DataFrame with absolute numeric value of each element."], "all": ["Return whether all elements are True, potentially over an axis.", "Return whether all elements are Truthy.", "Return True if all values in the group are truthful, else False."], "Series.all": ["Return whether all elements are True, potentially over an axis."], "pandas.Series.all": ["Return whether all elements are True, potentially over an axis."], "any": ["Return whether any element is True, potentially over an axis.", "Return whether any element is Truthy.", "Return True if any value in the group is truthful, else False.", "Returns True if any of the elements of <em class=\"xref py py-obj\">a</em> evaluate to True."], "Series.any": ["Return whether any element is True, potentially over an axis."], "pandas.Series.any": ["Return whether any element is True, potentially over an axis."], "autocorr": ["Compute the lag-N autocorrelation."], "Series.autocorr": ["Compute the lag-N autocorrelation."], "pandas.Series.autocorr": ["Compute the lag-N autocorrelation."], "between": ["Return boolean Series equivalent to left &lt;= series &lt;= right."], "Series.between": ["Return boolean Series equivalent to left &lt;= series &lt;= right."], "pandas.Series.between": ["Return boolean Series equivalent to left &lt;= series &lt;= right."], "clip": ["Trim values at input threshold(s)."], "Series.clip": ["Trim values at input threshold(s)."], "pandas.Series.clip": ["Trim values at input threshold(s)."], "corr": ["Compute correlation with <cite>other</cite> Series, excluding missing values.", "Compute pairwise correlation of columns, excluding NA/null values.", "Calculate the rolling correlation.", "Calculate the expanding correlation.", "Calculate the ewm (exponential weighted moment) sample correlation."], "Series.corr": ["Compute correlation with <cite>other</cite> Series, excluding missing values."], "pandas.Series.corr": ["Compute correlation with <cite>other</cite> Series, excluding missing values."], "count": ["Return number of non-NA/null observations in the Series.", "Count occurrences of pattern in each string of the Series/Index.", "Count non-NA cells for each column or row.", "Calculate the rolling count of non NaN observations.", "Calculate the expanding count of non NaN observations.", "Compute count of group, excluding missing values."], "Series.count": ["Return number of non-NA/null observations in the Series."], "pandas.Series.count": ["Return number of non-NA/null observations in the Series."], "cov": ["Compute covariance with Series, excluding missing values.", "Compute pairwise covariance of columns, excluding NA/null values.", "Calculate the rolling sample covariance.", "Calculate the expanding sample covariance.", "Calculate the ewm (exponential weighted moment) sample covariance."], "Series.cov": ["Compute covariance with Series, excluding missing values."], "pandas.Series.cov": ["Compute covariance with Series, excluding missing values."], "cummax": ["Return cumulative maximum over a DataFrame or Series axis.", "Cumulative max for each group."], "Series.cummax": ["Return cumulative maximum over a DataFrame or Series axis."], "pandas.Series.cummax": ["Return cumulative maximum over a DataFrame or Series axis."], "cummin": ["Return cumulative minimum over a DataFrame or Series axis.", "Cumulative min for each group."], "Series.cummin": ["Return cumulative minimum over a DataFrame or Series axis."], "pandas.Series.cummin": ["Return cumulative minimum over a DataFrame or Series axis."], "cumprod": ["Return cumulative product over a DataFrame or Series axis.", "Cumulative product for each group.", "Return the cumulative product of the elements along the given axis."], "Series.cumprod": ["Return cumulative product over a DataFrame or Series axis."], "pandas.Series.cumprod": ["Return cumulative product over a DataFrame or Series axis."], "cumsum": ["Return cumulative sum over a DataFrame or Series axis.", "Cumulative sum for each group.", "Return the cumulative sum of the elements along the given axis."], "Series.cumsum": ["Return cumulative sum over a DataFrame or Series axis."], "pandas.Series.cumsum": ["Return cumulative sum over a DataFrame or Series axis."], "describe": ["Generate descriptive statistics."], "Series.describe": ["Generate descriptive statistics."], "pandas.Series.describe": ["Generate descriptive statistics."], "diff": ["First discrete difference of element."], "Series.diff": ["First discrete difference of element."], "pandas.Series.diff": ["First discrete difference of element."], "Series.factorize": ["Encode the object as an enumerated type or categorical variable."], "pandas.Series.factorize": ["Encode the object as an enumerated type or categorical variable."], "kurt": ["Return unbiased kurtosis over requested axis.", "Calculate the rolling Fisher's definition of kurtosis without bias.", "Calculate the expanding Fisher's definition of kurtosis without bias."], "Series.kurt": ["Return unbiased kurtosis over requested axis."], "pandas.Series.kurt": ["Return unbiased kurtosis over requested axis."], "mad": ["Return the mean absolute deviation of the values over the requested axis."], "Series.mad": ["Return the mean absolute deviation of the values over the requested axis."], "pandas.Series.mad": ["Return the mean absolute deviation of the values over the requested axis."], "max": ["Return the maximum of the values over the requested axis.", "", "Return the maximum value of the Index.", "Calculate the rolling maximum.", "Calculate the expanding maximum.", "Compute max of group values.", "Return the maximum along a given axis."], "Series.max": ["Return the maximum of the values over the requested axis."], "pandas.Series.max": ["Return the maximum of the values over the requested axis."], "mean": ["Return the mean of the values over the requested axis.", "Return the mean value of the Array.", "Calculate the rolling mean.", "Calculate the rolling weighted window mean.", "Calculate the expanding mean.", "Calculate the ewm (exponential weighted moment) mean.", "Compute mean of groups, excluding missing values.", "Returns the average of the array elements along given axis."], "Series.mean": ["Return the mean of the values over the requested axis."], "pandas.Series.mean": ["Return the mean of the values over the requested axis."], "median": ["Return the median of the values over the requested axis.", "Calculate the rolling median.", "Calculate the expanding median.", "Compute median of groups, excluding missing values."], "Series.median": ["Return the median of the values over the requested axis."], "pandas.Series.median": ["Return the median of the values over the requested axis."], "min": ["Return the minimum of the values over the requested axis.", "", "Return the minimum value of the Index.", "Calculate the rolling minimum.", "Calculate the expanding minimum.", "Compute min of group values.", "Return the minimum along a given axis."], "Series.min": ["Return the minimum of the values over the requested axis."], "pandas.Series.min": ["Return the minimum of the values over the requested axis."], "mode": ["Return the mode(s) of the Series.", "Get the mode(s) of each element along the selected axis."], "Series.mode": ["Return the mode(s) of the Series."], "pandas.Series.mode": ["Return the mode(s) of the Series."], "nlargest": ["Return the largest <cite>n</cite> elements.", "Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in descending order."], "Series.nlargest": ["Return the largest <cite>n</cite> elements."], "pandas.Series.nlargest": ["Return the largest <cite>n</cite> elements."], "nsmallest": ["Return the smallest <cite>n</cite> elements.", "Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in ascending order."], "Series.nsmallest": ["Return the smallest <cite>n</cite> elements."], "pandas.Series.nsmallest": ["Return the smallest <cite>n</cite> elements."], "pct_change": ["Percentage change between the current and a prior element.", "Calculate pct_change of each value to previous entry in group."], "Series.pct_change": ["Percentage change between the current and a prior element."], "pandas.Series.pct_change": ["Percentage change between the current and a prior element."], "prod": ["Return the product of the values over the requested axis.", "Compute prod of group values.", "Return the product of the array elements over the given axis"], "Series.prod": ["Return the product of the values over the requested axis."], "pandas.Series.prod": ["Return the product of the values over the requested axis."], "quantile": ["Return value at the given quantile.", "Return values at the given quantile over requested axis.", "Calculate the rolling quantile.", "Calculate the expanding quantile.", "Return group values at the given quantile, a la numpy.percentile."], "Series.quantile": ["Return value at the given quantile."], "pandas.Series.quantile": ["Return value at the given quantile."], "rank": ["Compute numerical data ranks (1 through n) along axis.", "Calculate the rolling rank.", "Calculate the expanding rank.", "Provide the rank of values within each group."], "Series.rank": ["Compute numerical data ranks (1 through n) along axis."], "pandas.Series.rank": ["Compute numerical data ranks (1 through n) along axis."], "sem": ["Return unbiased standard error of the mean over requested axis.", "Calculate the rolling standard error of mean.", "Calculate the expanding standard error of mean.", "Compute standard error of the mean of groups, excluding missing values."], "Series.sem": ["Return unbiased standard error of the mean over requested axis."], "pandas.Series.sem": ["Return unbiased standard error of the mean over requested axis."], "skew": ["Return unbiased skew over requested axis.", "Calculate the rolling unbiased skewness.", "Calculate the expanding unbiased skewness."], "Series.skew": ["Return unbiased skew over requested axis."], "pandas.Series.skew": ["Return unbiased skew over requested axis."], "std": ["Return sample standard deviation over requested axis.", "Calculate the rolling standard deviation.", "Calculate the rolling weighted window standard deviation.", "Calculate the expanding standard deviation.", "Calculate the ewm (exponential weighted moment) standard deviation.", "Compute standard deviation of groups, excluding missing values.", "Returns the standard deviation of the array elements along given axis."], "Series.std": ["Return sample standard deviation over requested axis."], "pandas.Series.std": ["Return sample standard deviation over requested axis."], "sum": ["Return the sum of the values over the requested axis.", "Calculate the rolling sum.", "Calculate the rolling weighted window sum.", "Calculate the expanding sum.", "Calculate the ewm (exponential weighted moment) sum.", "Compute sum of group values.", "Return the sum of the array elements over the given axis."], "Series.sum": ["Return the sum of the values over the requested axis."], "pandas.Series.sum": ["Return the sum of the values over the requested axis."], "var": ["Return unbiased variance over requested axis.", "Calculate the rolling variance.", "Calculate the rolling weighted window variance.", "Calculate the expanding variance.", "Calculate the ewm (exponential weighted moment) variance.", "Compute variance of groups, excluding missing values.", "Returns the variance of the array elements, along given axis."], "Series.var": ["Return unbiased variance over requested axis."], "pandas.Series.var": ["Return unbiased variance over requested axis."], "kurtosis": ["Return unbiased kurtosis over requested axis."], "Series.kurtosis": ["Return unbiased kurtosis over requested axis."], "pandas.Series.kurtosis": ["Return unbiased kurtosis over requested axis."], "Series.unique": ["Return unique values of Series object."], "pandas.Series.unique": ["Return unique values of Series object."], "nunique": ["Return number of unique elements in the object.", "Count number of distinct elements in specified axis.", "Return DataFrame with counts of unique elements in each position.", "Return number of unique elements in the group."], "Series.nunique": ["Return number of unique elements in the object."], "pandas.Series.nunique": ["Return number of unique elements in the object."], "is_unique": ["Return boolean if values in the object are unique.", "Return if the index has unique values."], "Series.is_unique": ["Return boolean if values in the object are unique."], "pandas.Series.is_unique": ["Return boolean if values in the object are unique."], "is_monotonic": ["Return boolean if values in the object are monotonic_increasing.", "Alias for is_monotonic_increasing."], "Series.is_monotonic": ["Return boolean if values in the object are monotonic_increasing."], "pandas.Series.is_monotonic": ["Return boolean if values in the object are monotonic_increasing."], "is_monotonic_increasing": ["Alias for is_monotonic.", "Return if the index is monotonic increasing (only equal or increasing) values."], "Series.is_monotonic_increasing": ["Alias for is_monotonic."], "pandas.Series.is_monotonic_increasing": ["Alias for is_monotonic."], "is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing.", "Return if the index is monotonic decreasing (only equal or decreasing) values."], "Series.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "pandas.Series.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "value_counts": ["Return a Series containing counts of unique values.", "Return a Series containing counts of unique rows in the DataFrame.", "Return a Series or DataFrame containing counts of unique rows.", ""], "Series.value_counts": ["Return a Series containing counts of unique values."], "pandas.Series.value_counts": ["Return a Series containing counts of unique values."], "align": ["Align two objects on their axes with the specified join method."], "Series.align": ["Align two objects on their axes with the specified join method."], "pandas.Series.align": ["Align two objects on their axes with the specified join method."], "drop": ["Return Series with specified index labels removed.", "Drop specified labels from rows or columns.", "Make new Index with passed list of labels deleted."], "Series.drop": ["Return Series with specified index labels removed."], "pandas.Series.drop": ["Return Series with specified index labels removed."], "droplevel": ["Return Series/DataFrame with requested index / column level(s) removed.", "Return index with requested level(s) removed."], "Series.droplevel": ["Return Series/DataFrame with requested index / column level(s) removed."], "pandas.Series.droplevel": ["Return Series/DataFrame with requested index / column level(s) removed."], "drop_duplicates": ["Return Series with duplicate values removed.", "Return DataFrame with duplicate rows removed.", "Return Index with duplicate values removed."], "Series.drop_duplicates": ["Return Series with duplicate values removed."], "pandas.Series.drop_duplicates": ["Return Series with duplicate values removed."], "duplicated": ["Indicate duplicate Series values.", "Return boolean Series denoting duplicate rows.", "Indicate duplicate index values."], "Series.duplicated": ["Indicate duplicate Series values."], "pandas.Series.duplicated": ["Indicate duplicate Series values."], "equals": ["Test whether two objects contain the same elements.", "Determine if two Index object are equal.", "Determine if two CategoricalIndex objects contain the same elements."], "Series.equals": ["Test whether two objects contain the same elements."], "pandas.Series.equals": ["Test whether two objects contain the same elements."], "first": ["Select initial periods of time series data based on a date offset.", "Compute first of group values."], "Series.first": ["Select initial periods of time series data based on a date offset."], "pandas.Series.first": ["Select initial periods of time series data based on a date offset."], "head": ["Return the first <cite>n</cite> rows.", "Return first n rows of each group."], "Series.head": ["Return the first <cite>n</cite> rows."], "pandas.Series.head": ["Return the first <cite>n</cite> rows."], "idxmax": ["Return the row label of the maximum value.", "Return index of first occurrence of maximum over requested axis."], "Series.idxmax": ["Return the row label of the maximum value."], "pandas.Series.idxmax": ["Return the row label of the maximum value."], "idxmin": ["Return the row label of the minimum value.", "Return index of first occurrence of minimum over requested axis."], "Series.idxmin": ["Return the row label of the minimum value."], "pandas.Series.idxmin": ["Return the row label of the minimum value."], "isin": ["Whether elements in Series are contained in <cite>values</cite>.", "Whether each element in the DataFrame is contained in values.", "Return a boolean array where the index values are in <cite>values</cite>."], "Series.isin": ["Whether elements in Series are contained in <cite>values</cite>."], "pandas.Series.isin": ["Whether elements in Series are contained in <cite>values</cite>."], "last": ["Select final periods of time series data based on a date offset.", "Compute last of group values."], "Series.last": ["Select final periods of time series data based on a date offset."], "pandas.Series.last": ["Select final periods of time series data based on a date offset."], "reindex": ["Conform Series to new index with optional filling logic.", "Conform Series/DataFrame to new index with optional filling logic.", "Create index with target's values."], "Series.reindex": ["Conform Series to new index with optional filling logic."], "pandas.Series.reindex": ["Conform Series to new index with optional filling logic."], "reindex_like": ["Return an object with matching indices as other object."], "Series.reindex_like": ["Return an object with matching indices as other object."], "pandas.Series.reindex_like": ["Return an object with matching indices as other object."], "rename": ["Alter Series index labels or name.", "Alter axes labels.", "Alter Index or MultiIndex name."], "Series.rename": ["Alter Series index labels or name."], "pandas.Series.rename": ["Alter Series index labels or name."], "rename_axis": ["Set the name of the axis for the index or columns."], "Series.rename_axis": ["Set the name of the axis for the index or columns."], "pandas.Series.rename_axis": ["Set the name of the axis for the index or columns."], "reset_index": ["Generate a new DataFrame or Series with the index reset.", "Reset the index, or a level of it."], "Series.reset_index": ["Generate a new DataFrame or Series with the index reset."], "pandas.Series.reset_index": ["Generate a new DataFrame or Series with the index reset."], "sample": ["Return a random sample of items from an axis of object.", "Return a random sample of items from each group."], "Series.sample": ["Return a random sample of items from an axis of object."], "pandas.Series.sample": ["Return a random sample of items from an axis of object."], "set_axis": ["Assign desired index to given axis."], "Series.set_axis": ["Assign desired index to given axis."], "pandas.Series.set_axis": ["Assign desired index to given axis."], "take": ["Return the elements in the given <em>positional</em> indices along an axis.", "Return a new Index of the values selected by the indices.", "Return an array formed from the elements of <em class=\"xref py py-obj\">a</em> at the given indices."], "Series.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "pandas.Series.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "tail": ["Return the last <cite>n</cite> rows.", "Return last n rows of each group."], "Series.tail": ["Return the last <cite>n</cite> rows."], "pandas.Series.tail": ["Return the last <cite>n</cite> rows."], "truncate": ["Truncate a Series or DataFrame before and after some index value."], "Series.truncate": ["Truncate a Series or DataFrame before and after some index value."], "pandas.Series.truncate": ["Truncate a Series or DataFrame before and after some index value."], "where": ["Replace values where the condition is False."], "Series.where": ["Replace values where the condition is False."], "pandas.Series.where": ["Replace values where the condition is False."], "mask": ["Replace values where the condition is True."], "Series.mask": ["Replace values where the condition is True."], "pandas.Series.mask": ["Replace values where the condition is True."], "add_prefix": ["Prefix labels with string <cite>prefix</cite>."], "Series.add_prefix": ["Prefix labels with string <cite>prefix</cite>."], "pandas.Series.add_prefix": ["Prefix labels with string <cite>prefix</cite>."], "add_suffix": ["Suffix labels with string <cite>suffix</cite>."], "Series.add_suffix": ["Suffix labels with string <cite>suffix</cite>."], "pandas.Series.add_suffix": ["Suffix labels with string <cite>suffix</cite>."], "filter": ["Subset the dataframe rows or columns according to the specified index labels.", "Return a copy of a DataFrame excluding filtered elements."], "Series.filter": ["Subset the dataframe rows or columns according to the specified index labels."], "pandas.Series.filter": ["Subset the dataframe rows or columns according to the specified index labels."], "backfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>.", "Backward fill the values.", "Backward fill the new missing values in the resampled data."], "Series.backfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "pandas.Series.backfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "bfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>.", "Backward fill the values.", "Backward fill the new missing values in the resampled data."], "Series.bfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "pandas.Series.bfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "dropna": ["Return a new Series with missing values removed.", "Remove missing values.", "Return Index without NA/NaN values."], "Series.dropna": ["Return a new Series with missing values removed."], "pandas.Series.dropna": ["Return a new Series with missing values removed."], "ffill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>.", "Forward fill the values."], "Series.ffill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "pandas.Series.ffill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "fillna": ["Fill NA/NaN values using the specified method.", "Fill NA/NaN values with the specified value.", "Fill missing values introduced by upsampling."], "Series.fillna": ["Fill NA/NaN values using the specified method."], "pandas.Series.fillna": ["Fill NA/NaN values using the specified method."], "interpolate": ["Fill NaN values using an interpolation method.", "Interpolate values according to different methods."], "Series.interpolate": ["Fill NaN values using an interpolation method."], "pandas.Series.interpolate": ["Fill NaN values using an interpolation method."], "Series.isna": ["Detect missing values."], "pandas.Series.isna": ["Detect missing values."], "Series.isnull": ["Series.isnull is an alias for Series.isna."], "pandas.Series.isnull": ["Series.isnull is an alias for Series.isna."], "Series.notna": ["Detect existing (non-missing) values."], "pandas.Series.notna": ["Detect existing (non-missing) values."], "Series.notnull": ["Series.notnull is an alias for Series.notna."], "pandas.Series.notnull": ["Series.notnull is an alias for Series.notna."], "pad": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>.", "Pad strings in the Series/Index up to width.", "Forward fill the values."], "Series.pad": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "pandas.Series.pad": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "replace": ["Replace values given in <cite>to_replace</cite> with <cite>value</cite>.", "Replace each occurrence of pattern/regex in the Series/Index.", "Implements datetime.replace, handles nanoseconds."], "Series.replace": ["Replace values given in <cite>to_replace</cite> with <cite>value</cite>."], "pandas.Series.replace": ["Replace values given in <cite>to_replace</cite> with <cite>value</cite>."], "argsort": ["Return the integer indices that would sort the Series values.", "Return the integer indices that would sort the index.", "Returns the indices that would sort this array."], "Series.argsort": ["Return the integer indices that would sort the Series values."], "pandas.Series.argsort": ["Return the integer indices that would sort the Series values."], "argmin": ["Return int position of the smallest value in the Series.", "Return indices of the minimum values along the given axis."], "Series.argmin": ["Return int position of the smallest value in the Series."], "pandas.Series.argmin": ["Return int position of the smallest value in the Series."], "argmax": ["Return int position of the largest value in the Series.", "Return indices of the maximum values along the given axis."], "Series.argmax": ["Return int position of the largest value in the Series."], "pandas.Series.argmax": ["Return int position of the largest value in the Series."], "reorder_levels": ["Rearrange index levels using input order.", "Rearrange levels using input order."], "Series.reorder_levels": ["Rearrange index levels using input order."], "pandas.Series.reorder_levels": ["Rearrange index levels using input order."], "sort_values": ["Sort by the values.", "Sort by the values along either axis.", "Return a sorted copy of the index."], "Series.sort_values": ["Sort by the values."], "pandas.Series.sort_values": ["Sort by the values."], "sort_index": ["Sort Series by index labels.", "Sort object by labels (along an axis)."], "Series.sort_index": ["Sort Series by index labels."], "pandas.Series.sort_index": ["Sort Series by index labels."], "swaplevel": ["Swap levels i and j in a <a class=\"reference internal\" href=\"api/pandas.MultiIndex.html#pandas.MultiIndex\" title=\"pandas.MultiIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultiIndex</span></code></a>.", "Swap level i with level j."], "Series.swaplevel": ["Swap levels i and j in a <a class=\"reference internal\" href=\"api/pandas.MultiIndex.html#pandas.MultiIndex\" title=\"pandas.MultiIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultiIndex</span></code></a>."], "pandas.Series.swaplevel": ["Swap levels i and j in a <a class=\"reference internal\" href=\"api/pandas.MultiIndex.html#pandas.MultiIndex\" title=\"pandas.MultiIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultiIndex</span></code></a>."], "unstack": ["Unstack, also known as pivot, Series with MultiIndex to produce DataFrame.", "Pivot a level of the (necessarily hierarchical) index labels."], "Series.unstack": ["Unstack, also known as pivot, Series with MultiIndex to produce DataFrame."], "pandas.Series.unstack": ["Unstack, also known as pivot, Series with MultiIndex to produce DataFrame."], "explode": ["Transform each element of a list-like to a row.", "Transform each element of a list-like to a row, replicating index values."], "Series.explode": ["Transform each element of a list-like to a row."], "pandas.Series.explode": ["Transform each element of a list-like to a row."], "searchsorted": ["Find indices where elements should be inserted to maintain order.", "Find indices where elements of v should be inserted in a to maintain order."], "Series.searchsorted": ["Find indices where elements should be inserted to maintain order."], "pandas.Series.searchsorted": ["Find indices where elements should be inserted to maintain order."], "ravel": ["Return the flattened underlying data as an ndarray.", "Return an ndarray of the flattened values of the underlying data.", "Return a flattened array.", "Return a contiguous flattened array."], "Series.ravel": ["Return the flattened underlying data as an ndarray."], "pandas.Series.ravel": ["Return the flattened underlying data as an ndarray."], "repeat": ["Repeat elements of a Series.", "Duplicate each string in the Series or Index.", "Repeat elements of a Index.", "Repeat elements of an array."], "Series.repeat": ["Repeat elements of a Series."], "pandas.Series.repeat": ["Repeat elements of a Series."], "squeeze": ["Squeeze 1 dimensional axis objects into scalars.", "Remove axes of length one from <em class=\"xref py py-obj\">a</em>.", "Scalar method identical to the corresponding array attribute."], "Series.squeeze": ["Squeeze 1 dimensional axis objects into scalars."], "pandas.Series.squeeze": ["Squeeze 1 dimensional axis objects into scalars."], "view": ["Create a new view of the Series.", "Array view compatibility.", "", "New view of array with the same data."], "Series.view": ["Create a new view of the Series."], "pandas.Series.view": ["Create a new view of the Series."], "Series.append": ["(DEPRECATED) Concatenate two or more Series."], "pandas.Series.append": ["(DEPRECATED) Concatenate two or more Series."], "compare": ["Compare to another Series and show the differences.", "Compare to another DataFrame and show the differences."], "Series.compare": ["Compare to another Series and show the differences."], "pandas.Series.compare": ["Compare to another Series and show the differences."], "update": ["Modify Series in place using values from passed Series.", "Modify in place using non-NA values from another DataFrame."], "Series.update": ["Modify Series in place using values from passed Series."], "pandas.Series.update": ["Modify Series in place using values from passed Series."], "asfreq": ["Convert time series to specified frequency.", "Convert Period to desired frequency, at the start or end of the interval.", "Convert the PeriodArray to the specified frequency <cite>freq</cite>.", "Return the values at the new freq, essentially a reindex."], "Series.asfreq": ["Convert time series to specified frequency."], "pandas.Series.asfreq": ["Convert time series to specified frequency."], "asof": ["Return the last row(s) without any NaNs before <cite>where</cite>.", "Return the label from the index, or, if not present, the previous one."], "Series.asof": ["Return the last row(s) without any NaNs before <cite>where</cite>."], "pandas.Series.asof": ["Return the last row(s) without any NaNs before <cite>where</cite>."], "shift": ["Shift index by desired number of periods with an optional time <cite>freq</cite>.", "Shift index by desired number of time frequency increments.", "Shift each group by periods observations."], "Series.shift": ["Shift index by desired number of periods with an optional time <cite>freq</cite>."], "pandas.Series.shift": ["Shift index by desired number of periods with an optional time <cite>freq</cite>."], "first_valid_index": ["Return index for first non-NA value or None, if no non-NA value is found."], "Series.first_valid_index": ["Return index for first non-NA value or None, if no non-NA value is found."], "pandas.Series.first_valid_index": ["Return index for first non-NA value or None, if no non-NA value is found."], "last_valid_index": ["Return index for last non-NA value or None, if no non-NA value is found."], "Series.last_valid_index": ["Return index for last non-NA value or None, if no non-NA value is found."], "pandas.Series.last_valid_index": ["Return index for last non-NA value or None, if no non-NA value is found."], "resample": ["Resample time-series data.", "Provide resampling when using a TimeGrouper.", "Resample arrays or sparse matrices in a consistent way."], "Series.resample": ["Resample time-series data."], "pandas.Series.resample": ["Resample time-series data."], "tz_convert": ["Convert tz-aware axis to target time zone.", "Convert tz-aware Datetime Array/Index from one time zone to another.", "Convert timezone-aware Timestamp to another time zone."], "Series.tz_convert": ["Convert tz-aware axis to target time zone."], "pandas.Series.tz_convert": ["Convert tz-aware axis to target time zone."], "tz_localize": ["Localize tz-naive index of a Series or DataFrame to target time zone.", "Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index.", "Convert naive Timestamp to local time zone, or remove timezone from timezone-aware Timestamp."], "Series.tz_localize": ["Localize tz-naive index of a Series or DataFrame to target time zone."], "pandas.Series.tz_localize": ["Localize tz-naive index of a Series or DataFrame to target time zone."], "at_time": ["Select values at particular time of day (e.g., 9:30AM)."], "Series.at_time": ["Select values at particular time of day (e.g., 9:30AM)."], "pandas.Series.at_time": ["Select values at particular time of day (e.g., 9:30AM)."], "between_time": ["Select values between particular times of the day (e.g., 9:00-9:30 AM)."], "Series.between_time": ["Select values between particular times of the day (e.g., 9:00-9:30 AM)."], "pandas.Series.between_time": ["Select values between particular times of the day (e.g., 9:00-9:30 AM)."], "tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "Series.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "pandas.Series.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "slice_shift": ["(DEPRECATED) Equivalent to <cite>shift</cite> without copying data."], "Series.slice_shift": ["(DEPRECATED) Equivalent to <cite>shift</cite> without copying data."], "pandas.Series.slice_shift": ["(DEPRECATED) Equivalent to <cite>shift</cite> without copying data."], "date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects.", "Return date object with same year, month and day."], "dt.date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects."], "Series.dt.date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects."], "pandas.Series.dt.date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects."], "time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects.", "Return time object with same time but with tzinfo=None."], "dt.time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects."], "Series.dt.time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects."], "pandas.Series.dt.time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects."], "timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information.", "Return time object with same time and tzinfo."], "dt.timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information."], "Series.dt.timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information."], "pandas.Series.dt.timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information."], "year": ["The year of the datetime.", "", "Return the year this Period falls on.", "The year of the period."], "dt.year": ["The year of the datetime."], "Series.dt.year": ["The year of the datetime."], "pandas.Series.dt.year": ["The year of the datetime."], "month": ["The month as January=1, December=12.", "", "Return the month this Period falls on."], "dt.month": ["The month as January=1, December=12."], "Series.dt.month": ["The month as January=1, December=12."], "pandas.Series.dt.month": ["The month as January=1, December=12."], "day": ["The day of the datetime.", "", "Get day of the month that a Period falls on.", "The days of the period."], "dt.day": ["The day of the datetime."], "Series.dt.day": ["The day of the datetime."], "pandas.Series.dt.day": ["The day of the datetime."], "hour": ["The hours of the datetime.", "", "Get the hour of the day component of the Period.", "The hour of the period."], "dt.hour": ["The hours of the datetime."], "Series.dt.hour": ["The hours of the datetime."], "pandas.Series.dt.hour": ["The hours of the datetime."], "minute": ["The minutes of the datetime.", "", "Get minute of the hour component of the Period.", "The minute of the period."], "dt.minute": ["The minutes of the datetime."], "Series.dt.minute": ["The minutes of the datetime."], "pandas.Series.dt.minute": ["The minutes of the datetime."], "second": ["The seconds of the datetime.", "", "Get the second component of the Period.", "The second of the period."], "dt.second": ["The seconds of the datetime."], "Series.dt.second": ["The seconds of the datetime."], "pandas.Series.dt.second": ["The seconds of the datetime."], "microsecond": ["The microseconds of the datetime.", ""], "dt.microsecond": ["The microseconds of the datetime."], "Series.dt.microsecond": ["The microseconds of the datetime."], "pandas.Series.dt.microsecond": ["The microseconds of the datetime."], "nanosecond": ["The nanoseconds of the datetime.", ""], "dt.nanosecond": ["The nanoseconds of the datetime."], "Series.dt.nanosecond": ["The nanoseconds of the datetime."], "pandas.Series.dt.nanosecond": ["The nanoseconds of the datetime."], "week": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard.", "Return the week number of the year.", "Get the week of the year on the given Period.", "(DEPRECATED) The week ordinal of the year.", "The week ordinal of the year.", ""], "dt.week": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "Series.dt.week": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "pandas.Series.dt.week": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "weekofyear": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard.", "Return the week number of the year.", "Get the week of the year on the given Period.", "(DEPRECATED) The week ordinal of the year.", "The week ordinal of the year."], "dt.weekofyear": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "Series.dt.weekofyear": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "pandas.Series.dt.weekofyear": ["(DEPRECATED) The week ordinal of the year according to the ISO 8601 standard."], "dayofweek": ["The day of the week with Monday=0, Sunday=6.", "Return day of the week.", "Day of the week the period lies in, with Monday=0 and Sunday=6."], "dt.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "Series.dt.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "pandas.Series.dt.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "day_of_week": ["The day of the week with Monday=0, Sunday=6.", "Return day of the week.", "Day of the week the period lies in, with Monday=0 and Sunday=6."], "dt.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "Series.dt.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "pandas.Series.dt.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "weekday": ["The day of the week with Monday=0, Sunday=6.", "Return the day of the week represented by the date.", "Day of the week the period lies in, with Monday=0 and Sunday=6.", ""], "dt.weekday": ["The day of the week with Monday=0, Sunday=6."], "Series.dt.weekday": ["The day of the week with Monday=0, Sunday=6."], "pandas.Series.dt.weekday": ["The day of the week with Monday=0, Sunday=6."], "dayofyear": ["The ordinal day of the year.", "Return the day of the year."], "dt.dayofyear": ["The ordinal day of the year."], "Series.dt.dayofyear": ["The ordinal day of the year."], "pandas.Series.dt.dayofyear": ["The ordinal day of the year."], "day_of_year": ["The ordinal day of the year.", "Return the day of the year."], "dt.day_of_year": ["The ordinal day of the year."], "Series.dt.day_of_year": ["The ordinal day of the year."], "pandas.Series.dt.day_of_year": ["The ordinal day of the year."], "quarter": ["The quarter of the date.", "Return the quarter of the year.", "Return the quarter this Period falls on."], "dt.quarter": ["The quarter of the date."], "Series.dt.quarter": ["The quarter of the date."], "pandas.Series.dt.quarter": ["The quarter of the date."], "is_month_start": ["Indicates whether the date is the first day of the month.", "Return True if date is first day of month.", ""], "dt.is_month_start": ["Indicates whether the date is the first day of the month."], "Series.dt.is_month_start": ["Indicates whether the date is the first day of the month."], "pandas.Series.dt.is_month_start": ["Indicates whether the date is the first day of the month."], "is_month_end": ["Indicates whether the date is the last day of the month.", "Return True if date is last day of month.", ""], "dt.is_month_end": ["Indicates whether the date is the last day of the month."], "Series.dt.is_month_end": ["Indicates whether the date is the last day of the month."], "pandas.Series.dt.is_month_end": ["Indicates whether the date is the last day of the month."], "is_quarter_start": ["Indicator for whether the date is the first day of a quarter.", "Return True if date is first day of the quarter.", ""], "dt.is_quarter_start": ["Indicator for whether the date is the first day of a quarter."], "Series.dt.is_quarter_start": ["Indicator for whether the date is the first day of a quarter."], "pandas.Series.dt.is_quarter_start": ["Indicator for whether the date is the first day of a quarter."], "is_quarter_end": ["Indicator for whether the date is the last day of a quarter.", "Return True if date is last day of the quarter.", ""], "dt.is_quarter_end": ["Indicator for whether the date is the last day of a quarter."], "Series.dt.is_quarter_end": ["Indicator for whether the date is the last day of a quarter."], "pandas.Series.dt.is_quarter_end": ["Indicator for whether the date is the last day of a quarter."], "is_year_start": ["Indicate whether the date is the first day of a year.", "Return True if date is first day of the year.", ""], "dt.is_year_start": ["Indicate whether the date is the first day of a year."], "Series.dt.is_year_start": ["Indicate whether the date is the first day of a year."], "pandas.Series.dt.is_year_start": ["Indicate whether the date is the first day of a year."], "is_year_end": ["Indicate whether the date is the last day of the year.", "Return True if date is last day of the year.", ""], "dt.is_year_end": ["Indicate whether the date is the last day of the year."], "Series.dt.is_year_end": ["Indicate whether the date is the last day of the year."], "pandas.Series.dt.is_year_end": ["Indicate whether the date is the last day of the year."], "is_leap_year": ["Boolean indicator if the date belongs to a leap year.", "Return True if year is a leap year.", "Return True if the period's year is in a leap year.", "Logical indicating if the date belongs to a leap year."], "dt.is_leap_year": ["Boolean indicator if the date belongs to a leap year."], "Series.dt.is_leap_year": ["Boolean indicator if the date belongs to a leap year."], "pandas.Series.dt.is_leap_year": ["Boolean indicator if the date belongs to a leap year."], "daysinmonth": ["The number of days in the month.", "Return the number of days in the month.", "Get the total number of days of the month that the Period falls in."], "dt.daysinmonth": ["The number of days in the month."], "Series.dt.daysinmonth": ["The number of days in the month."], "pandas.Series.dt.daysinmonth": ["The number of days in the month."], "days_in_month": ["The number of days in the month.", "Return the number of days in the month.", "Get the total number of days in the month that this period falls on."], "dt.days_in_month": ["The number of days in the month."], "Series.dt.days_in_month": ["The number of days in the month."], "pandas.Series.dt.days_in_month": ["The number of days in the month."], "tz": ["Return the timezone.", "Alias for tzinfo."], "dt.tz": ["Return the timezone."], "Series.dt.tz": ["Return the timezone."], "pandas.Series.dt.tz": ["Return the timezone."], "freq": ["Return the frequency object for this PeriodArray.", "", "Return the frequency object if it is set, otherwise None."], "dt.freq": ["Return the frequency object for this PeriodArray."], "Series.dt.freq": ["Return the frequency object for this PeriodArray."], "pandas.Series.dt.freq": ["Return the frequency object for this PeriodArray."], "isocalendar": ["Calculate year, week, and day according to the ISO 8601 standard.", "Return a 3-tuple containing ISO year, week number, and weekday."], "dt.isocalendar": ["Calculate year, week, and day according to the ISO 8601 standard."], "Series.dt.isocalendar": ["Calculate year, week, and day according to the ISO 8601 standard."], "pandas.Series.dt.isocalendar": ["Calculate year, week, and day according to the ISO 8601 standard."], "dt.to_period": ["Cast to PeriodArray/Index at a particular frequency."], "Series.dt.to_period": ["Cast to PeriodArray/Index at a particular frequency."], "pandas.Series.dt.to_period": ["Cast to PeriodArray/Index at a particular frequency."], "to_pydatetime": ["Return the data as an array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.datetime\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.datetime</span></code></a> objects.", "Convert a Timestamp object to a native Python datetime object.", "Return Datetime Array/Index as object ndarray of datetime.datetime objects."], "dt.to_pydatetime": ["Return the data as an array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.datetime\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.datetime</span></code></a> objects."], "Series.dt.to_pydatetime": ["Return the data as an array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.datetime\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.datetime</span></code></a> objects."], "pandas.Series.dt.to_pydatetime": ["Return the data as an array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.datetime\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.datetime</span></code></a> objects."], "dt.tz_localize": ["Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index."], "Series.dt.tz_localize": ["Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index."], "pandas.Series.dt.tz_localize": ["Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index."], "dt.tz_convert": ["Convert tz-aware Datetime Array/Index from one time zone to another."], "Series.dt.tz_convert": ["Convert tz-aware Datetime Array/Index from one time zone to another."], "pandas.Series.dt.tz_convert": ["Convert tz-aware Datetime Array/Index from one time zone to another."], "normalize": ["Convert times to midnight.", "Return the Unicode normal form for the strings in the Series/Index.", "Normalize Timestamp to midnight, preserving tz information.", "", "Scale input vectors individually to unit norm (vector length)."], "dt.normalize": ["Convert times to midnight."], "Series.dt.normalize": ["Convert times to midnight."], "pandas.Series.dt.normalize": ["Convert times to midnight."], "strftime": ["Convert to Index using specified date_format.", "Return a string representing the given POSIX timestamp controlled by an explicit format string.", "Returns the string representation of the <a class=\"reference internal\" href=\"api/pandas.Period.html#pandas.Period\" title=\"pandas.Period\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Period</span></code></a>, depending on the selected <code class=\"docutils literal notranslate\"><span class=\"pre\">fmt</span></code>."], "dt.strftime": ["Convert to Index using specified date_format."], "Series.dt.strftime": ["Convert to Index using specified date_format."], "pandas.Series.dt.strftime": ["Convert to Index using specified date_format."], "dt.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "Series.dt.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "pandas.Series.dt.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "floor": ["Perform floor operation on the data to the specified <cite>freq</cite>.", "Return a new Timestamp floored to this resolution.", "Return a new Timedelta floored to this resolution."], "dt.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "Series.dt.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "pandas.Series.dt.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>.", "Return a new Timestamp ceiled to this resolution.", "Return a new Timedelta ceiled to this resolution."], "dt.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "Series.dt.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "pandas.Series.dt.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale.", "Return the month name of the Timestamp with specified locale."], "dt.month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "Series.dt.month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "pandas.Series.dt.month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale.", "Return the day name of the Timestamp with specified locale."], "dt.day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "Series.dt.day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "pandas.Series.dt.day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "qyear": ["", "Fiscal year the Period lies in according to its starting-quarter."], "dt.qyear": [""], "Series.dt.qyear": [""], "pandas.Series.dt.qyear": [""], "start_time": ["", "Get the Timestamp for the start of the period."], "dt.start_time": [""], "Series.dt.start_time": [""], "pandas.Series.dt.start_time": [""], "end_time": ["", "Get the Timestamp for the end of the period."], "dt.end_time": [""], "Series.dt.end_time": [""], "pandas.Series.dt.end_time": [""], "days": ["Number of days for each element.", "Number of days."], "dt.days": ["Number of days for each element."], "Series.dt.days": ["Number of days for each element."], "pandas.Series.dt.days": ["Number of days for each element."], "seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element.", "Number of seconds (&gt;= 0 and less than 1 day)."], "dt.seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element."], "Series.dt.seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element."], "pandas.Series.dt.seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element."], "microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element.", "Number of microseconds (&gt;= 0 and less than 1 second)."], "dt.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element."], "Series.dt.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element."], "pandas.Series.dt.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element."], "nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element.", "Return the number of nanoseconds (n), where 0 &lt;= n &lt; 1 microsecond."], "dt.nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element."], "Series.dt.nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element."], "pandas.Series.dt.nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element."], "components": ["Return a Dataframe of the components of the Timedeltas.", "Return a components namedtuple-like.", "Return a dataframe of the components (days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas."], "dt.components": ["Return a Dataframe of the components of the Timedeltas."], "Series.dt.components": ["Return a Dataframe of the components of the Timedeltas."], "pandas.Series.dt.components": ["Return a Dataframe of the components of the Timedeltas."], "to_pytimedelta": ["Return an array of native <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.timedelta\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code></a> objects.", "Convert a pandas Timedelta object into a python <code class=\"docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code> object.", "Return Timedelta Array/Index as object ndarray of datetime.timedelta objects."], "dt.to_pytimedelta": ["Return an array of native <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.timedelta\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code></a> objects."], "Series.dt.to_pytimedelta": ["Return an array of native <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.timedelta\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code></a> objects."], "pandas.Series.dt.to_pytimedelta": ["Return an array of native <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.timedelta\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code></a> objects."], "total_seconds": ["Return total duration of each element expressed in seconds.", "Total seconds in the duration."], "dt.total_seconds": ["Return total duration of each element expressed in seconds."], "Series.dt.total_seconds": ["Return total duration of each element expressed in seconds."], "pandas.Series.dt.total_seconds": ["Return total duration of each element expressed in seconds."], "capitalize": ["Convert strings in the Series/Index to be capitalized."], "str.capitalize": ["Convert strings in the Series/Index to be capitalized."], "Series.str.capitalize": ["Convert strings in the Series/Index to be capitalized."], "pandas.Series.str.capitalize": ["Convert strings in the Series/Index to be capitalized."], "casefold": ["Convert strings in the Series/Index to be casefolded."], "str.casefold": ["Convert strings in the Series/Index to be casefolded."], "Series.str.casefold": ["Convert strings in the Series/Index to be casefolded."], "pandas.Series.str.casefold": ["Convert strings in the Series/Index to be casefolded."], "cat": ["Concatenate strings in the Series/Index with given separator."], "str.cat": ["Concatenate strings in the Series/Index with given separator."], "Series.str.cat": ["Concatenate strings in the Series/Index with given separator."], "pandas.Series.str.cat": ["Concatenate strings in the Series/Index with given separator."], "center": ["Pad left and right side of strings in the Series/Index."], "str.center": ["Pad left and right side of strings in the Series/Index."], "Series.str.center": ["Pad left and right side of strings in the Series/Index."], "pandas.Series.str.center": ["Pad left and right side of strings in the Series/Index."], "contains": ["Test if pattern or regex is contained within a string of a Series or Index.", "Check elementwise if the Intervals contain the value."], "str.contains": ["Test if pattern or regex is contained within a string of a Series or Index."], "Series.str.contains": ["Test if pattern or regex is contained within a string of a Series or Index."], "pandas.Series.str.contains": ["Test if pattern or regex is contained within a string of a Series or Index."], "str.count": ["Count occurrences of pattern in each string of the Series/Index."], "Series.str.count": ["Count occurrences of pattern in each string of the Series/Index."], "pandas.Series.str.count": ["Count occurrences of pattern in each string of the Series/Index."], "decode": ["Decode character string in the Series/Index using indicated encoding.", "Calls <em class=\"xref py py-obj\">str.decode</em> element-wise."], "str.decode": ["Decode character string in the Series/Index using indicated encoding."], "Series.str.decode": ["Decode character string in the Series/Index using indicated encoding."], "pandas.Series.str.decode": ["Decode character string in the Series/Index using indicated encoding."], "encode": ["Encode character string in the Series/Index using indicated encoding.", "Calls <a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str.encode\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">str.encode</span></code></a> element-wise."], "str.encode": ["Encode character string in the Series/Index using indicated encoding."], "Series.str.encode": ["Encode character string in the Series/Index using indicated encoding."], "pandas.Series.str.encode": ["Encode character string in the Series/Index using indicated encoding."], "endswith": ["Test if the end of each string element matches a pattern."], "str.endswith": ["Test if the end of each string element matches a pattern."], "Series.str.endswith": ["Test if the end of each string element matches a pattern."], "pandas.Series.str.endswith": ["Test if the end of each string element matches a pattern."], "extract": ["Extract capture groups in the regex <cite>pat</cite> as columns in a DataFrame."], "str.extract": ["Extract capture groups in the regex <cite>pat</cite> as columns in a DataFrame."], "Series.str.extract": ["Extract capture groups in the regex <cite>pat</cite> as columns in a DataFrame."], "pandas.Series.str.extract": ["Extract capture groups in the regex <cite>pat</cite> as columns in a DataFrame."], "extractall": ["Extract capture groups in the regex <cite>pat</cite> as columns in DataFrame."], "str.extractall": ["Extract capture groups in the regex <cite>pat</cite> as columns in DataFrame."], "Series.str.extractall": ["Extract capture groups in the regex <cite>pat</cite> as columns in DataFrame."], "pandas.Series.str.extractall": ["Extract capture groups in the regex <cite>pat</cite> as columns in DataFrame."], "find": ["Return lowest indexes in each strings in the Series/Index."], "str.find": ["Return lowest indexes in each strings in the Series/Index."], "Series.str.find": ["Return lowest indexes in each strings in the Series/Index."], "pandas.Series.str.find": ["Return lowest indexes in each strings in the Series/Index."], "findall": ["Find all occurrences of pattern or regular expression in the Series/Index."], "str.findall": ["Find all occurrences of pattern or regular expression in the Series/Index."], "Series.str.findall": ["Find all occurrences of pattern or regular expression in the Series/Index."], "pandas.Series.str.findall": ["Find all occurrences of pattern or regular expression in the Series/Index."], "fullmatch": ["Determine if each string entirely matches a regular expression."], "str.fullmatch": ["Determine if each string entirely matches a regular expression."], "Series.str.fullmatch": ["Determine if each string entirely matches a regular expression."], "pandas.Series.str.fullmatch": ["Determine if each string entirely matches a regular expression."], "str.get": ["Extract element from each component at specified position."], "Series.str.get": ["Extract element from each component at specified position."], "pandas.Series.str.get": ["Extract element from each component at specified position."], "str.index": ["Return lowest indexes in each string in Series/Index."], "Series.str.index": ["Return lowest indexes in each string in Series/Index."], "pandas.Series.str.index": ["Return lowest indexes in each string in Series/Index."], "join": ["Join lists contained as elements in the Series/Index with passed delimiter.", "Join columns of another DataFrame.", "Compute join_index and indexers to conform data structures to the new index."], "str.join": ["Join lists contained as elements in the Series/Index with passed delimiter."], "Series.str.join": ["Join lists contained as elements in the Series/Index with passed delimiter."], "pandas.Series.str.join": ["Join lists contained as elements in the Series/Index with passed delimiter."], "len": ["Compute the length of each element in the Series/Index."], "str.len": ["Compute the length of each element in the Series/Index."], "Series.str.len": ["Compute the length of each element in the Series/Index."], "pandas.Series.str.len": ["Compute the length of each element in the Series/Index."], "ljust": ["Pad right side of strings in the Series/Index."], "str.ljust": ["Pad right side of strings in the Series/Index."], "Series.str.ljust": ["Pad right side of strings in the Series/Index."], "pandas.Series.str.ljust": ["Pad right side of strings in the Series/Index."], "lower": ["Convert strings in the Series/Index to lowercase.", "Return an array with the elements converted to lowercase."], "str.lower": ["Convert strings in the Series/Index to lowercase."], "Series.str.lower": ["Convert strings in the Series/Index to lowercase."], "pandas.Series.str.lower": ["Convert strings in the Series/Index to lowercase."], "lstrip": ["Remove leading characters."], "str.lstrip": ["Remove leading characters."], "Series.str.lstrip": ["Remove leading characters."], "pandas.Series.str.lstrip": ["Remove leading characters."], "match": ["Determine if each string starts with a match of a regular expression."], "str.match": ["Determine if each string starts with a match of a regular expression."], "Series.str.match": ["Determine if each string starts with a match of a regular expression."], "pandas.Series.str.match": ["Determine if each string starts with a match of a regular expression."], "str.normalize": ["Return the Unicode normal form for the strings in the Series/Index."], "Series.str.normalize": ["Return the Unicode normal form for the strings in the Series/Index."], "pandas.Series.str.normalize": ["Return the Unicode normal form for the strings in the Series/Index."], "str.pad": ["Pad strings in the Series/Index up to width."], "Series.str.pad": ["Pad strings in the Series/Index up to width."], "pandas.Series.str.pad": ["Pad strings in the Series/Index up to width."], "partition": ["Split the string at the first occurrence of <cite>sep</cite>.", "Partition each element in <em class=\"xref py py-obj\">a</em> around <em class=\"xref py py-obj\">sep</em>."], "str.partition": ["Split the string at the first occurrence of <cite>sep</cite>."], "Series.str.partition": ["Split the string at the first occurrence of <cite>sep</cite>."], "pandas.Series.str.partition": ["Split the string at the first occurrence of <cite>sep</cite>."], "removeprefix": ["Remove a prefix from an object series."], "str.removeprefix": ["Remove a prefix from an object series."], "Series.str.removeprefix": ["Remove a prefix from an object series."], "pandas.Series.str.removeprefix": ["Remove a prefix from an object series."], "removesuffix": ["Remove a suffix from an object series."], "str.removesuffix": ["Remove a suffix from an object series."], "Series.str.removesuffix": ["Remove a suffix from an object series."], "pandas.Series.str.removesuffix": ["Remove a suffix from an object series."], "str.repeat": ["Duplicate each string in the Series or Index."], "Series.str.repeat": ["Duplicate each string in the Series or Index."], "pandas.Series.str.repeat": ["Duplicate each string in the Series or Index."], "str.replace": ["Replace each occurrence of pattern/regex in the Series/Index."], "Series.str.replace": ["Replace each occurrence of pattern/regex in the Series/Index."], "pandas.Series.str.replace": ["Replace each occurrence of pattern/regex in the Series/Index."], "rfind": ["Return highest indexes in each strings in the Series/Index."], "str.rfind": ["Return highest indexes in each strings in the Series/Index."], "Series.str.rfind": ["Return highest indexes in each strings in the Series/Index."], "pandas.Series.str.rfind": ["Return highest indexes in each strings in the Series/Index."], "rindex": ["Return highest indexes in each string in Series/Index."], "str.rindex": ["Return highest indexes in each string in Series/Index."], "Series.str.rindex": ["Return highest indexes in each string in Series/Index."], "pandas.Series.str.rindex": ["Return highest indexes in each string in Series/Index."], "rjust": ["Pad left side of strings in the Series/Index."], "str.rjust": ["Pad left side of strings in the Series/Index."], "Series.str.rjust": ["Pad left side of strings in the Series/Index."], "pandas.Series.str.rjust": ["Pad left side of strings in the Series/Index."], "rpartition": ["Split the string at the last occurrence of <cite>sep</cite>.", "Partition (split) each element around the right-most separator."], "str.rpartition": ["Split the string at the last occurrence of <cite>sep</cite>."], "Series.str.rpartition": ["Split the string at the last occurrence of <cite>sep</cite>."], "pandas.Series.str.rpartition": ["Split the string at the last occurrence of <cite>sep</cite>."], "rstrip": ["Remove trailing characters."], "str.rstrip": ["Remove trailing characters."], "Series.str.rstrip": ["Remove trailing characters."], "pandas.Series.str.rstrip": ["Remove trailing characters."], "slice": ["Slice substrings from each element in the Series or Index."], "str.slice": ["Slice substrings from each element in the Series or Index."], "Series.str.slice": ["Slice substrings from each element in the Series or Index."], "pandas.Series.str.slice": ["Slice substrings from each element in the Series or Index."], "slice_replace": ["Replace a positional slice of a string with another value."], "str.slice_replace": ["Replace a positional slice of a string with another value."], "Series.str.slice_replace": ["Replace a positional slice of a string with another value."], "pandas.Series.str.slice_replace": ["Replace a positional slice of a string with another value."], "split": ["Split strings around given separator/delimiter.", "Split an array into multiple sub-arrays as views into <em class=\"xref py py-obj\">ary</em>."], "str.split": ["Split strings around given separator/delimiter."], "Series.str.split": ["Split strings around given separator/delimiter."], "pandas.Series.str.split": ["Split strings around given separator/delimiter."], "rsplit": ["Split strings around given separator/delimiter."], "str.rsplit": ["Split strings around given separator/delimiter."], "Series.str.rsplit": ["Split strings around given separator/delimiter."], "pandas.Series.str.rsplit": ["Split strings around given separator/delimiter."], "startswith": ["Test if the start of each string element matches a pattern."], "str.startswith": ["Test if the start of each string element matches a pattern."], "Series.str.startswith": ["Test if the start of each string element matches a pattern."], "pandas.Series.str.startswith": ["Test if the start of each string element matches a pattern."], "strip": ["Remove leading and trailing characters."], "str.strip": ["Remove leading and trailing characters."], "Series.str.strip": ["Remove leading and trailing characters."], "pandas.Series.str.strip": ["Remove leading and trailing characters."], "swapcase": ["Convert strings in the Series/Index to be swapcased."], "str.swapcase": ["Convert strings in the Series/Index to be swapcased."], "Series.str.swapcase": ["Convert strings in the Series/Index to be swapcased."], "pandas.Series.str.swapcase": ["Convert strings in the Series/Index to be swapcased."], "title": ["Convert strings in the Series/Index to titlecase.", "Return element-wise title cased version of string or unicode."], "str.title": ["Convert strings in the Series/Index to titlecase."], "Series.str.title": ["Convert strings in the Series/Index to titlecase."], "pandas.Series.str.title": ["Convert strings in the Series/Index to titlecase."], "translate": ["Map all characters in the string through the given mapping table."], "str.translate": ["Map all characters in the string through the given mapping table."], "Series.str.translate": ["Map all characters in the string through the given mapping table."], "pandas.Series.str.translate": ["Map all characters in the string through the given mapping table."], "upper": ["Convert strings in the Series/Index to uppercase.", "Return an array with the elements converted to uppercase."], "str.upper": ["Convert strings in the Series/Index to uppercase."], "Series.str.upper": ["Convert strings in the Series/Index to uppercase."], "pandas.Series.str.upper": ["Convert strings in the Series/Index to uppercase."], "wrap": ["Wrap strings in Series/Index at specified line width."], "str.wrap": ["Wrap strings in Series/Index at specified line width."], "Series.str.wrap": ["Wrap strings in Series/Index at specified line width."], "pandas.Series.str.wrap": ["Wrap strings in Series/Index at specified line width."], "zfill": ["Pad strings in the Series/Index by prepending '0' characters.", "Return the numeric string left-filled with zeros"], "str.zfill": ["Pad strings in the Series/Index by prepending '0' characters."], "Series.str.zfill": ["Pad strings in the Series/Index by prepending '0' characters."], "pandas.Series.str.zfill": ["Pad strings in the Series/Index by prepending '0' characters."], "isalnum": ["Check whether all characters in each string are alphanumeric."], "str.isalnum": ["Check whether all characters in each string are alphanumeric."], "Series.str.isalnum": ["Check whether all characters in each string are alphanumeric."], "pandas.Series.str.isalnum": ["Check whether all characters in each string are alphanumeric."], "isalpha": ["Check whether all characters in each string are alphabetic."], "str.isalpha": ["Check whether all characters in each string are alphabetic."], "Series.str.isalpha": ["Check whether all characters in each string are alphabetic."], "pandas.Series.str.isalpha": ["Check whether all characters in each string are alphabetic."], "isdigit": ["Check whether all characters in each string are digits."], "str.isdigit": ["Check whether all characters in each string are digits."], "Series.str.isdigit": ["Check whether all characters in each string are digits."], "pandas.Series.str.isdigit": ["Check whether all characters in each string are digits."], "isspace": ["Check whether all characters in each string are whitespace."], "str.isspace": ["Check whether all characters in each string are whitespace."], "Series.str.isspace": ["Check whether all characters in each string are whitespace."], "pandas.Series.str.isspace": ["Check whether all characters in each string are whitespace."], "islower": ["Check whether all characters in each string are lowercase."], "str.islower": ["Check whether all characters in each string are lowercase."], "Series.str.islower": ["Check whether all characters in each string are lowercase."], "pandas.Series.str.islower": ["Check whether all characters in each string are lowercase."], "isupper": ["Check whether all characters in each string are uppercase."], "str.isupper": ["Check whether all characters in each string are uppercase."], "Series.str.isupper": ["Check whether all characters in each string are uppercase."], "pandas.Series.str.isupper": ["Check whether all characters in each string are uppercase."], "istitle": ["Check whether all characters in each string are titlecase."], "str.istitle": ["Check whether all characters in each string are titlecase."], "Series.str.istitle": ["Check whether all characters in each string are titlecase."], "pandas.Series.str.istitle": ["Check whether all characters in each string are titlecase."], "isnumeric": ["Check whether all characters in each string are numeric."], "str.isnumeric": ["Check whether all characters in each string are numeric."], "Series.str.isnumeric": ["Check whether all characters in each string are numeric."], "pandas.Series.str.isnumeric": ["Check whether all characters in each string are numeric."], "isdecimal": ["Check whether all characters in each string are decimal."], "str.isdecimal": ["Check whether all characters in each string are decimal."], "Series.str.isdecimal": ["Check whether all characters in each string are decimal."], "pandas.Series.str.isdecimal": ["Check whether all characters in each string are decimal."], "str.get_dummies": ["Return DataFrame of dummy/indicator variables for Series."], "Series.str.get_dummies": ["Return DataFrame of dummy/indicator variables for Series."], "pandas.Series.str.get_dummies": ["Return DataFrame of dummy/indicator variables for Series."], "categories": ["The categories of this categorical.", "An <code class=\"docutils literal notranslate\"><span class=\"pre\">Index</span></code> containing the unique categories allowed."], "cat.categories": ["The categories of this categorical."], "Series.cat.categories": ["The categories of this categorical."], "pandas.Series.cat.categories": ["The categories of this categorical."], "ordered": ["Whether the categories have an ordered relationship."], "cat.ordered": ["Whether the categories have an ordered relationship."], "Series.cat.ordered": ["Whether the categories have an ordered relationship."], "pandas.Series.cat.ordered": ["Whether the categories have an ordered relationship."], "codes": ["Return Series of codes as well as the index.", "The category codes of this categorical.", ""], "cat.codes": ["Return Series of codes as well as the index."], "Series.cat.codes": ["Return Series of codes as well as the index."], "pandas.Series.cat.codes": ["Return Series of codes as well as the index."], "rename_categories": ["Rename categories."], "cat.rename_categories": ["Rename categories."], "Series.cat.rename_categories": ["Rename categories."], "pandas.Series.cat.rename_categories": ["Rename categories."], "reorder_categories": ["Reorder categories as specified in new_categories."], "cat.reorder_categories": ["Reorder categories as specified in new_categories."], "Series.cat.reorder_categories": ["Reorder categories as specified in new_categories."], "pandas.Series.cat.reorder_categories": ["Reorder categories as specified in new_categories."], "add_categories": ["Add new categories."], "cat.add_categories": ["Add new categories."], "Series.cat.add_categories": ["Add new categories."], "pandas.Series.cat.add_categories": ["Add new categories."], "remove_categories": ["Remove the specified categories."], "cat.remove_categories": ["Remove the specified categories."], "Series.cat.remove_categories": ["Remove the specified categories."], "pandas.Series.cat.remove_categories": ["Remove the specified categories."], "remove_unused_categories": ["Remove categories which are not used."], "cat.remove_unused_categories": ["Remove categories which are not used."], "Series.cat.remove_unused_categories": ["Remove categories which are not used."], "pandas.Series.cat.remove_unused_categories": ["Remove categories which are not used."], "set_categories": ["Set the categories to the specified new_categories."], "cat.set_categories": ["Set the categories to the specified new_categories."], "Series.cat.set_categories": ["Set the categories to the specified new_categories."], "pandas.Series.cat.set_categories": ["Set the categories to the specified new_categories."], "as_ordered": ["Set the Categorical to be ordered."], "cat.as_ordered": ["Set the Categorical to be ordered."], "Series.cat.as_ordered": ["Set the Categorical to be ordered."], "pandas.Series.cat.as_ordered": ["Set the Categorical to be ordered."], "as_unordered": ["Set the Categorical to be unordered."], "cat.as_unordered": ["Set the Categorical to be unordered."], "Series.cat.as_unordered": ["Set the Categorical to be unordered."], "pandas.Series.cat.as_unordered": ["Set the Categorical to be unordered."], "npoints": ["The number of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points."], "sparse.npoints": ["The number of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points."], "Series.sparse.npoints": ["The number of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points."], "pandas.Series.sparse.npoints": ["The number of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points."], "density": ["The percent of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points, as decimal.", "Generate Kernel Density Estimate plot using Gaussian kernels.", "Ratio of non-sparse points to total (dense) data points.", "Compute density of a sparse vector."], "sparse.density": ["The percent of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points, as decimal.", "Ratio of non-sparse points to total (dense) data points."], "Series.sparse.density": ["The percent of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points, as decimal."], "pandas.Series.sparse.density": ["The percent of non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> points, as decimal."], "fill_value": ["Elements in <cite>data</cite> that are <cite>fill_value</cite> are not stored."], "sparse.fill_value": ["Elements in <cite>data</cite> that are <cite>fill_value</cite> are not stored."], "Series.sparse.fill_value": ["Elements in <cite>data</cite> that are <cite>fill_value</cite> are not stored."], "pandas.Series.sparse.fill_value": ["Elements in <cite>data</cite> that are <cite>fill_value</cite> are not stored."], "sp_values": ["An ndarray containing the non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> values."], "sparse.sp_values": ["An ndarray containing the non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> values."], "Series.sparse.sp_values": ["An ndarray containing the non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> values."], "pandas.Series.sparse.sp_values": ["An ndarray containing the non- <code class=\"docutils literal notranslate\"><span class=\"pre\">fill_value</span></code> values."], "from_coo": ["Create a Series with sparse values from a scipy.sparse.coo_matrix."], "sparse.from_coo": ["Create a Series with sparse values from a scipy.sparse.coo_matrix."], "Series.sparse.from_coo": ["Create a Series with sparse values from a scipy.sparse.coo_matrix."], "pandas.Series.sparse.from_coo": ["Create a Series with sparse values from a scipy.sparse.coo_matrix."], "to_coo": ["Create a scipy.sparse.coo_matrix from a Series with MultiIndex.", "Return the contents of the frame as a sparse SciPy COO matrix."], "sparse.to_coo": ["Create a scipy.sparse.coo_matrix from a Series with MultiIndex.", "Return the contents of the frame as a sparse SciPy COO matrix."], "Series.sparse.to_coo": ["Create a scipy.sparse.coo_matrix from a Series with MultiIndex."], "pandas.Series.sparse.to_coo": ["Create a scipy.sparse.coo_matrix from a Series with MultiIndex."], "Flags": ["Flags that apply to pandas objects."], "pandas.Flags": ["Flags that apply to pandas objects."], "attrs": ["Dictionary of global attributes of this dataset."], "Series.attrs": ["Dictionary of global attributes of this dataset."], "pandas.Series.attrs": ["Dictionary of global attributes of this dataset."], "plot": ["Series plotting accessor and method", "DataFrame plotting accessor and method", "Class implementing the .plot attribute for groupby objects."], "Series.plot": ["Series plotting accessor and method"], "pandas.Series.plot": ["Series plotting accessor and method"], "area": ["Draw a stacked area plot."], "plot.area": ["Draw a stacked area plot."], "Series.plot.area": ["Draw a stacked area plot."], "pandas.Series.plot.area": ["Draw a stacked area plot."], "bar": ["Vertical bar plot.", "Draw bar chart in the cell backgrounds."], "plot.bar": ["Vertical bar plot."], "Series.plot.bar": ["Vertical bar plot."], "pandas.Series.plot.bar": ["Vertical bar plot."], "barh": ["Make a horizontal bar plot."], "plot.barh": ["Make a horizontal bar plot."], "Series.plot.barh": ["Make a horizontal bar plot."], "pandas.Series.plot.barh": ["Make a horizontal bar plot."], "box": ["Make a box plot of the DataFrame columns."], "plot.box": ["Make a box plot of the DataFrame columns."], "Series.plot.box": ["Make a box plot of the DataFrame columns."], "pandas.Series.plot.box": ["Make a box plot of the DataFrame columns."], "plot.density": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "Series.plot.density": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "pandas.Series.plot.density": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "hist": ["Draw one histogram of the DataFrame's columns.", "Draw histogram of the input series using matplotlib.", "Make a histogram of the DataFrame's columns."], "plot.hist": ["Draw one histogram of the DataFrame's columns."], "Series.plot.hist": ["Draw one histogram of the DataFrame's columns."], "pandas.Series.plot.hist": ["Draw one histogram of the DataFrame's columns."], "kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "plot.kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "Series.plot.kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "pandas.Series.plot.kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "line": ["Plot Series or DataFrame as lines."], "plot.line": ["Plot Series or DataFrame as lines."], "Series.plot.line": ["Plot Series or DataFrame as lines."], "pandas.Series.plot.line": ["Plot Series or DataFrame as lines."], "pie": ["Generate a pie plot."], "plot.pie": ["Generate a pie plot."], "Series.plot.pie": ["Generate a pie plot."], "pandas.Series.plot.pie": ["Generate a pie plot."], "Series.hist": ["Draw histogram of the input series using matplotlib."], "pandas.Series.hist": ["Draw histogram of the input series using matplotlib."], "Series.to_pickle": ["Pickle (serialize) object to file."], "pandas.Series.to_pickle": ["Pickle (serialize) object to file."], "Series.to_csv": ["Write object to a comma-separated values (csv) file."], "pandas.Series.to_csv": ["Write object to a comma-separated values (csv) file."], "to_dict": ["Convert Series to {label -&gt; value} dict or dict-like object.", "Convert the DataFrame to a dictionary."], "Series.to_dict": ["Convert Series to {label -&gt; value} dict or dict-like object."], "pandas.Series.to_dict": ["Convert Series to {label -&gt; value} dict or dict-like object."], "Series.to_excel": ["Write object to an Excel sheet."], "pandas.Series.to_excel": ["Write object to an Excel sheet."], "to_frame": ["Convert Series to DataFrame.", "Create a DataFrame with a column containing the Index.", "Create a DataFrame with the levels of the MultiIndex as columns."], "Series.to_frame": ["Convert Series to DataFrame."], "pandas.Series.to_frame": ["Convert Series to DataFrame."], "to_xarray": ["Return an xarray object from the pandas object."], "Series.to_xarray": ["Return an xarray object from the pandas object."], "pandas.Series.to_xarray": ["Return an xarray object from the pandas object."], "to_hdf": ["Write the contained data to an HDF5 file using HDFStore."], "Series.to_hdf": ["Write the contained data to an HDF5 file using HDFStore."], "pandas.Series.to_hdf": ["Write the contained data to an HDF5 file using HDFStore."], "Series.to_sql": ["Write records stored in a DataFrame to a SQL database."], "pandas.Series.to_sql": ["Write records stored in a DataFrame to a SQL database."], "Series.to_json": ["Convert the object to a JSON string."], "pandas.Series.to_json": ["Convert the object to a JSON string."], "to_string": ["Render a string representation of the Series.", "Render a DataFrame to a console-friendly tabular output."], "Series.to_string": ["Render a string representation of the Series."], "pandas.Series.to_string": ["Render a string representation of the Series."], "Series.to_clipboard": ["Copy object to the system clipboard."], "pandas.Series.to_clipboard": ["Copy object to the system clipboard."], "Series.to_latex": ["Render object to a LaTeX tabular, longtable, or nested table."], "pandas.Series.to_latex": ["Render object to a LaTeX tabular, longtable, or nested table."], "to_markdown": ["Print Series in Markdown-friendly format.", "Print DataFrame in Markdown-friendly format."], "Series.to_markdown": ["Print Series in Markdown-friendly format."], "pandas.Series.to_markdown": ["Print Series in Markdown-friendly format."], "DataFrame": ["Two-dimensional, size-mutable, potentially heterogeneous tabular data."], "pandas.DataFrame": ["Two-dimensional, size-mutable, potentially heterogeneous tabular data."], "DataFrame.index": ["The index (row labels) of the DataFrame."], "pandas.DataFrame.index": ["The index (row labels) of the DataFrame."], "columns": ["The column labels of the DataFrame."], "DataFrame.columns": ["The column labels of the DataFrame."], "pandas.DataFrame.columns": ["The column labels of the DataFrame."], "DataFrame.dtypes": ["Return the dtypes in the DataFrame."], "pandas.DataFrame.dtypes": ["Return the dtypes in the DataFrame."], "DataFrame.info": ["Print a concise summary of a DataFrame."], "pandas.DataFrame.info": ["Print a concise summary of a DataFrame."], "select_dtypes": ["Return a subset of the DataFrame's columns based on the column dtypes."], "DataFrame.select_dtypes": ["Return a subset of the DataFrame's columns based on the column dtypes."], "pandas.DataFrame.select_dtypes": ["Return a subset of the DataFrame's columns based on the column dtypes."], "DataFrame.values": ["Return a Numpy representation of the DataFrame."], "pandas.DataFrame.values": ["Return a Numpy representation of the DataFrame."], "axes": ["Return a list representing the axes of the DataFrame."], "DataFrame.axes": ["Return a list representing the axes of the DataFrame."], "pandas.DataFrame.axes": ["Return a list representing the axes of the DataFrame."], "DataFrame.ndim": ["Return an int representing the number of axes / array dimensions."], "pandas.DataFrame.ndim": ["Return an int representing the number of axes / array dimensions."], "DataFrame.size": ["Return an int representing the number of elements in this object."], "pandas.DataFrame.size": ["Return an int representing the number of elements in this object."], "DataFrame.shape": ["Return a tuple representing the dimensionality of the DataFrame."], "pandas.DataFrame.shape": ["Return a tuple representing the dimensionality of the DataFrame."], "DataFrame.memory_usage": ["Return the memory usage of each column in bytes."], "pandas.DataFrame.memory_usage": ["Return the memory usage of each column in bytes."], "DataFrame.empty": ["Indicator whether Series/DataFrame is empty."], "pandas.DataFrame.empty": ["Indicator whether Series/DataFrame is empty."], "DataFrame.set_flags": ["Return a new object with updated flags."], "pandas.DataFrame.set_flags": ["Return a new object with updated flags."], "DataFrame.astype": ["Cast a pandas object to a specified dtype <code class=\"docutils literal notranslate\"><span class=\"pre\">dtype</span></code>."], "pandas.DataFrame.astype": ["Cast a pandas object to a specified dtype <code class=\"docutils literal notranslate\"><span class=\"pre\">dtype</span></code>."], "DataFrame.convert_dtypes": ["Convert columns to best possible dtypes using dtypes supporting <code class=\"docutils literal notranslate\"><span class=\"pre\">pd.NA</span></code>."], "pandas.DataFrame.convert_dtypes": ["Convert columns to best possible dtypes using dtypes supporting <code class=\"docutils literal notranslate\"><span class=\"pre\">pd.NA</span></code>."], "DataFrame.infer_objects": ["Attempt to infer better dtypes for object columns."], "pandas.DataFrame.infer_objects": ["Attempt to infer better dtypes for object columns."], "DataFrame.copy": ["Make a copy of this object's indices and data."], "pandas.DataFrame.copy": ["Make a copy of this object's indices and data."], "DataFrame.bool": ["Return the bool of a single element Series or DataFrame."], "pandas.DataFrame.bool": ["Return the bool of a single element Series or DataFrame."], "DataFrame.head": ["Return the first <cite>n</cite> rows."], "pandas.DataFrame.head": ["Return the first <cite>n</cite> rows."], "DataFrame.at": ["Access a single value for a row/column label pair."], "pandas.DataFrame.at": ["Access a single value for a row/column label pair."], "DataFrame.iat": ["Access a single value for a row/column pair by integer position."], "pandas.DataFrame.iat": ["Access a single value for a row/column pair by integer position."], "DataFrame.loc": ["Access a group of rows and columns by label(s) or a boolean array."], "pandas.DataFrame.loc": ["Access a group of rows and columns by label(s) or a boolean array."], "DataFrame.iloc": ["Purely integer-location based indexing for selection by position."], "pandas.DataFrame.iloc": ["Purely integer-location based indexing for selection by position."], "insert": ["Insert column into DataFrame at specified location.", "Make new Index inserting new item at location.", "Insert values along the given axis before the given indices."], "DataFrame.insert": ["Insert column into DataFrame at specified location."], "pandas.DataFrame.insert": ["Insert column into DataFrame at specified location."], "DataFrame.__iter__": ["Iterate over info axis."], "pandas.DataFrame.__iter__": ["Iterate over info axis."], "DataFrame.items": ["Iterate over (column name, Series) pairs."], "pandas.DataFrame.items": ["Iterate over (column name, Series) pairs."], "DataFrame.iteritems": ["Iterate over (column name, Series) pairs."], "pandas.DataFrame.iteritems": ["Iterate over (column name, Series) pairs."], "DataFrame.keys": ["Get the 'info axis' (see Indexing for more)."], "pandas.DataFrame.keys": ["Get the 'info axis' (see Indexing for more)."], "iterrows": ["Iterate over DataFrame rows as (index, Series) pairs."], "DataFrame.iterrows": ["Iterate over DataFrame rows as (index, Series) pairs."], "pandas.DataFrame.iterrows": ["Iterate over DataFrame rows as (index, Series) pairs."], "itertuples": ["Iterate over DataFrame rows as namedtuples."], "DataFrame.itertuples": ["Iterate over DataFrame rows as namedtuples."], "pandas.DataFrame.itertuples": ["Iterate over DataFrame rows as namedtuples."], "lookup": ["(DEPRECATED) Label-based \"fancy indexing\" function for DataFrame."], "DataFrame.lookup": ["(DEPRECATED) Label-based \"fancy indexing\" function for DataFrame."], "pandas.DataFrame.lookup": ["(DEPRECATED) Label-based \"fancy indexing\" function for DataFrame."], "DataFrame.pop": ["Return item and drop from frame."], "pandas.DataFrame.pop": ["Return item and drop from frame."], "DataFrame.tail": ["Return the last <cite>n</cite> rows."], "pandas.DataFrame.tail": ["Return the last <cite>n</cite> rows."], "DataFrame.xs": ["Return cross-section from the Series/DataFrame."], "pandas.DataFrame.xs": ["Return cross-section from the Series/DataFrame."], "DataFrame.get": ["Get item from object for given key (ex: DataFrame column)."], "pandas.DataFrame.get": ["Get item from object for given key (ex: DataFrame column)."], "DataFrame.isin": ["Whether each element in the DataFrame is contained in values."], "pandas.DataFrame.isin": ["Whether each element in the DataFrame is contained in values."], "DataFrame.where": ["Replace values where the condition is False."], "pandas.DataFrame.where": ["Replace values where the condition is False."], "DataFrame.mask": ["Replace values where the condition is True."], "pandas.DataFrame.mask": ["Replace values where the condition is True."], "query": ["Query the columns of a DataFrame with a boolean expression."], "DataFrame.query": ["Query the columns of a DataFrame with a boolean expression."], "pandas.DataFrame.query": ["Query the columns of a DataFrame with a boolean expression."], "DataFrame.add": ["Get Addition of dataframe and other, element-wise (binary operator <cite>add</cite>)."], "pandas.DataFrame.add": ["Get Addition of dataframe and other, element-wise (binary operator <cite>add</cite>)."], "DataFrame.sub": ["Get Subtraction of dataframe and other, element-wise (binary operator <cite>sub</cite>)."], "pandas.DataFrame.sub": ["Get Subtraction of dataframe and other, element-wise (binary operator <cite>sub</cite>)."], "DataFrame.mul": ["Get Multiplication of dataframe and other, element-wise (binary operator <cite>mul</cite>)."], "pandas.DataFrame.mul": ["Get Multiplication of dataframe and other, element-wise (binary operator <cite>mul</cite>)."], "DataFrame.div": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "pandas.DataFrame.div": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "DataFrame.truediv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "pandas.DataFrame.truediv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>truediv</cite>)."], "DataFrame.floordiv": ["Get Integer division of dataframe and other, element-wise (binary operator <cite>floordiv</cite>)."], "pandas.DataFrame.floordiv": ["Get Integer division of dataframe and other, element-wise (binary operator <cite>floordiv</cite>)."], "DataFrame.mod": ["Get Modulo of dataframe and other, element-wise (binary operator <cite>mod</cite>)."], "pandas.DataFrame.mod": ["Get Modulo of dataframe and other, element-wise (binary operator <cite>mod</cite>)."], "DataFrame.pow": ["Get Exponential power of dataframe and other, element-wise (binary operator <cite>pow</cite>)."], "pandas.DataFrame.pow": ["Get Exponential power of dataframe and other, element-wise (binary operator <cite>pow</cite>)."], "DataFrame.dot": ["Compute the matrix multiplication between the DataFrame and other."], "pandas.DataFrame.dot": ["Compute the matrix multiplication between the DataFrame and other."], "DataFrame.radd": ["Get Addition of dataframe and other, element-wise (binary operator <cite>radd</cite>)."], "pandas.DataFrame.radd": ["Get Addition of dataframe and other, element-wise (binary operator <cite>radd</cite>)."], "DataFrame.rsub": ["Get Subtraction of dataframe and other, element-wise (binary operator <cite>rsub</cite>)."], "pandas.DataFrame.rsub": ["Get Subtraction of dataframe and other, element-wise (binary operator <cite>rsub</cite>)."], "DataFrame.rmul": ["Get Multiplication of dataframe and other, element-wise (binary operator <cite>rmul</cite>)."], "pandas.DataFrame.rmul": ["Get Multiplication of dataframe and other, element-wise (binary operator <cite>rmul</cite>)."], "DataFrame.rdiv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "pandas.DataFrame.rdiv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "DataFrame.rtruediv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "pandas.DataFrame.rtruediv": ["Get Floating division of dataframe and other, element-wise (binary operator <cite>rtruediv</cite>)."], "DataFrame.rfloordiv": ["Get Integer division of dataframe and other, element-wise (binary operator <cite>rfloordiv</cite>)."], "pandas.DataFrame.rfloordiv": ["Get Integer division of dataframe and other, element-wise (binary operator <cite>rfloordiv</cite>)."], "DataFrame.rmod": ["Get Modulo of dataframe and other, element-wise (binary operator <cite>rmod</cite>)."], "pandas.DataFrame.rmod": ["Get Modulo of dataframe and other, element-wise (binary operator <cite>rmod</cite>)."], "DataFrame.rpow": ["Get Exponential power of dataframe and other, element-wise (binary operator <cite>rpow</cite>)."], "pandas.DataFrame.rpow": ["Get Exponential power of dataframe and other, element-wise (binary operator <cite>rpow</cite>)."], "DataFrame.lt": ["Get Less than of dataframe and other, element-wise (binary operator <cite>lt</cite>)."], "pandas.DataFrame.lt": ["Get Less than of dataframe and other, element-wise (binary operator <cite>lt</cite>)."], "DataFrame.gt": ["Get Greater than of dataframe and other, element-wise (binary operator <cite>gt</cite>)."], "pandas.DataFrame.gt": ["Get Greater than of dataframe and other, element-wise (binary operator <cite>gt</cite>)."], "DataFrame.le": ["Get Less than or equal to of dataframe and other, element-wise (binary operator <cite>le</cite>)."], "pandas.DataFrame.le": ["Get Less than or equal to of dataframe and other, element-wise (binary operator <cite>le</cite>)."], "DataFrame.ge": ["Get Greater than or equal to of dataframe and other, element-wise (binary operator <cite>ge</cite>)."], "pandas.DataFrame.ge": ["Get Greater than or equal to of dataframe and other, element-wise (binary operator <cite>ge</cite>)."], "DataFrame.ne": ["Get Not equal to of dataframe and other, element-wise (binary operator <cite>ne</cite>)."], "pandas.DataFrame.ne": ["Get Not equal to of dataframe and other, element-wise (binary operator <cite>ne</cite>)."], "DataFrame.eq": ["Get Equal to of dataframe and other, element-wise (binary operator <cite>eq</cite>)."], "pandas.DataFrame.eq": ["Get Equal to of dataframe and other, element-wise (binary operator <cite>eq</cite>)."], "DataFrame.combine": ["Perform column-wise combine with another DataFrame."], "pandas.DataFrame.combine": ["Perform column-wise combine with another DataFrame."], "DataFrame.combine_first": ["Update null elements with value in the same location in <cite>other</cite>."], "pandas.DataFrame.combine_first": ["Update null elements with value in the same location in <cite>other</cite>."], "DataFrame.apply": ["Apply a function along an axis of the DataFrame."], "pandas.DataFrame.apply": ["Apply a function along an axis of the DataFrame."], "applymap": ["Apply a function to a Dataframe elementwise.", "Apply a CSS-styling function elementwise."], "DataFrame.applymap": ["Apply a function to a Dataframe elementwise."], "pandas.DataFrame.applymap": ["Apply a function to a Dataframe elementwise."], "DataFrame.pipe": ["Apply chainable functions that expect Series or DataFrames."], "pandas.DataFrame.pipe": ["Apply chainable functions that expect Series or DataFrames."], "DataFrame.agg": ["Aggregate using one or more operations over the specified axis."], "pandas.DataFrame.agg": ["Aggregate using one or more operations over the specified axis."], "DataFrame.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.DataFrame.aggregate": ["Aggregate using one or more operations over the specified axis."], "DataFrame.transform": ["Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a DataFrame with the same axis shape as self."], "pandas.DataFrame.transform": ["Call <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> on self producing a DataFrame with the same axis shape as self."], "DataFrame.groupby": ["Group DataFrame using a mapper or by a Series of columns."], "pandas.DataFrame.groupby": ["Group DataFrame using a mapper or by a Series of columns."], "DataFrame.rolling": ["Provide rolling window calculations."], "pandas.DataFrame.rolling": ["Provide rolling window calculations."], "DataFrame.expanding": ["Provide expanding window calculations."], "pandas.DataFrame.expanding": ["Provide expanding window calculations."], "DataFrame.ewm": ["Provide exponentially weighted (EW) calculations."], "pandas.DataFrame.ewm": ["Provide exponentially weighted (EW) calculations."], "DataFrame.abs": ["Return a Series/DataFrame with absolute numeric value of each element."], "pandas.DataFrame.abs": ["Return a Series/DataFrame with absolute numeric value of each element."], "DataFrame.all": ["Return whether all elements are True, potentially over an axis."], "pandas.DataFrame.all": ["Return whether all elements are True, potentially over an axis."], "DataFrame.any": ["Return whether any element is True, potentially over an axis."], "pandas.DataFrame.any": ["Return whether any element is True, potentially over an axis."], "DataFrame.clip": ["Trim values at input threshold(s)."], "pandas.DataFrame.clip": ["Trim values at input threshold(s)."], "DataFrame.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "pandas.DataFrame.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "corrwith": ["Compute pairwise correlation."], "DataFrame.corrwith": ["Compute pairwise correlation."], "pandas.DataFrame.corrwith": ["Compute pairwise correlation."], "DataFrame.count": ["Count non-NA cells for each column or row."], "pandas.DataFrame.count": ["Count non-NA cells for each column or row."], "DataFrame.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "pandas.DataFrame.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "DataFrame.cummax": ["Return cumulative maximum over a DataFrame or Series axis."], "pandas.DataFrame.cummax": ["Return cumulative maximum over a DataFrame or Series axis."], "DataFrame.cummin": ["Return cumulative minimum over a DataFrame or Series axis."], "pandas.DataFrame.cummin": ["Return cumulative minimum over a DataFrame or Series axis."], "DataFrame.cumprod": ["Return cumulative product over a DataFrame or Series axis."], "pandas.DataFrame.cumprod": ["Return cumulative product over a DataFrame or Series axis."], "DataFrame.cumsum": ["Return cumulative sum over a DataFrame or Series axis."], "pandas.DataFrame.cumsum": ["Return cumulative sum over a DataFrame or Series axis."], "DataFrame.describe": ["Generate descriptive statistics."], "pandas.DataFrame.describe": ["Generate descriptive statistics."], "DataFrame.diff": ["First discrete difference of element."], "pandas.DataFrame.diff": ["First discrete difference of element."], "DataFrame.eval": ["Evaluate a string describing operations on DataFrame columns."], "pandas.DataFrame.eval": ["Evaluate a string describing operations on DataFrame columns."], "DataFrame.kurt": ["Return unbiased kurtosis over requested axis."], "pandas.DataFrame.kurt": ["Return unbiased kurtosis over requested axis."], "DataFrame.kurtosis": ["Return unbiased kurtosis over requested axis."], "pandas.DataFrame.kurtosis": ["Return unbiased kurtosis over requested axis."], "DataFrame.mad": ["Return the mean absolute deviation of the values over the requested axis."], "pandas.DataFrame.mad": ["Return the mean absolute deviation of the values over the requested axis."], "DataFrame.max": ["Return the maximum of the values over the requested axis."], "pandas.DataFrame.max": ["Return the maximum of the values over the requested axis."], "DataFrame.mean": ["Return the mean of the values over the requested axis."], "pandas.DataFrame.mean": ["Return the mean of the values over the requested axis."], "DataFrame.median": ["Return the median of the values over the requested axis."], "pandas.DataFrame.median": ["Return the median of the values over the requested axis."], "DataFrame.min": ["Return the minimum of the values over the requested axis."], "pandas.DataFrame.min": ["Return the minimum of the values over the requested axis."], "DataFrame.mode": ["Get the mode(s) of each element along the selected axis."], "pandas.DataFrame.mode": ["Get the mode(s) of each element along the selected axis."], "DataFrame.pct_change": ["Percentage change between the current and a prior element."], "pandas.DataFrame.pct_change": ["Percentage change between the current and a prior element."], "DataFrame.prod": ["Return the product of the values over the requested axis."], "pandas.DataFrame.prod": ["Return the product of the values over the requested axis."], "DataFrame.product": ["Return the product of the values over the requested axis."], "pandas.DataFrame.product": ["Return the product of the values over the requested axis."], "DataFrame.quantile": ["Return values at the given quantile over requested axis."], "pandas.DataFrame.quantile": ["Return values at the given quantile over requested axis."], "DataFrame.rank": ["Compute numerical data ranks (1 through n) along axis."], "pandas.DataFrame.rank": ["Compute numerical data ranks (1 through n) along axis."], "DataFrame.round": ["Round a DataFrame to a variable number of decimal places."], "pandas.DataFrame.round": ["Round a DataFrame to a variable number of decimal places."], "DataFrame.sem": ["Return unbiased standard error of the mean over requested axis."], "pandas.DataFrame.sem": ["Return unbiased standard error of the mean over requested axis."], "DataFrame.skew": ["Return unbiased skew over requested axis."], "pandas.DataFrame.skew": ["Return unbiased skew over requested axis."], "DataFrame.sum": ["Return the sum of the values over the requested axis."], "pandas.DataFrame.sum": ["Return the sum of the values over the requested axis."], "DataFrame.std": ["Return sample standard deviation over requested axis."], "pandas.DataFrame.std": ["Return sample standard deviation over requested axis."], "DataFrame.var": ["Return unbiased variance over requested axis."], "pandas.DataFrame.var": ["Return unbiased variance over requested axis."], "DataFrame.nunique": ["Count number of distinct elements in specified axis."], "pandas.DataFrame.nunique": ["Count number of distinct elements in specified axis."], "DataFrame.value_counts": ["Return a Series containing counts of unique rows in the DataFrame."], "pandas.DataFrame.value_counts": ["Return a Series containing counts of unique rows in the DataFrame."], "DataFrame.add_prefix": ["Prefix labels with string <cite>prefix</cite>."], "pandas.DataFrame.add_prefix": ["Prefix labels with string <cite>prefix</cite>."], "DataFrame.add_suffix": ["Suffix labels with string <cite>suffix</cite>."], "pandas.DataFrame.add_suffix": ["Suffix labels with string <cite>suffix</cite>."], "DataFrame.align": ["Align two objects on their axes with the specified join method."], "pandas.DataFrame.align": ["Align two objects on their axes with the specified join method."], "DataFrame.at_time": ["Select values at particular time of day (e.g., 9:30AM)."], "pandas.DataFrame.at_time": ["Select values at particular time of day (e.g., 9:30AM)."], "DataFrame.between_time": ["Select values between particular times of the day (e.g., 9:00-9:30 AM)."], "pandas.DataFrame.between_time": ["Select values between particular times of the day (e.g., 9:00-9:30 AM)."], "DataFrame.drop": ["Drop specified labels from rows or columns."], "pandas.DataFrame.drop": ["Drop specified labels from rows or columns."], "DataFrame.drop_duplicates": ["Return DataFrame with duplicate rows removed."], "pandas.DataFrame.drop_duplicates": ["Return DataFrame with duplicate rows removed."], "DataFrame.duplicated": ["Return boolean Series denoting duplicate rows."], "pandas.DataFrame.duplicated": ["Return boolean Series denoting duplicate rows."], "DataFrame.equals": ["Test whether two objects contain the same elements."], "pandas.DataFrame.equals": ["Test whether two objects contain the same elements."], "DataFrame.filter": ["Subset the dataframe rows or columns according to the specified index labels."], "pandas.DataFrame.filter": ["Subset the dataframe rows or columns according to the specified index labels."], "DataFrame.first": ["Select initial periods of time series data based on a date offset."], "pandas.DataFrame.first": ["Select initial periods of time series data based on a date offset."], "DataFrame.idxmax": ["Return index of first occurrence of maximum over requested axis."], "pandas.DataFrame.idxmax": ["Return index of first occurrence of maximum over requested axis."], "DataFrame.idxmin": ["Return index of first occurrence of minimum over requested axis."], "pandas.DataFrame.idxmin": ["Return index of first occurrence of minimum over requested axis."], "DataFrame.last": ["Select final periods of time series data based on a date offset."], "pandas.DataFrame.last": ["Select final periods of time series data based on a date offset."], "DataFrame.reindex": ["Conform Series/DataFrame to new index with optional filling logic."], "pandas.DataFrame.reindex": ["Conform Series/DataFrame to new index with optional filling logic."], "DataFrame.reindex_like": ["Return an object with matching indices as other object."], "pandas.DataFrame.reindex_like": ["Return an object with matching indices as other object."], "DataFrame.rename": ["Alter axes labels."], "pandas.DataFrame.rename": ["Alter axes labels."], "DataFrame.rename_axis": ["Set the name of the axis for the index or columns."], "pandas.DataFrame.rename_axis": ["Set the name of the axis for the index or columns."], "DataFrame.reset_index": ["Reset the index, or a level of it."], "pandas.DataFrame.reset_index": ["Reset the index, or a level of it."], "DataFrame.sample": ["Return a random sample of items from an axis of object."], "pandas.DataFrame.sample": ["Return a random sample of items from an axis of object."], "DataFrame.set_axis": ["Assign desired index to given axis."], "pandas.DataFrame.set_axis": ["Assign desired index to given axis."], "set_index": ["Set the DataFrame index using existing columns."], "DataFrame.set_index": ["Set the DataFrame index using existing columns."], "pandas.DataFrame.set_index": ["Set the DataFrame index using existing columns."], "DataFrame.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "pandas.DataFrame.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "DataFrame.truncate": ["Truncate a Series or DataFrame before and after some index value."], "pandas.DataFrame.truncate": ["Truncate a Series or DataFrame before and after some index value."], "DataFrame.backfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "pandas.DataFrame.backfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "DataFrame.bfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "pandas.DataFrame.bfill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='bfill'</span></code>."], "DataFrame.dropna": ["Remove missing values."], "pandas.DataFrame.dropna": ["Remove missing values."], "DataFrame.ffill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "pandas.DataFrame.ffill": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "DataFrame.fillna": ["Fill NA/NaN values using the specified method."], "pandas.DataFrame.fillna": ["Fill NA/NaN values using the specified method."], "DataFrame.interpolate": ["Fill NaN values using an interpolation method."], "pandas.DataFrame.interpolate": ["Fill NaN values using an interpolation method."], "DataFrame.isna": ["Detect missing values."], "pandas.DataFrame.isna": ["Detect missing values."], "DataFrame.isnull": ["DataFrame.isnull is an alias for DataFrame.isna."], "pandas.DataFrame.isnull": ["DataFrame.isnull is an alias for DataFrame.isna."], "DataFrame.notna": ["Detect existing (non-missing) values."], "pandas.DataFrame.notna": ["Detect existing (non-missing) values."], "DataFrame.notnull": ["DataFrame.notnull is an alias for DataFrame.notna."], "pandas.DataFrame.notnull": ["DataFrame.notnull is an alias for DataFrame.notna."], "DataFrame.pad": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "pandas.DataFrame.pad": ["Synonym for <a class=\"reference internal\" href=\"api/pandas.DataFrame.fillna.html#pandas.DataFrame.fillna\" title=\"pandas.DataFrame.fillna\"><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">DataFrame.fillna()</span></code></a> with <code class=\"docutils literal notranslate\"><span class=\"pre\">method='ffill'</span></code>."], "DataFrame.replace": ["Replace values given in <cite>to_replace</cite> with <cite>value</cite>."], "pandas.DataFrame.replace": ["Replace values given in <cite>to_replace</cite> with <cite>value</cite>."], "DataFrame.droplevel": ["Return Series/DataFrame with requested index / column level(s) removed."], "pandas.DataFrame.droplevel": ["Return Series/DataFrame with requested index / column level(s) removed."], "DataFrame.pivot": ["Return reshaped DataFrame organized by given index / column values."], "pandas.DataFrame.pivot": ["Return reshaped DataFrame organized by given index / column values."], "DataFrame.pivot_table": ["Create a spreadsheet-style pivot table as a DataFrame."], "pandas.DataFrame.pivot_table": ["Create a spreadsheet-style pivot table as a DataFrame."], "DataFrame.reorder_levels": ["Rearrange index levels using input order."], "pandas.DataFrame.reorder_levels": ["Rearrange index levels using input order."], "DataFrame.sort_values": ["Sort by the values along either axis."], "pandas.DataFrame.sort_values": ["Sort by the values along either axis."], "DataFrame.sort_index": ["Sort object by labels (along an axis)."], "pandas.DataFrame.sort_index": ["Sort object by labels (along an axis)."], "DataFrame.nlargest": ["Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in descending order."], "pandas.DataFrame.nlargest": ["Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in descending order."], "DataFrame.nsmallest": ["Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in ascending order."], "pandas.DataFrame.nsmallest": ["Return the first <cite>n</cite> rows ordered by <cite>columns</cite> in ascending order."], "DataFrame.swaplevel": ["Swap levels i and j in a <a class=\"reference internal\" href=\"api/pandas.MultiIndex.html#pandas.MultiIndex\" title=\"pandas.MultiIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultiIndex</span></code></a>."], "pandas.DataFrame.swaplevel": ["Swap levels i and j in a <a class=\"reference internal\" href=\"api/pandas.MultiIndex.html#pandas.MultiIndex\" title=\"pandas.MultiIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultiIndex</span></code></a>."], "stack": ["Stack the prescribed level(s) from columns to index.", "Join a sequence of arrays along a new axis."], "DataFrame.stack": ["Stack the prescribed level(s) from columns to index."], "pandas.DataFrame.stack": ["Stack the prescribed level(s) from columns to index."], "DataFrame.unstack": ["Pivot a level of the (necessarily hierarchical) index labels."], "pandas.DataFrame.unstack": ["Pivot a level of the (necessarily hierarchical) index labels."], "swapaxes": ["Interchange axes and swap values axes appropriately.", "Return a view of the array with <em class=\"xref py py-obj\">axis1</em> and <em class=\"xref py py-obj\">axis2</em> interchanged.", "Interchange two axes of an array."], "DataFrame.swapaxes": ["Interchange axes and swap values axes appropriately."], "pandas.DataFrame.swapaxes": ["Interchange axes and swap values axes appropriately."], "DataFrame.melt": ["Unpivot a DataFrame from wide to long format, optionally leaving identifiers set."], "pandas.DataFrame.melt": ["Unpivot a DataFrame from wide to long format, optionally leaving identifiers set."], "DataFrame.explode": ["Transform each element of a list-like to a row, replicating index values."], "pandas.DataFrame.explode": ["Transform each element of a list-like to a row, replicating index values."], "DataFrame.squeeze": ["Squeeze 1 dimensional axis objects into scalars."], "pandas.DataFrame.squeeze": ["Squeeze 1 dimensional axis objects into scalars."], "DataFrame.to_xarray": ["Return an xarray object from the pandas object."], "pandas.DataFrame.to_xarray": ["Return an xarray object from the pandas object."], "DataFrame.T": [""], "pandas.DataFrame.T": [""], "transpose": ["Transpose index and columns.", "Returns a view of the array with axes transposed.", "Reverse or permute the axes of an array; returns the modified array."], "DataFrame.transpose": ["Transpose index and columns."], "pandas.DataFrame.transpose": ["Transpose index and columns."], "DataFrame.append": ["(DEPRECATED) Append rows of <cite>other</cite> to the end of caller, returning a new object."], "pandas.DataFrame.append": ["(DEPRECATED) Append rows of <cite>other</cite> to the end of caller, returning a new object."], "assign": ["Assign new columns to a DataFrame."], "DataFrame.assign": ["Assign new columns to a DataFrame."], "pandas.DataFrame.assign": ["Assign new columns to a DataFrame."], "DataFrame.compare": ["Compare to another DataFrame and show the differences."], "pandas.DataFrame.compare": ["Compare to another DataFrame and show the differences."], "DataFrame.join": ["Join columns of another DataFrame."], "pandas.DataFrame.join": ["Join columns of another DataFrame."], "DataFrame.merge": ["Merge DataFrame or named Series objects with a database-style join."], "pandas.DataFrame.merge": ["Merge DataFrame or named Series objects with a database-style join."], "DataFrame.update": ["Modify in place using non-NA values from another DataFrame."], "pandas.DataFrame.update": ["Modify in place using non-NA values from another DataFrame."], "DataFrame.asfreq": ["Convert time series to specified frequency."], "pandas.DataFrame.asfreq": ["Convert time series to specified frequency."], "DataFrame.asof": ["Return the last row(s) without any NaNs before <cite>where</cite>."], "pandas.DataFrame.asof": ["Return the last row(s) without any NaNs before <cite>where</cite>."], "DataFrame.shift": ["Shift index by desired number of periods with an optional time <cite>freq</cite>."], "pandas.DataFrame.shift": ["Shift index by desired number of periods with an optional time <cite>freq</cite>."], "DataFrame.slice_shift": ["(DEPRECATED) Equivalent to <cite>shift</cite> without copying data."], "pandas.DataFrame.slice_shift": ["(DEPRECATED) Equivalent to <cite>shift</cite> without copying data."], "DataFrame.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "pandas.DataFrame.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "DataFrame.first_valid_index": ["Return index for first non-NA value or None, if no non-NA value is found."], "pandas.DataFrame.first_valid_index": ["Return index for first non-NA value or None, if no non-NA value is found."], "DataFrame.last_valid_index": ["Return index for last non-NA value or None, if no non-NA value is found."], "pandas.DataFrame.last_valid_index": ["Return index for last non-NA value or None, if no non-NA value is found."], "DataFrame.resample": ["Resample time-series data."], "pandas.DataFrame.resample": ["Resample time-series data."], "DataFrame.to_period": ["Convert DataFrame from DatetimeIndex to PeriodIndex."], "pandas.DataFrame.to_period": ["Convert DataFrame from DatetimeIndex to PeriodIndex."], "DataFrame.to_timestamp": ["Cast to DatetimeIndex of timestamps, at <em>beginning</em> of period."], "pandas.DataFrame.to_timestamp": ["Cast to DatetimeIndex of timestamps, at <em>beginning</em> of period."], "DataFrame.tz_convert": ["Convert tz-aware axis to target time zone."], "pandas.DataFrame.tz_convert": ["Convert tz-aware axis to target time zone."], "DataFrame.tz_localize": ["Localize tz-naive index of a Series or DataFrame to target time zone."], "pandas.DataFrame.tz_localize": ["Localize tz-naive index of a Series or DataFrame to target time zone."], "DataFrame.attrs": ["Dictionary of global attributes of this dataset."], "pandas.DataFrame.attrs": ["Dictionary of global attributes of this dataset."], "DataFrame.plot": ["DataFrame plotting accessor and method"], "pandas.DataFrame.plot": ["DataFrame plotting accessor and method"], "DataFrame.plot.area": ["Draw a stacked area plot."], "pandas.DataFrame.plot.area": ["Draw a stacked area plot."], "DataFrame.plot.bar": ["Vertical bar plot."], "pandas.DataFrame.plot.bar": ["Vertical bar plot."], "DataFrame.plot.barh": ["Make a horizontal bar plot."], "pandas.DataFrame.plot.barh": ["Make a horizontal bar plot."], "DataFrame.plot.box": ["Make a box plot of the DataFrame columns."], "pandas.DataFrame.plot.box": ["Make a box plot of the DataFrame columns."], "DataFrame.plot.density": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "pandas.DataFrame.plot.density": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "hexbin": ["Generate a hexagonal binning plot."], "plot.hexbin": ["Generate a hexagonal binning plot."], "DataFrame.plot.hexbin": ["Generate a hexagonal binning plot."], "pandas.DataFrame.plot.hexbin": ["Generate a hexagonal binning plot."], "DataFrame.plot.hist": ["Draw one histogram of the DataFrame's columns."], "pandas.DataFrame.plot.hist": ["Draw one histogram of the DataFrame's columns."], "DataFrame.plot.kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "pandas.DataFrame.plot.kde": ["Generate Kernel Density Estimate plot using Gaussian kernels."], "DataFrame.plot.line": ["Plot Series or DataFrame as lines."], "pandas.DataFrame.plot.line": ["Plot Series or DataFrame as lines."], "DataFrame.plot.pie": ["Generate a pie plot."], "pandas.DataFrame.plot.pie": ["Generate a pie plot."], "scatter": ["Create a scatter plot with varying marker point size and color."], "plot.scatter": ["Create a scatter plot with varying marker point size and color."], "DataFrame.plot.scatter": ["Create a scatter plot with varying marker point size and color."], "pandas.DataFrame.plot.scatter": ["Create a scatter plot with varying marker point size and color."], "boxplot": ["Make a box plot from DataFrame columns.", "Make box plots from DataFrameGroupBy data."], "DataFrame.boxplot": ["Make a box plot from DataFrame columns."], "pandas.DataFrame.boxplot": ["Make a box plot from DataFrame columns."], "DataFrame.hist": ["Make a histogram of the DataFrame's columns."], "pandas.DataFrame.hist": ["Make a histogram of the DataFrame's columns."], "DataFrame.sparse.density": ["Ratio of non-sparse points to total (dense) data points."], "pandas.DataFrame.sparse.density": ["Ratio of non-sparse points to total (dense) data points."], "from_spmatrix": ["Create a new DataFrame from a scipy sparse matrix."], "sparse.from_spmatrix": ["Create a new DataFrame from a scipy sparse matrix."], "DataFrame.sparse.from_spmatrix": ["Create a new DataFrame from a scipy sparse matrix."], "pandas.DataFrame.sparse.from_spmatrix": ["Create a new DataFrame from a scipy sparse matrix."], "DataFrame.sparse.to_coo": ["Return the contents of the frame as a sparse SciPy COO matrix."], "pandas.DataFrame.sparse.to_coo": ["Return the contents of the frame as a sparse SciPy COO matrix."], "to_dense": ["Convert a DataFrame with sparse values to dense."], "sparse.to_dense": ["Convert a DataFrame with sparse values to dense."], "DataFrame.sparse.to_dense": ["Convert a DataFrame with sparse values to dense."], "pandas.DataFrame.sparse.to_dense": ["Convert a DataFrame with sparse values to dense."], "from_dict": ["Construct DataFrame from dict of array-like or dicts."], "DataFrame.from_dict": ["Construct DataFrame from dict of array-like or dicts."], "pandas.DataFrame.from_dict": ["Construct DataFrame from dict of array-like or dicts."], "from_records": ["Convert structured or record ndarray to DataFrame."], "DataFrame.from_records": ["Convert structured or record ndarray to DataFrame."], "pandas.DataFrame.from_records": ["Convert structured or record ndarray to DataFrame."], "DataFrame.to_hdf": ["Write the contained data to an HDF5 file using HDFStore."], "pandas.DataFrame.to_hdf": ["Write the contained data to an HDF5 file using HDFStore."], "DataFrame.to_dict": ["Convert the DataFrame to a dictionary."], "pandas.DataFrame.to_dict": ["Convert the DataFrame to a dictionary."], "to_gbq": ["Write a DataFrame to a Google BigQuery table."], "DataFrame.to_gbq": ["Write a DataFrame to a Google BigQuery table."], "pandas.DataFrame.to_gbq": ["Write a DataFrame to a Google BigQuery table."], "to_records": ["Convert DataFrame to a NumPy record array."], "DataFrame.to_records": ["Convert DataFrame to a NumPy record array."], "pandas.DataFrame.to_records": ["Convert DataFrame to a NumPy record array."], "DataFrame.to_string": ["Render a DataFrame to a console-friendly tabular output."], "pandas.DataFrame.to_string": ["Render a DataFrame to a console-friendly tabular output."], "DataFrame.to_markdown": ["Print DataFrame in Markdown-friendly format."], "pandas.DataFrame.to_markdown": ["Print DataFrame in Markdown-friendly format."], "style": ["Returns a Styler object."], "DataFrame.style": ["Returns a Styler object."], "pandas.DataFrame.style": ["Returns a Styler object."], "DatetimeTZDtype": ["a class=\"reference internal\" href=\"api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype\" title=\"pandas.DatetimeTZDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeTZDtype</span></code></a", "An ExtensionDtype for timezone-aware datetime data."], "pandas.DatetimeTZDtype": ["a class=\"reference internal\" href=\"api/pandas.DatetimeTZDtype.html#pandas.DatetimeTZDtype\" title=\"pandas.DatetimeTZDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeTZDtype</span></code></a", "An ExtensionDtype for timezone-aware datetime data."], "Timedelta": ["(none)", "Represents a duration, the difference between two dates or times."], "pandas.Timedelta": ["(none)", "Represents a duration, the difference between two dates or times."], "PeriodDtype": ["a class=\"reference internal\" href=\"api/pandas.PeriodDtype.html#pandas.PeriodDtype\" title=\"pandas.PeriodDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">PeriodDtype</span></code></a", "An ExtensionDtype for Period data."], "pandas.PeriodDtype": ["a class=\"reference internal\" href=\"api/pandas.PeriodDtype.html#pandas.PeriodDtype\" title=\"pandas.PeriodDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">PeriodDtype</span></code></a", "An ExtensionDtype for Period data."], "IntervalDtype": ["a class=\"reference internal\" href=\"api/pandas.IntervalDtype.html#pandas.IntervalDtype\" title=\"pandas.IntervalDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">IntervalDtype</span></code></a", "An ExtensionDtype for Interval data."], "pandas.IntervalDtype": ["a class=\"reference internal\" href=\"api/pandas.IntervalDtype.html#pandas.IntervalDtype\" title=\"pandas.IntervalDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">IntervalDtype</span></code></a", "An ExtensionDtype for Interval data."], "Int64Dtype": ["a class=\"reference internal\" href=\"api/pandas.Int64Dtype.html#pandas.Int64Dtype\" title=\"pandas.Int64Dtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Int64Dtype</span></code></a>, \u2026", "An ExtensionDtype for int64 integer data."], "pandas.Int64Dtype": ["a class=\"reference internal\" href=\"api/pandas.Int64Dtype.html#pandas.Int64Dtype\" title=\"pandas.Int64Dtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Int64Dtype</span></code></a>, \u2026", "An ExtensionDtype for int64 integer data."], "CategoricalDtype": ["a class=\"reference internal\" href=\"api/pandas.CategoricalDtype.html#pandas.CategoricalDtype\" title=\"pandas.CategoricalDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">CategoricalDtype</span></code></a", "Type for categorical data with the categories and orderedness."], "pandas.CategoricalDtype": ["a class=\"reference internal\" href=\"api/pandas.CategoricalDtype.html#pandas.CategoricalDtype\" title=\"pandas.CategoricalDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">CategoricalDtype</span></code></a", "Type for categorical data with the categories and orderedness."], "SparseDtype": ["a class=\"reference internal\" href=\"api/pandas.SparseDtype.html#pandas.SparseDtype\" title=\"pandas.SparseDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SparseDtype</span></code></a", "Dtype for data stored in <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SparseArray</span></code>."], "pandas.SparseDtype": ["a class=\"reference internal\" href=\"api/pandas.SparseDtype.html#pandas.SparseDtype\" title=\"pandas.SparseDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SparseDtype</span></code></a", "Dtype for data stored in <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SparseArray</span></code>."], "StringDtype": ["a class=\"reference internal\" href=\"api/pandas.StringDtype.html#pandas.StringDtype\" title=\"pandas.StringDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">StringDtype</span></code></a", "Extension dtype for string data."], "pandas.StringDtype": ["a class=\"reference internal\" href=\"api/pandas.StringDtype.html#pandas.StringDtype\" title=\"pandas.StringDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">StringDtype</span></code></a", "Extension dtype for string data."], "BooleanDtype": ["a class=\"reference internal\" href=\"api/pandas.BooleanDtype.html#pandas.BooleanDtype\" title=\"pandas.BooleanDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">BooleanDtype</span></code></a", "Extension dtype for boolean data."], "pandas.BooleanDtype": ["a class=\"reference internal\" href=\"api/pandas.BooleanDtype.html#pandas.BooleanDtype\" title=\"pandas.BooleanDtype\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">BooleanDtype</span></code></a", "Extension dtype for boolean data."], "pandas.array": ["Create an array."], "Timestamp": ["Pandas replacement for python datetime.datetime object."], "pandas.Timestamp": ["Pandas replacement for python datetime.datetime object."], "asm8": ["Return numpy datetime64 format in nanoseconds.", "Return a numpy timedelta64 array scalar view."], "Timestamp.asm8": ["Return numpy datetime64 format in nanoseconds."], "pandas.Timestamp.asm8": ["Return numpy datetime64 format in nanoseconds."], "Timestamp.day": [""], "pandas.Timestamp.day": [""], "Timestamp.dayofweek": ["Return day of the week."], "pandas.Timestamp.dayofweek": ["Return day of the week."], "Timestamp.day_of_week": ["Return day of the week."], "pandas.Timestamp.day_of_week": ["Return day of the week."], "Timestamp.dayofyear": ["Return the day of the year."], "pandas.Timestamp.dayofyear": ["Return the day of the year."], "Timestamp.day_of_year": ["Return the day of the year."], "pandas.Timestamp.day_of_year": ["Return the day of the year."], "Timestamp.days_in_month": ["Return the number of days in the month."], "pandas.Timestamp.days_in_month": ["Return the number of days in the month."], "Timestamp.daysinmonth": ["Return the number of days in the month."], "pandas.Timestamp.daysinmonth": ["Return the number of days in the month."], "fold": [""], "Timestamp.fold": [""], "pandas.Timestamp.fold": [""], "Timestamp.hour": [""], "pandas.Timestamp.hour": [""], "Timestamp.is_leap_year": ["Return True if year is a leap year."], "pandas.Timestamp.is_leap_year": ["Return True if year is a leap year."], "Timestamp.is_month_end": ["Return True if date is last day of month."], "pandas.Timestamp.is_month_end": ["Return True if date is last day of month."], "Timestamp.is_month_start": ["Return True if date is first day of month."], "pandas.Timestamp.is_month_start": ["Return True if date is first day of month."], "Timestamp.is_quarter_end": ["Return True if date is last day of the quarter."], "pandas.Timestamp.is_quarter_end": ["Return True if date is last day of the quarter."], "Timestamp.is_quarter_start": ["Return True if date is first day of the quarter."], "pandas.Timestamp.is_quarter_start": ["Return True if date is first day of the quarter."], "Timestamp.is_year_end": ["Return True if date is last day of the year."], "pandas.Timestamp.is_year_end": ["Return True if date is last day of the year."], "Timestamp.is_year_start": ["Return True if date is first day of the year."], "pandas.Timestamp.is_year_start": ["Return True if date is first day of the year."], "Timestamp.max": [""], "pandas.Timestamp.max": [""], "Timestamp.microsecond": [""], "pandas.Timestamp.microsecond": [""], "Timestamp.min": [""], "pandas.Timestamp.min": [""], "Timestamp.minute": [""], "pandas.Timestamp.minute": [""], "Timestamp.month": [""], "pandas.Timestamp.month": [""], "Timestamp.nanosecond": [""], "pandas.Timestamp.nanosecond": [""], "Timestamp.quarter": ["Return the quarter of the year."], "pandas.Timestamp.quarter": ["Return the quarter of the year."], "resolution": [""], "Timestamp.resolution": [""], "pandas.Timestamp.resolution": [""], "Timestamp.second": [""], "pandas.Timestamp.second": [""], "Timestamp.tz": ["Alias for tzinfo."], "pandas.Timestamp.tz": ["Alias for tzinfo."], "tzinfo": [""], "Timestamp.tzinfo": [""], "pandas.Timestamp.tzinfo": [""], "value": [""], "Timestamp.value": [""], "pandas.Timestamp.value": [""], "Timestamp.week": ["Return the week number of the year."], "pandas.Timestamp.week": ["Return the week number of the year."], "Timestamp.weekofyear": ["Return the week number of the year."], "pandas.Timestamp.weekofyear": ["Return the week number of the year."], "Timestamp.year": [""], "pandas.Timestamp.year": [""], "astimezone": ["Convert timezone-aware Timestamp to another time zone."], "Timestamp.astimezone": ["Convert timezone-aware Timestamp to another time zone."], "pandas.Timestamp.astimezone": ["Convert timezone-aware Timestamp to another time zone."], "Timestamp.ceil": ["Return a new Timestamp ceiled to this resolution."], "pandas.Timestamp.ceil": ["Return a new Timestamp ceiled to this resolution."], "Timestamp.combine": ["Combine date, time into datetime with same date and time fields."], "pandas.Timestamp.combine": ["Combine date, time into datetime with same date and time fields."], "ctime": ["Return ctime() style string."], "Timestamp.ctime": ["Return ctime() style string."], "pandas.Timestamp.ctime": ["Return ctime() style string."], "Timestamp.date": ["Return date object with same year, month and day."], "pandas.Timestamp.date": ["Return date object with same year, month and day."], "Timestamp.day_name": ["Return the day name of the Timestamp with specified locale."], "pandas.Timestamp.day_name": ["Return the day name of the Timestamp with specified locale."], "dst": ["Return self.tzinfo.dst(self)."], "Timestamp.dst": ["Return self.tzinfo.dst(self)."], "pandas.Timestamp.dst": ["Return self.tzinfo.dst(self)."], "Timestamp.floor": ["Return a new Timestamp floored to this resolution."], "pandas.Timestamp.floor": ["Return a new Timestamp floored to this resolution."], "Timestamp.freq": [""], "pandas.Timestamp.freq": [""], "freqstr": ["Return the total number of days in the month.", "Return a string representation of the frequency.", "Return the frequency object as a string if its set, otherwise None.", ""], "Timestamp.freqstr": ["Return the total number of days in the month."], "pandas.Timestamp.freqstr": ["Return the total number of days in the month."], "fromordinal": ["Passed an ordinal, translate and convert to a ts."], "Timestamp.fromordinal": ["Passed an ordinal, translate and convert to a ts."], "pandas.Timestamp.fromordinal": ["Passed an ordinal, translate and convert to a ts."], "fromtimestamp": ["Transform timestamp[, tz] to tz's local time from POSIX timestamp."], "Timestamp.fromtimestamp": ["Transform timestamp[, tz] to tz's local time from POSIX timestamp."], "pandas.Timestamp.fromtimestamp": ["Transform timestamp[, tz] to tz's local time from POSIX timestamp."], "Timestamp.isocalendar": ["Return a 3-tuple containing ISO year, week number, and weekday."], "pandas.Timestamp.isocalendar": ["Return a 3-tuple containing ISO year, week number, and weekday."], "isoformat": ["Return the time formatted according to ISO 8610.", "Format Timedelta as ISO 8601 Duration like <code class=\"docutils literal notranslate\"><span class=\"pre\">P[n]Y[n]M[n]DT[n]H[n]M[n]S</span></code>, where the <code class=\"docutils literal notranslate\"><span class=\"pre\">[n]</span></code> s are replaced by the values."], "Timestamp.isoformat": ["Return the time formatted according to ISO 8610."], "pandas.Timestamp.isoformat": ["Return the time formatted according to ISO 8610."], "isoweekday": ["Return the day of the week represented by the date."], "Timestamp.isoweekday": ["Return the day of the week represented by the date."], "pandas.Timestamp.isoweekday": ["Return the day of the week represented by the date."], "Timestamp.month_name": ["Return the month name of the Timestamp with specified locale."], "pandas.Timestamp.month_name": ["Return the month name of the Timestamp with specified locale."], "Timestamp.normalize": ["Normalize Timestamp to midnight, preserving tz information."], "pandas.Timestamp.normalize": ["Normalize Timestamp to midnight, preserving tz information."], "now": ["Return new Timestamp object representing current time local to tz.", "Return the period of now's date."], "Timestamp.now": ["Return new Timestamp object representing current time local to tz."], "pandas.Timestamp.now": ["Return new Timestamp object representing current time local to tz."], "Timestamp.replace": ["Implements datetime.replace, handles nanoseconds."], "pandas.Timestamp.replace": ["Implements datetime.replace, handles nanoseconds."], "Timestamp.round": ["Round the Timestamp to the specified resolution."], "pandas.Timestamp.round": ["Round the Timestamp to the specified resolution."], "Timestamp.strftime": ["Return a string representing the given POSIX timestamp controlled by an explicit format string."], "pandas.Timestamp.strftime": ["Return a string representing the given POSIX timestamp controlled by an explicit format string."], "strptime": ["Function is not implemented."], "Timestamp.strptime": ["Function is not implemented."], "pandas.Timestamp.strptime": ["Function is not implemented."], "Timestamp.time": ["Return time object with same time but with tzinfo=None."], "pandas.Timestamp.time": ["Return time object with same time but with tzinfo=None."], "timestamp": ["Return POSIX timestamp as float."], "Timestamp.timestamp": ["Return POSIX timestamp as float."], "pandas.Timestamp.timestamp": ["Return POSIX timestamp as float."], "timetuple": ["Return time tuple, compatible with time.localtime()."], "Timestamp.timetuple": ["Return time tuple, compatible with time.localtime()."], "pandas.Timestamp.timetuple": ["Return time tuple, compatible with time.localtime()."], "Timestamp.timetz": ["Return time object with same time and tzinfo."], "pandas.Timestamp.timetz": ["Return time object with same time and tzinfo."], "to_datetime64": ["Return a numpy.datetime64 object with 'ns' precision."], "Timestamp.to_datetime64": ["Return a numpy.datetime64 object with 'ns' precision."], "pandas.Timestamp.to_datetime64": ["Return a numpy.datetime64 object with 'ns' precision."], "Timestamp.to_numpy": ["Convert the Timestamp to a NumPy datetime64."], "pandas.Timestamp.to_numpy": ["Convert the Timestamp to a NumPy datetime64."], "to_julian_date": ["Convert TimeStamp to a Julian Date."], "Timestamp.to_julian_date": ["Convert TimeStamp to a Julian Date."], "pandas.Timestamp.to_julian_date": ["Convert TimeStamp to a Julian Date."], "Timestamp.to_period": ["Return an period of which this timestamp is an observation."], "pandas.Timestamp.to_period": ["Return an period of which this timestamp is an observation."], "Timestamp.to_pydatetime": ["Convert a Timestamp object to a native Python datetime object."], "pandas.Timestamp.to_pydatetime": ["Convert a Timestamp object to a native Python datetime object."], "today": ["Return the current time in the local timezone."], "Timestamp.today": ["Return the current time in the local timezone."], "pandas.Timestamp.today": ["Return the current time in the local timezone."], "toordinal": ["Return proleptic Gregorian ordinal."], "Timestamp.toordinal": ["Return proleptic Gregorian ordinal."], "pandas.Timestamp.toordinal": ["Return proleptic Gregorian ordinal."], "Timestamp.tz_convert": ["Convert timezone-aware Timestamp to another time zone."], "pandas.Timestamp.tz_convert": ["Convert timezone-aware Timestamp to another time zone."], "Timestamp.tz_localize": ["Convert naive Timestamp to local time zone, or remove timezone from timezone-aware Timestamp."], "pandas.Timestamp.tz_localize": ["Convert naive Timestamp to local time zone, or remove timezone from timezone-aware Timestamp."], "tzname": ["Return self.tzinfo.tzname(self)."], "Timestamp.tzname": ["Return self.tzinfo.tzname(self)."], "pandas.Timestamp.tzname": ["Return self.tzinfo.tzname(self)."], "utcfromtimestamp": ["Construct a naive UTC datetime from a POSIX timestamp."], "Timestamp.utcfromtimestamp": ["Construct a naive UTC datetime from a POSIX timestamp."], "pandas.Timestamp.utcfromtimestamp": ["Construct a naive UTC datetime from a POSIX timestamp."], "utcnow": ["Return a new Timestamp representing UTC day and time."], "Timestamp.utcnow": ["Return a new Timestamp representing UTC day and time."], "pandas.Timestamp.utcnow": ["Return a new Timestamp representing UTC day and time."], "utcoffset": ["Return self.tzinfo.utcoffset(self)."], "Timestamp.utcoffset": ["Return self.tzinfo.utcoffset(self)."], "pandas.Timestamp.utcoffset": ["Return self.tzinfo.utcoffset(self)."], "utctimetuple": ["Return UTC time tuple, compatible with time.localtime()."], "Timestamp.utctimetuple": ["Return UTC time tuple, compatible with time.localtime()."], "pandas.Timestamp.utctimetuple": ["Return UTC time tuple, compatible with time.localtime()."], "Timestamp.weekday": ["Return the day of the week represented by the date."], "pandas.Timestamp.weekday": ["Return the day of the week represented by the date."], "DatetimeArray": ["Pandas ExtensionArray for tz-naive or tz-aware datetime data."], "arrays.DatetimeArray": ["Pandas ExtensionArray for tz-naive or tz-aware datetime data."], "pandas.arrays.DatetimeArray": ["Pandas ExtensionArray for tz-naive or tz-aware datetime data."], "Timedelta.asm8": ["Return a numpy timedelta64 array scalar view."], "pandas.Timedelta.asm8": ["Return a numpy timedelta64 array scalar view."], "Timedelta.components": ["Return a components namedtuple-like."], "pandas.Timedelta.components": ["Return a components namedtuple-like."], "Timedelta.days": ["Number of days."], "pandas.Timedelta.days": ["Number of days."], "delta": ["Return the timedelta in nanoseconds (ns), for internal compatibility.", ""], "Timedelta.delta": ["Return the timedelta in nanoseconds (ns), for internal compatibility."], "pandas.Timedelta.delta": ["Return the timedelta in nanoseconds (ns), for internal compatibility."], "Timedelta.freq": [""], "pandas.Timedelta.freq": [""], "is_populated": [""], "Timedelta.is_populated": [""], "pandas.Timedelta.is_populated": [""], "Timedelta.max": [""], "pandas.Timedelta.max": [""], "Timedelta.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second)."], "pandas.Timedelta.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second)."], "Timedelta.min": [""], "pandas.Timedelta.min": [""], "Timedelta.nanoseconds": ["Return the number of nanoseconds (n), where 0 &lt;= n &lt; 1 microsecond."], "pandas.Timedelta.nanoseconds": ["Return the number of nanoseconds (n), where 0 &lt;= n &lt; 1 microsecond."], "Timedelta.resolution": [""], "pandas.Timedelta.resolution": [""], "Timedelta.seconds": ["Number of seconds (&gt;= 0 and less than 1 day)."], "pandas.Timedelta.seconds": ["Number of seconds (&gt;= 0 and less than 1 day)."], "Timedelta.value": [""], "pandas.Timedelta.value": [""], "Timedelta.view": ["Array view compatibility."], "pandas.Timedelta.view": ["Array view compatibility."], "Timedelta.ceil": ["Return a new Timedelta ceiled to this resolution."], "pandas.Timedelta.ceil": ["Return a new Timedelta ceiled to this resolution."], "Timedelta.floor": ["Return a new Timedelta floored to this resolution."], "pandas.Timedelta.floor": ["Return a new Timedelta floored to this resolution."], "Timedelta.isoformat": ["Format Timedelta as ISO 8601 Duration like <code class=\"docutils literal notranslate\"><span class=\"pre\">P[n]Y[n]M[n]DT[n]H[n]M[n]S</span></code>, where the <code class=\"docutils literal notranslate\"><span class=\"pre\">[n]</span></code> s are replaced by the values."], "pandas.Timedelta.isoformat": ["Format Timedelta as ISO 8601 Duration like <code class=\"docutils literal notranslate\"><span class=\"pre\">P[n]Y[n]M[n]DT[n]H[n]M[n]S</span></code>, where the <code class=\"docutils literal notranslate\"><span class=\"pre\">[n]</span></code> s are replaced by the values."], "Timedelta.round": ["Round the Timedelta to the specified resolution."], "pandas.Timedelta.round": ["Round the Timedelta to the specified resolution."], "Timedelta.to_pytimedelta": ["Convert a pandas Timedelta object into a python <code class=\"docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code> object."], "pandas.Timedelta.to_pytimedelta": ["Convert a pandas Timedelta object into a python <code class=\"docutils literal notranslate\"><span class=\"pre\">datetime.timedelta</span></code> object."], "to_timedelta64": ["Return a numpy.timedelta64 object with 'ns' precision."], "Timedelta.to_timedelta64": ["Return a numpy.timedelta64 object with 'ns' precision."], "pandas.Timedelta.to_timedelta64": ["Return a numpy.timedelta64 object with 'ns' precision."], "Timedelta.to_numpy": ["Convert the Timedelta to a NumPy timedelta64."], "pandas.Timedelta.to_numpy": ["Convert the Timedelta to a NumPy timedelta64."], "Timedelta.total_seconds": ["Total seconds in the duration."], "pandas.Timedelta.total_seconds": ["Total seconds in the duration."], "TimedeltaArray": ["Pandas ExtensionArray for timedelta data."], "arrays.TimedeltaArray": ["Pandas ExtensionArray for timedelta data."], "pandas.arrays.TimedeltaArray": ["Pandas ExtensionArray for timedelta data."], "Period": ["Represents a period of time."], "pandas.Period": ["Represents a period of time."], "Period.day": ["Get day of the month that a Period falls on."], "pandas.Period.day": ["Get day of the month that a Period falls on."], "Period.dayofweek": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "pandas.Period.dayofweek": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "Period.day_of_week": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "pandas.Period.day_of_week": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "Period.dayofyear": ["Return the day of the year."], "pandas.Period.dayofyear": ["Return the day of the year."], "Period.day_of_year": ["Return the day of the year."], "pandas.Period.day_of_year": ["Return the day of the year."], "Period.days_in_month": ["Get the total number of days in the month that this period falls on."], "pandas.Period.days_in_month": ["Get the total number of days in the month that this period falls on."], "Period.daysinmonth": ["Get the total number of days of the month that the Period falls in."], "pandas.Period.daysinmonth": ["Get the total number of days of the month that the Period falls in."], "Period.end_time": ["Get the Timestamp for the end of the period."], "pandas.Period.end_time": ["Get the Timestamp for the end of the period."], "Period.freq": [""], "pandas.Period.freq": [""], "Period.freqstr": ["Return a string representation of the frequency."], "pandas.Period.freqstr": ["Return a string representation of the frequency."], "Period.hour": ["Get the hour of the day component of the Period."], "pandas.Period.hour": ["Get the hour of the day component of the Period."], "Period.is_leap_year": ["Return True if the period's year is in a leap year."], "pandas.Period.is_leap_year": ["Return True if the period's year is in a leap year."], "Period.minute": ["Get minute of the hour component of the Period."], "pandas.Period.minute": ["Get minute of the hour component of the Period."], "Period.month": ["Return the month this Period falls on."], "pandas.Period.month": ["Return the month this Period falls on."], "ordinal": [""], "Period.ordinal": [""], "pandas.Period.ordinal": [""], "Period.quarter": ["Return the quarter this Period falls on."], "pandas.Period.quarter": ["Return the quarter this Period falls on."], "Period.qyear": ["Fiscal year the Period lies in according to its starting-quarter."], "pandas.Period.qyear": ["Fiscal year the Period lies in according to its starting-quarter."], "Period.second": ["Get the second component of the Period."], "pandas.Period.second": ["Get the second component of the Period."], "Period.start_time": ["Get the Timestamp for the start of the period."], "pandas.Period.start_time": ["Get the Timestamp for the start of the period."], "Period.week": ["Get the week of the year on the given Period."], "pandas.Period.week": ["Get the week of the year on the given Period."], "Period.weekday": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "pandas.Period.weekday": ["Day of the week the period lies in, with Monday=0 and Sunday=6."], "Period.weekofyear": ["Get the week of the year on the given Period."], "pandas.Period.weekofyear": ["Get the week of the year on the given Period."], "Period.year": ["Return the year this Period falls on."], "pandas.Period.year": ["Return the year this Period falls on."], "Period.asfreq": ["Convert Period to desired frequency, at the start or end of the interval."], "pandas.Period.asfreq": ["Convert Period to desired frequency, at the start or end of the interval."], "Period.now": ["Return the period of now's date."], "pandas.Period.now": ["Return the period of now's date."], "Period.strftime": ["Returns the string representation of the <a class=\"reference internal\" href=\"api/pandas.Period.html#pandas.Period\" title=\"pandas.Period\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Period</span></code></a>, depending on the selected <code class=\"docutils literal notranslate\"><span class=\"pre\">fmt</span></code>."], "pandas.Period.strftime": ["Returns the string representation of the <a class=\"reference internal\" href=\"api/pandas.Period.html#pandas.Period\" title=\"pandas.Period\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Period</span></code></a>, depending on the selected <code class=\"docutils literal notranslate\"><span class=\"pre\">fmt</span></code>."], "Period.to_timestamp": ["Return the Timestamp representation of the Period."], "pandas.Period.to_timestamp": ["Return the Timestamp representation of the Period."], "PeriodArray": ["Pandas ExtensionArray for storing Period data."], "arrays.PeriodArray": ["Pandas ExtensionArray for storing Period data."], "pandas.arrays.PeriodArray": ["Pandas ExtensionArray for storing Period data."], "Interval": ["Immutable object implementing an Interval, a bounded slice-like interval."], "pandas.Interval": ["Immutable object implementing an Interval, a bounded slice-like interval."], "closed": ["Whether the interval is closed on the left-side, right-side, both or neither.", "Whether the intervals are closed on the left-side, right-side, both or neither."], "Interval.closed": ["Whether the interval is closed on the left-side, right-side, both or neither."], "pandas.Interval.closed": ["Whether the interval is closed on the left-side, right-side, both or neither."], "closed_left": ["Check if the interval is closed on the left side."], "Interval.closed_left": ["Check if the interval is closed on the left side."], "pandas.Interval.closed_left": ["Check if the interval is closed on the left side."], "closed_right": ["Check if the interval is closed on the right side."], "Interval.closed_right": ["Check if the interval is closed on the right side."], "pandas.Interval.closed_right": ["Check if the interval is closed on the right side."], "is_empty": ["Indicates if an interval is empty, meaning it contains no points."], "Interval.is_empty": ["Indicates if an interval is empty, meaning it contains no points."], "pandas.Interval.is_empty": ["Indicates if an interval is empty, meaning it contains no points."], "left": ["Left bound for the interval.", ""], "Interval.left": ["Left bound for the interval."], "pandas.Interval.left": ["Left bound for the interval."], "length": ["Return the length of the Interval.", ""], "Interval.length": ["Return the length of the Interval."], "pandas.Interval.length": ["Return the length of the Interval."], "mid": ["Return the midpoint of the Interval.", ""], "Interval.mid": ["Return the midpoint of the Interval."], "pandas.Interval.mid": ["Return the midpoint of the Interval."], "open_left": ["Check if the interval is open on the left side."], "Interval.open_left": ["Check if the interval is open on the left side."], "pandas.Interval.open_left": ["Check if the interval is open on the left side."], "open_right": ["Check if the interval is open on the right side."], "Interval.open_right": ["Check if the interval is open on the right side."], "pandas.Interval.open_right": ["Check if the interval is open on the right side."], "overlaps": ["Check whether two Interval objects overlap.", "Check elementwise if an Interval overlaps the values in the IntervalArray."], "Interval.overlaps": ["Check whether two Interval objects overlap."], "pandas.Interval.overlaps": ["Check whether two Interval objects overlap."], "right": ["Right bound for the interval.", ""], "Interval.right": ["Right bound for the interval."], "pandas.Interval.right": ["Right bound for the interval."], "IntervalArray": ["Pandas array for interval data that are closed on the same side."], "arrays.IntervalArray": ["Pandas array for interval data that are closed on the same side."], "pandas.arrays.IntervalArray": ["Pandas array for interval data that are closed on the same side."], "IntegerArray": ["Array of integer (optional missing) values."], "arrays.IntegerArray": ["Array of integer (optional missing) values."], "pandas.arrays.IntegerArray": ["Array of integer (optional missing) values."], "Int8Dtype": ["An ExtensionDtype for int8 integer data."], "pandas.Int8Dtype": ["An ExtensionDtype for int8 integer data."], "Int16Dtype": ["An ExtensionDtype for int16 integer data."], "pandas.Int16Dtype": ["An ExtensionDtype for int16 integer data."], "Int32Dtype": ["An ExtensionDtype for int32 integer data."], "pandas.Int32Dtype": ["An ExtensionDtype for int32 integer data."], "UInt8Dtype": ["An ExtensionDtype for uint8 integer data."], "pandas.UInt8Dtype": ["An ExtensionDtype for uint8 integer data."], "UInt16Dtype": ["An ExtensionDtype for uint16 integer data."], "pandas.UInt16Dtype": ["An ExtensionDtype for uint16 integer data."], "UInt32Dtype": ["An ExtensionDtype for uint32 integer data."], "pandas.UInt32Dtype": ["An ExtensionDtype for uint32 integer data."], "UInt64Dtype": ["An ExtensionDtype for uint64 integer data."], "pandas.UInt64Dtype": ["An ExtensionDtype for uint64 integer data."], "CategoricalDtype.categories": ["An <code class=\"docutils literal notranslate\"><span class=\"pre\">Index</span></code> containing the unique categories allowed."], "pandas.CategoricalDtype.categories": ["An <code class=\"docutils literal notranslate\"><span class=\"pre\">Index</span></code> containing the unique categories allowed."], "CategoricalDtype.ordered": ["Whether the categories have an ordered relationship."], "pandas.CategoricalDtype.ordered": ["Whether the categories have an ordered relationship."], "Categorical": ["Represent a categorical variable in classic R / S-plus fashion."], "pandas.Categorical": ["Represent a categorical variable in classic R / S-plus fashion."], "from_codes": ["Make a Categorical type from codes and categories or dtype."], "Categorical.from_codes": ["Make a Categorical type from codes and categories or dtype."], "pandas.Categorical.from_codes": ["Make a Categorical type from codes and categories or dtype."], "Categorical.dtype": ["The <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">CategoricalDtype</span></code> for this instance."], "pandas.Categorical.dtype": ["The <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">CategoricalDtype</span></code> for this instance."], "Categorical.categories": ["The categories of this categorical."], "pandas.Categorical.categories": ["The categories of this categorical."], "Categorical.ordered": ["Whether the categories have an ordered relationship."], "pandas.Categorical.ordered": ["Whether the categories have an ordered relationship."], "Categorical.codes": ["The category codes of this categorical."], "pandas.Categorical.codes": ["The category codes of this categorical."], "Categorical.__array__": ["The numpy array interface."], "pandas.Categorical.__array__": ["The numpy array interface."], "SparseArray": ["An ExtensionArray for storing sparse data."], "arrays.SparseArray": ["An ExtensionArray for storing sparse data."], "pandas.arrays.SparseArray": ["An ExtensionArray for storing sparse data."], "StringArray": ["Extension array for string data."], "arrays.StringArray": ["Extension array for string data."], "pandas.arrays.StringArray": ["Extension array for string data."], "ArrowStringArray": ["Extension array for string data in a <code class=\"docutils literal notranslate\"><span class=\"pre\">pyarrow.ChunkedArray</span></code>."], "arrays.ArrowStringArray": ["Extension array for string data in a <code class=\"docutils literal notranslate\"><span class=\"pre\">pyarrow.ChunkedArray</span></code>."], "pandas.arrays.ArrowStringArray": ["Extension array for string data in a <code class=\"docutils literal notranslate\"><span class=\"pre\">pyarrow.ChunkedArray</span></code>."], "BooleanArray": ["Array of boolean (True/False) data with missing values."], "arrays.BooleanArray": ["Array of boolean (True/False) data with missing values."], "pandas.arrays.BooleanArray": ["Array of boolean (True/False) data with missing values."], "Index": ["Immutable sequence used for indexing and alignment."], "pandas.Index": ["Immutable sequence used for indexing and alignment."], "Index.values": ["Return an array representing the data in the Index."], "pandas.Index.values": ["Return an array representing the data in the Index."], "Index.is_monotonic": ["Alias for is_monotonic_increasing."], "pandas.Index.is_monotonic": ["Alias for is_monotonic_increasing."], "Index.is_monotonic_increasing": ["Return if the index is monotonic increasing (only equal or increasing) values."], "pandas.Index.is_monotonic_increasing": ["Return if the index is monotonic increasing (only equal or increasing) values."], "Index.is_monotonic_decreasing": ["Return if the index is monotonic decreasing (only equal or decreasing) values."], "pandas.Index.is_monotonic_decreasing": ["Return if the index is monotonic decreasing (only equal or decreasing) values."], "Index.is_unique": ["Return if the index has unique values."], "pandas.Index.is_unique": ["Return if the index has unique values."], "has_duplicates": ["Check if the Index has duplicate values."], "Index.has_duplicates": ["Check if the Index has duplicate values."], "pandas.Index.has_duplicates": ["Check if the Index has duplicate values."], "Index.hasnans": ["Return True if there are any NaNs."], "pandas.Index.hasnans": ["Return True if there are any NaNs."], "Index.dtype": ["Return the dtype object of the underlying data."], "pandas.Index.dtype": ["Return the dtype object of the underlying data."], "inferred_type": ["Return a string of the type inferred from the values."], "Index.inferred_type": ["Return a string of the type inferred from the values."], "pandas.Index.inferred_type": ["Return a string of the type inferred from the values."], "is_all_dates": ["Whether or not the index values only consist of dates."], "Index.is_all_dates": ["Whether or not the index values only consist of dates."], "pandas.Index.is_all_dates": ["Whether or not the index values only consist of dates."], "Index.shape": ["Return a tuple of the shape of the underlying data."], "pandas.Index.shape": ["Return a tuple of the shape of the underlying data."], "Index.name": ["Return Index or MultiIndex name."], "pandas.Index.name": ["Return Index or MultiIndex name."], "names": ["", "Names of levels in MultiIndex.", "Ordered list of field names, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> if there are no fields."], "Index.names": [""], "pandas.Index.names": [""], "Index.nbytes": ["Return the number of bytes in the underlying data."], "pandas.Index.nbytes": ["Return the number of bytes in the underlying data."], "Index.ndim": ["Number of dimensions of the underlying data, by definition 1."], "pandas.Index.ndim": ["Number of dimensions of the underlying data, by definition 1."], "Index.size": ["Return the number of elements in the underlying data."], "pandas.Index.size": ["Return the number of elements in the underlying data."], "Index.empty": [""], "pandas.Index.empty": [""], "Index.T": ["Return the transpose, which is by definition self."], "pandas.Index.T": ["Return the transpose, which is by definition self."], "Index.memory_usage": ["Memory usage of the values."], "pandas.Index.memory_usage": ["Memory usage of the values."], "Index.all": ["Return whether all elements are Truthy."], "pandas.Index.all": ["Return whether all elements are Truthy."], "Index.any": ["Return whether any element is Truthy."], "pandas.Index.any": ["Return whether any element is Truthy."], "Index.argmin": ["Return int position of the smallest value in the Series."], "pandas.Index.argmin": ["Return int position of the smallest value in the Series."], "Index.argmax": ["Return int position of the largest value in the Series."], "pandas.Index.argmax": ["Return int position of the largest value in the Series."], "Index.copy": ["Make a copy of this object."], "pandas.Index.copy": ["Make a copy of this object."], "delete": ["Make new Index with passed location(-s) deleted."], "Index.delete": ["Make new Index with passed location(-s) deleted."], "pandas.Index.delete": ["Make new Index with passed location(-s) deleted."], "Index.drop": ["Make new Index with passed list of labels deleted."], "pandas.Index.drop": ["Make new Index with passed list of labels deleted."], "Index.drop_duplicates": ["Return Index with duplicate values removed."], "pandas.Index.drop_duplicates": ["Return Index with duplicate values removed."], "Index.duplicated": ["Indicate duplicate index values."], "pandas.Index.duplicated": ["Indicate duplicate index values."], "Index.equals": ["Determine if two Index object are equal."], "pandas.Index.equals": ["Determine if two Index object are equal."], "Index.factorize": ["Encode the object as an enumerated type or categorical variable."], "pandas.Index.factorize": ["Encode the object as an enumerated type or categorical variable."], "identical": ["Similar to equals, but checks that object attributes and types are also equal."], "Index.identical": ["Similar to equals, but checks that object attributes and types are also equal."], "pandas.Index.identical": ["Similar to equals, but checks that object attributes and types are also equal."], "Index.insert": ["Make new Index inserting new item at location."], "pandas.Index.insert": ["Make new Index inserting new item at location."], "is_": ["More flexible, faster check like <code class=\"docutils literal notranslate\"><span class=\"pre\">is</span></code> but that works through views."], "Index.is_": ["More flexible, faster check like <code class=\"docutils literal notranslate\"><span class=\"pre\">is</span></code> but that works through views."], "pandas.Index.is_": ["More flexible, faster check like <code class=\"docutils literal notranslate\"><span class=\"pre\">is</span></code> but that works through views."], "is_boolean": ["Check if the Index only consists of booleans."], "Index.is_boolean": ["Check if the Index only consists of booleans."], "pandas.Index.is_boolean": ["Check if the Index only consists of booleans."], "is_categorical": ["Check if the Index holds categorical data.", "Check whether an array-like is a Categorical instance."], "Index.is_categorical": ["Check if the Index holds categorical data."], "pandas.Index.is_categorical": ["Check if the Index holds categorical data."], "is_floating": ["Check if the Index is a floating type."], "Index.is_floating": ["Check if the Index is a floating type."], "pandas.Index.is_floating": ["Check if the Index is a floating type."], "is_integer": ["Check if the Index only consists of integers.", "Return True if given object is integer."], "Index.is_integer": ["Check if the Index only consists of integers."], "pandas.Index.is_integer": ["Check if the Index only consists of integers."], "is_interval": ["Check if the Index holds Interval objects.", ""], "Index.is_interval": ["Check if the Index holds Interval objects."], "pandas.Index.is_interval": ["Check if the Index holds Interval objects."], "is_mixed": ["Check if the Index holds data with mixed data types."], "Index.is_mixed": ["Check if the Index holds data with mixed data types."], "pandas.Index.is_mixed": ["Check if the Index holds data with mixed data types."], "is_numeric": ["Check if the Index only consists of numeric data."], "Index.is_numeric": ["Check if the Index only consists of numeric data."], "pandas.Index.is_numeric": ["Check if the Index only consists of numeric data."], "is_object": ["Check if the Index is of the object dtype."], "Index.is_object": ["Check if the Index is of the object dtype."], "pandas.Index.is_object": ["Check if the Index is of the object dtype."], "Index.min": ["Return the minimum value of the Index."], "pandas.Index.min": ["Return the minimum value of the Index."], "Index.max": ["Return the maximum value of the Index."], "pandas.Index.max": ["Return the maximum value of the Index."], "Index.reindex": ["Create index with target's values."], "pandas.Index.reindex": ["Create index with target's values."], "Index.rename": ["Alter Index or MultiIndex name."], "pandas.Index.rename": ["Alter Index or MultiIndex name."], "Index.repeat": ["Repeat elements of a Index."], "pandas.Index.repeat": ["Repeat elements of a Index."], "Index.where": ["Replace values where the condition is False."], "pandas.Index.where": ["Replace values where the condition is False."], "Index.take": ["Return a new Index of the values selected by the indices."], "pandas.Index.take": ["Return a new Index of the values selected by the indices."], "putmask": ["Return a new Index of the values set with the mask."], "Index.putmask": ["Return a new Index of the values set with the mask."], "pandas.Index.putmask": ["Return a new Index of the values set with the mask."], "Index.unique": ["Return unique values in the index."], "pandas.Index.unique": ["Return unique values in the index."], "Index.nunique": ["Return number of unique elements in the object."], "pandas.Index.nunique": ["Return number of unique elements in the object."], "Index.value_counts": ["Return a Series containing counts of unique values."], "pandas.Index.value_counts": ["Return a Series containing counts of unique values."], "set_names": ["Set Index or MultiIndex name."], "Index.set_names": ["Set Index or MultiIndex name."], "pandas.Index.set_names": ["Set Index or MultiIndex name."], "Index.droplevel": ["Return index with requested level(s) removed."], "pandas.Index.droplevel": ["Return index with requested level(s) removed."], "Index.fillna": ["Fill NA/NaN values with the specified value."], "pandas.Index.fillna": ["Fill NA/NaN values with the specified value."], "Index.dropna": ["Return Index without NA/NaN values."], "pandas.Index.dropna": ["Return Index without NA/NaN values."], "Index.isna": ["Detect missing values."], "pandas.Index.isna": ["Detect missing values."], "Index.notna": ["Detect existing (non-missing) values."], "pandas.Index.notna": ["Detect existing (non-missing) values."], "Index.astype": ["Create an Index with values cast to dtypes."], "pandas.Index.astype": ["Create an Index with values cast to dtypes."], "Index.item": ["Return the first element of the underlying data as a Python scalar."], "pandas.Index.item": ["Return the first element of the underlying data as a Python scalar."], "Index.map": ["Map values using an input mapping or function."], "pandas.Index.map": ["Map values using an input mapping or function."], "Index.ravel": ["Return an ndarray of the flattened values of the underlying data."], "pandas.Index.ravel": ["Return an ndarray of the flattened values of the underlying data."], "Index.to_list": ["Return a list of the values."], "pandas.Index.to_list": ["Return a list of the values."], "to_native_types": ["(DEPRECATED) Format specified values of <cite>self</cite> and return them."], "Index.to_native_types": ["(DEPRECATED) Format specified values of <cite>self</cite> and return them."], "pandas.Index.to_native_types": ["(DEPRECATED) Format specified values of <cite>self</cite> and return them."], "to_series": ["Create a Series with both index and values equal to the index keys.", "Create a Series with both index and values equal to the index keys useful with map for returning an indexer based on an index."], "Index.to_series": ["Create a Series with both index and values equal to the index keys."], "pandas.Index.to_series": ["Create a Series with both index and values equal to the index keys."], "Index.to_frame": ["Create a DataFrame with a column containing the Index."], "pandas.Index.to_frame": ["Create a DataFrame with a column containing the Index."], "Index.view": [""], "pandas.Index.view": [""], "Index.argsort": ["Return the integer indices that would sort the index."], "pandas.Index.argsort": ["Return the integer indices that would sort the index."], "Index.searchsorted": ["Find indices where elements should be inserted to maintain order."], "pandas.Index.searchsorted": ["Find indices where elements should be inserted to maintain order."], "Index.sort_values": ["Return a sorted copy of the index."], "pandas.Index.sort_values": ["Return a sorted copy of the index."], "Index.shift": ["Shift index by desired number of time frequency increments."], "pandas.Index.shift": ["Shift index by desired number of time frequency increments."], "Index.append": ["Append a collection of Index options together."], "pandas.Index.append": ["Append a collection of Index options together."], "Index.join": ["Compute join_index and indexers to conform data structures to the new index."], "pandas.Index.join": ["Compute join_index and indexers to conform data structures to the new index."], "intersection": ["Form the intersection of two Index objects."], "Index.intersection": ["Form the intersection of two Index objects."], "pandas.Index.intersection": ["Form the intersection of two Index objects."], "union": ["Form the union of two Index objects."], "Index.union": ["Form the union of two Index objects."], "pandas.Index.union": ["Form the union of two Index objects."], "difference": ["Return a new Index with elements of index not in <cite>other</cite>."], "Index.difference": ["Return a new Index with elements of index not in <cite>other</cite>."], "pandas.Index.difference": ["Return a new Index with elements of index not in <cite>other</cite>."], "symmetric_difference": ["Compute the symmetric difference of two Index objects."], "Index.symmetric_difference": ["Compute the symmetric difference of two Index objects."], "pandas.Index.symmetric_difference": ["Compute the symmetric difference of two Index objects."], "Index.asof": ["Return the label from the index, or, if not present, the previous one."], "pandas.Index.asof": ["Return the label from the index, or, if not present, the previous one."], "asof_locs": ["Return the locations (indices) of labels in the index."], "Index.asof_locs": ["Return the locations (indices) of labels in the index."], "pandas.Index.asof_locs": ["Return the locations (indices) of labels in the index."], "get_indexer": ["Compute indexer and mask for new index given the current index."], "Index.get_indexer": ["Compute indexer and mask for new index given the current index."], "pandas.Index.get_indexer": ["Compute indexer and mask for new index given the current index."], "get_indexer_for": ["Guaranteed return of an indexer even when non-unique."], "Index.get_indexer_for": ["Guaranteed return of an indexer even when non-unique."], "pandas.Index.get_indexer_for": ["Guaranteed return of an indexer even when non-unique."], "get_indexer_non_unique": ["Compute indexer and mask for new index given the current index."], "Index.get_indexer_non_unique": ["Compute indexer and mask for new index given the current index."], "pandas.Index.get_indexer_non_unique": ["Compute indexer and mask for new index given the current index."], "get_level_values": ["Return an Index of values for requested level.", "Return vector of label values for requested level."], "Index.get_level_values": ["Return an Index of values for requested level."], "pandas.Index.get_level_values": ["Return an Index of values for requested level."], "get_loc": ["Get integer location, slice or boolean mask for requested label.", "Get location for a label or a tuple of labels."], "Index.get_loc": ["Get integer location, slice or boolean mask for requested label."], "pandas.Index.get_loc": ["Get integer location, slice or boolean mask for requested label."], "get_slice_bound": ["Calculate slice bound that corresponds to given label."], "Index.get_slice_bound": ["Calculate slice bound that corresponds to given label."], "pandas.Index.get_slice_bound": ["Calculate slice bound that corresponds to given label."], "get_value": ["Fast lookup of value from 1-dimensional ndarray."], "Index.get_value": ["Fast lookup of value from 1-dimensional ndarray."], "pandas.Index.get_value": ["Fast lookup of value from 1-dimensional ndarray."], "Index.isin": ["Return a boolean array where the index values are in <cite>values</cite>."], "pandas.Index.isin": ["Return a boolean array where the index values are in <cite>values</cite>."], "slice_indexer": ["Compute the slice indexer for input labels and step."], "Index.slice_indexer": ["Compute the slice indexer for input labels and step."], "pandas.Index.slice_indexer": ["Compute the slice indexer for input labels and step."], "slice_locs": ["Compute slice locations for input labels."], "Index.slice_locs": ["Compute slice locations for input labels."], "pandas.Index.slice_locs": ["Compute slice locations for input labels."], "RangeIndex": ["Immutable Index implementing a monotonic integer range."], "pandas.RangeIndex": ["Immutable Index implementing a monotonic integer range."], "Int64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "pandas.Int64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "UInt64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "pandas.UInt64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "Float64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "pandas.Float64Index": ["(DEPRECATED) Immutable sequence used for indexing and alignment."], "start": ["The value of the <cite>start</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">0</span></code> if this was not supplied).", ""], "RangeIndex.start": ["The value of the <cite>start</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">0</span></code> if this was not supplied)."], "pandas.RangeIndex.start": ["The value of the <cite>start</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">0</span></code> if this was not supplied)."], "stop": ["The value of the <cite>stop</cite> parameter."], "RangeIndex.stop": ["The value of the <cite>stop</cite> parameter."], "pandas.RangeIndex.stop": ["The value of the <cite>stop</cite> parameter."], "step": ["The value of the <cite>step</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">1</span></code> if this was not supplied)."], "RangeIndex.step": ["The value of the <cite>step</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">1</span></code> if this was not supplied)."], "pandas.RangeIndex.step": ["The value of the <cite>step</cite> parameter (<code class=\"docutils literal notranslate\"><span class=\"pre\">1</span></code> if this was not supplied)."], "from_range": ["Create RangeIndex from a range object."], "RangeIndex.from_range": ["Create RangeIndex from a range object."], "pandas.RangeIndex.from_range": ["Create RangeIndex from a range object."], "CategoricalIndex": ["Index based on an underlying <a class=\"reference internal\" href=\"api/pandas.Categorical.html#pandas.Categorical\" title=\"pandas.Categorical\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Categorical</span></code></a>."], "pandas.CategoricalIndex": ["Index based on an underlying <a class=\"reference internal\" href=\"api/pandas.Categorical.html#pandas.Categorical\" title=\"pandas.Categorical\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Categorical</span></code></a>."], "CategoricalIndex.codes": ["The category codes of this categorical."], "pandas.CategoricalIndex.codes": ["The category codes of this categorical."], "CategoricalIndex.categories": ["The categories of this categorical."], "pandas.CategoricalIndex.categories": ["The categories of this categorical."], "CategoricalIndex.ordered": ["Whether the categories have an ordered relationship."], "pandas.CategoricalIndex.ordered": ["Whether the categories have an ordered relationship."], "CategoricalIndex.rename_categories": ["Rename categories."], "pandas.CategoricalIndex.rename_categories": ["Rename categories."], "CategoricalIndex.reorder_categories": ["Reorder categories as specified in new_categories."], "pandas.CategoricalIndex.reorder_categories": ["Reorder categories as specified in new_categories."], "CategoricalIndex.add_categories": ["Add new categories."], "pandas.CategoricalIndex.add_categories": ["Add new categories."], "CategoricalIndex.remove_categories": ["Remove the specified categories."], "pandas.CategoricalIndex.remove_categories": ["Remove the specified categories."], "CategoricalIndex.remove_unused_categories": ["Remove categories which are not used."], "pandas.CategoricalIndex.remove_unused_categories": ["Remove categories which are not used."], "CategoricalIndex.set_categories": ["Set the categories to the specified new_categories."], "pandas.CategoricalIndex.set_categories": ["Set the categories to the specified new_categories."], "CategoricalIndex.as_ordered": ["Set the Categorical to be ordered."], "pandas.CategoricalIndex.as_ordered": ["Set the Categorical to be ordered."], "CategoricalIndex.as_unordered": ["Set the Categorical to be unordered."], "pandas.CategoricalIndex.as_unordered": ["Set the Categorical to be unordered."], "CategoricalIndex.map": ["Map values using input an input mapping or function."], "pandas.CategoricalIndex.map": ["Map values using input an input mapping or function."], "CategoricalIndex.equals": ["Determine if two CategoricalIndex objects contain the same elements."], "pandas.CategoricalIndex.equals": ["Determine if two CategoricalIndex objects contain the same elements."], "IntervalIndex": ["Immutable index of intervals that are closed on the same side."], "pandas.IntervalIndex": ["Immutable index of intervals that are closed on the same side."], "from_arrays": ["Construct from two arrays defining the left and right bounds.", "Convert arrays to MultiIndex."], "IntervalIndex.from_arrays": ["Construct from two arrays defining the left and right bounds."], "pandas.IntervalIndex.from_arrays": ["Construct from two arrays defining the left and right bounds."], "from_tuples": ["Construct an IntervalIndex from an array-like of tuples.", "Convert list of tuples to MultiIndex."], "IntervalIndex.from_tuples": ["Construct an IntervalIndex from an array-like of tuples."], "pandas.IntervalIndex.from_tuples": ["Construct an IntervalIndex from an array-like of tuples."], "from_breaks": ["Construct an IntervalIndex from an array of splits."], "IntervalIndex.from_breaks": ["Construct an IntervalIndex from an array of splits."], "pandas.IntervalIndex.from_breaks": ["Construct an IntervalIndex from an array of splits."], "IntervalIndex.left": [""], "pandas.IntervalIndex.left": [""], "IntervalIndex.right": [""], "pandas.IntervalIndex.right": [""], "IntervalIndex.mid": [""], "pandas.IntervalIndex.mid": [""], "IntervalIndex.closed": ["Whether the intervals are closed on the left-side, right-side, both or neither."], "pandas.IntervalIndex.closed": ["Whether the intervals are closed on the left-side, right-side, both or neither."], "IntervalIndex.length": [""], "pandas.IntervalIndex.length": [""], "IntervalIndex.values": ["Return an array representing the data in the Index."], "pandas.IntervalIndex.values": ["Return an array representing the data in the Index."], "IntervalIndex.is_empty": ["Indicates if an interval is empty, meaning it contains no points."], "pandas.IntervalIndex.is_empty": ["Indicates if an interval is empty, meaning it contains no points."], "is_non_overlapping_monotonic": ["Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False."], "IntervalIndex.is_non_overlapping_monotonic": ["Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False."], "pandas.IntervalIndex.is_non_overlapping_monotonic": ["Return True if the IntervalArray is non-overlapping (no Intervals share points) and is either monotonic increasing or monotonic decreasing, else False."], "is_overlapping": ["Return True if the IntervalIndex has overlapping intervals, else False."], "IntervalIndex.is_overlapping": ["Return True if the IntervalIndex has overlapping intervals, else False."], "pandas.IntervalIndex.is_overlapping": ["Return True if the IntervalIndex has overlapping intervals, else False."], "IntervalIndex.get_loc": ["Get integer location, slice or boolean mask for requested label."], "pandas.IntervalIndex.get_loc": ["Get integer location, slice or boolean mask for requested label."], "IntervalIndex.get_indexer": ["Compute indexer and mask for new index given the current index."], "pandas.IntervalIndex.get_indexer": ["Compute indexer and mask for new index given the current index."], "set_closed": ["Return an IntervalArray identical to the current one, but closed on the specified side."], "IntervalIndex.set_closed": ["Return an IntervalArray identical to the current one, but closed on the specified side."], "pandas.IntervalIndex.set_closed": ["Return an IntervalArray identical to the current one, but closed on the specified side."], "IntervalIndex.contains": ["Check elementwise if the Intervals contain the value."], "pandas.IntervalIndex.contains": ["Check elementwise if the Intervals contain the value."], "IntervalIndex.overlaps": ["Check elementwise if an Interval overlaps the values in the IntervalArray."], "pandas.IntervalIndex.overlaps": ["Check elementwise if an Interval overlaps the values in the IntervalArray."], "to_tuples": ["Return an ndarray of tuples of the form (left, right)."], "IntervalIndex.to_tuples": ["Return an ndarray of tuples of the form (left, right)."], "pandas.IntervalIndex.to_tuples": ["Return an ndarray of tuples of the form (left, right)."], "MultiIndex": ["A multi-level, or hierarchical, index object for pandas objects."], "pandas.MultiIndex": ["A multi-level, or hierarchical, index object for pandas objects."], "IndexSlice": ["Create an object to more easily perform multi-index slicing."], "pandas.IndexSlice": ["Create an object to more easily perform multi-index slicing."], "MultiIndex.from_arrays": ["Convert arrays to MultiIndex."], "pandas.MultiIndex.from_arrays": ["Convert arrays to MultiIndex."], "MultiIndex.from_tuples": ["Convert list of tuples to MultiIndex."], "pandas.MultiIndex.from_tuples": ["Convert list of tuples to MultiIndex."], "from_product": ["Make a MultiIndex from the cartesian product of multiple iterables."], "MultiIndex.from_product": ["Make a MultiIndex from the cartesian product of multiple iterables."], "pandas.MultiIndex.from_product": ["Make a MultiIndex from the cartesian product of multiple iterables."], "from_frame": ["Make a MultiIndex from a DataFrame."], "MultiIndex.from_frame": ["Make a MultiIndex from a DataFrame."], "pandas.MultiIndex.from_frame": ["Make a MultiIndex from a DataFrame."], "MultiIndex.names": ["Names of levels in MultiIndex."], "pandas.MultiIndex.names": ["Names of levels in MultiIndex."], "levels": [""], "MultiIndex.levels": [""], "pandas.MultiIndex.levels": [""], "MultiIndex.codes": [""], "pandas.MultiIndex.codes": [""], "nlevels": ["Integer number of levels in this MultiIndex."], "MultiIndex.nlevels": ["Integer number of levels in this MultiIndex."], "pandas.MultiIndex.nlevels": ["Integer number of levels in this MultiIndex."], "levshape": ["A tuple with the length of each level."], "MultiIndex.levshape": ["A tuple with the length of each level."], "pandas.MultiIndex.levshape": ["A tuple with the length of each level."], "MultiIndex.dtypes": ["Return the dtypes as a Series for the underlying MultiIndex."], "pandas.MultiIndex.dtypes": ["Return the dtypes as a Series for the underlying MultiIndex."], "set_levels": ["Set new levels on MultiIndex."], "MultiIndex.set_levels": ["Set new levels on MultiIndex."], "pandas.MultiIndex.set_levels": ["Set new levels on MultiIndex."], "set_codes": ["Set new codes on MultiIndex."], "MultiIndex.set_codes": ["Set new codes on MultiIndex."], "pandas.MultiIndex.set_codes": ["Set new codes on MultiIndex."], "to_flat_index": ["Convert a MultiIndex to an Index of Tuples containing the level values."], "MultiIndex.to_flat_index": ["Convert a MultiIndex to an Index of Tuples containing the level values."], "pandas.MultiIndex.to_flat_index": ["Convert a MultiIndex to an Index of Tuples containing the level values."], "MultiIndex.to_frame": ["Create a DataFrame with the levels of the MultiIndex as columns."], "pandas.MultiIndex.to_frame": ["Create a DataFrame with the levels of the MultiIndex as columns."], "sortlevel": ["Sort MultiIndex at the requested level."], "MultiIndex.sortlevel": ["Sort MultiIndex at the requested level."], "pandas.MultiIndex.sortlevel": ["Sort MultiIndex at the requested level."], "MultiIndex.droplevel": ["Return index with requested level(s) removed."], "pandas.MultiIndex.droplevel": ["Return index with requested level(s) removed."], "MultiIndex.swaplevel": ["Swap level i with level j."], "pandas.MultiIndex.swaplevel": ["Swap level i with level j."], "MultiIndex.reorder_levels": ["Rearrange levels using input order."], "pandas.MultiIndex.reorder_levels": ["Rearrange levels using input order."], "remove_unused_levels": ["Create new MultiIndex from current that removes unused levels."], "MultiIndex.remove_unused_levels": ["Create new MultiIndex from current that removes unused levels."], "pandas.MultiIndex.remove_unused_levels": ["Create new MultiIndex from current that removes unused levels."], "MultiIndex.get_loc": ["Get location for a label or a tuple of labels."], "pandas.MultiIndex.get_loc": ["Get location for a label or a tuple of labels."], "get_locs": ["Get location for a sequence of labels."], "MultiIndex.get_locs": ["Get location for a sequence of labels."], "pandas.MultiIndex.get_locs": ["Get location for a sequence of labels."], "get_loc_level": ["Get location and sliced index for requested label(s)/level(s)."], "MultiIndex.get_loc_level": ["Get location and sliced index for requested label(s)/level(s)."], "pandas.MultiIndex.get_loc_level": ["Get location and sliced index for requested label(s)/level(s)."], "MultiIndex.get_indexer": ["Compute indexer and mask for new index given the current index."], "pandas.MultiIndex.get_indexer": ["Compute indexer and mask for new index given the current index."], "MultiIndex.get_level_values": ["Return vector of label values for requested level."], "pandas.MultiIndex.get_level_values": ["Return vector of label values for requested level."], "DatetimeIndex": ["Immutable ndarray-like of datetime64 data."], "pandas.DatetimeIndex": ["Immutable ndarray-like of datetime64 data."], "DatetimeIndex.year": ["The year of the datetime."], "pandas.DatetimeIndex.year": ["The year of the datetime."], "DatetimeIndex.month": ["The month as January=1, December=12."], "pandas.DatetimeIndex.month": ["The month as January=1, December=12."], "DatetimeIndex.day": ["The day of the datetime."], "pandas.DatetimeIndex.day": ["The day of the datetime."], "DatetimeIndex.hour": ["The hours of the datetime."], "pandas.DatetimeIndex.hour": ["The hours of the datetime."], "DatetimeIndex.minute": ["The minutes of the datetime."], "pandas.DatetimeIndex.minute": ["The minutes of the datetime."], "DatetimeIndex.second": ["The seconds of the datetime."], "pandas.DatetimeIndex.second": ["The seconds of the datetime."], "DatetimeIndex.microsecond": ["The microseconds of the datetime."], "pandas.DatetimeIndex.microsecond": ["The microseconds of the datetime."], "DatetimeIndex.nanosecond": ["The nanoseconds of the datetime."], "pandas.DatetimeIndex.nanosecond": ["The nanoseconds of the datetime."], "DatetimeIndex.date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects."], "pandas.DatetimeIndex.date": ["Returns numpy array of python <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.date\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.date</span></code></a> objects."], "DatetimeIndex.time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects."], "pandas.DatetimeIndex.time": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects."], "DatetimeIndex.timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information."], "pandas.DatetimeIndex.timetz": ["Returns numpy array of <a class=\"reference external\" href=\"https://docs.python.org/3/library/datetime.html#datetime.time\" title=\"(in Python v3.10)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">datetime.time</span></code></a> objects with timezone information."], "DatetimeIndex.dayofyear": ["The ordinal day of the year."], "pandas.DatetimeIndex.dayofyear": ["The ordinal day of the year."], "DatetimeIndex.day_of_year": ["The ordinal day of the year."], "pandas.DatetimeIndex.day_of_year": ["The ordinal day of the year."], "DatetimeIndex.weekofyear": ["(DEPRECATED) The week ordinal of the year."], "pandas.DatetimeIndex.weekofyear": ["(DEPRECATED) The week ordinal of the year."], "DatetimeIndex.week": ["(DEPRECATED) The week ordinal of the year."], "pandas.DatetimeIndex.week": ["(DEPRECATED) The week ordinal of the year."], "DatetimeIndex.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "pandas.DatetimeIndex.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "DatetimeIndex.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "pandas.DatetimeIndex.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "DatetimeIndex.weekday": ["The day of the week with Monday=0, Sunday=6."], "pandas.DatetimeIndex.weekday": ["The day of the week with Monday=0, Sunday=6."], "DatetimeIndex.quarter": ["The quarter of the date."], "pandas.DatetimeIndex.quarter": ["The quarter of the date."], "DatetimeIndex.tz": ["Return the timezone."], "pandas.DatetimeIndex.tz": ["Return the timezone."], "DatetimeIndex.freq": ["Return the frequency object if it is set, otherwise None."], "pandas.DatetimeIndex.freq": ["Return the frequency object if it is set, otherwise None."], "DatetimeIndex.freqstr": ["Return the frequency object as a string if its set, otherwise None."], "pandas.DatetimeIndex.freqstr": ["Return the frequency object as a string if its set, otherwise None."], "DatetimeIndex.is_month_start": ["Indicates whether the date is the first day of the month."], "pandas.DatetimeIndex.is_month_start": ["Indicates whether the date is the first day of the month."], "DatetimeIndex.is_month_end": ["Indicates whether the date is the last day of the month."], "pandas.DatetimeIndex.is_month_end": ["Indicates whether the date is the last day of the month."], "DatetimeIndex.is_quarter_start": ["Indicator for whether the date is the first day of a quarter."], "pandas.DatetimeIndex.is_quarter_start": ["Indicator for whether the date is the first day of a quarter."], "DatetimeIndex.is_quarter_end": ["Indicator for whether the date is the last day of a quarter."], "pandas.DatetimeIndex.is_quarter_end": ["Indicator for whether the date is the last day of a quarter."], "DatetimeIndex.is_year_start": ["Indicate whether the date is the first day of a year."], "pandas.DatetimeIndex.is_year_start": ["Indicate whether the date is the first day of a year."], "DatetimeIndex.is_year_end": ["Indicate whether the date is the last day of the year."], "pandas.DatetimeIndex.is_year_end": ["Indicate whether the date is the last day of the year."], "DatetimeIndex.is_leap_year": ["Boolean indicator if the date belongs to a leap year."], "pandas.DatetimeIndex.is_leap_year": ["Boolean indicator if the date belongs to a leap year."], "inferred_freq": ["Tries to return a string representing a frequency guess, generated by infer_freq."], "DatetimeIndex.inferred_freq": ["Tries to return a string representing a frequency guess, generated by infer_freq."], "pandas.DatetimeIndex.inferred_freq": ["Tries to return a string representing a frequency guess, generated by infer_freq."], "indexer_at_time": ["Return index locations of values at particular time of day (e.g."], "DatetimeIndex.indexer_at_time": ["Return index locations of values at particular time of day (e.g."], "pandas.DatetimeIndex.indexer_at_time": ["Return index locations of values at particular time of day (e.g."], "indexer_between_time": ["Return index locations of values between particular times of day (e.g., 9:00-9:30AM)."], "DatetimeIndex.indexer_between_time": ["Return index locations of values between particular times of day (e.g., 9:00-9:30AM)."], "pandas.DatetimeIndex.indexer_between_time": ["Return index locations of values between particular times of day (e.g., 9:00-9:30AM)."], "DatetimeIndex.normalize": ["Convert times to midnight."], "pandas.DatetimeIndex.normalize": ["Convert times to midnight."], "DatetimeIndex.strftime": ["Convert to Index using specified date_format."], "pandas.DatetimeIndex.strftime": ["Convert to Index using specified date_format."], "snap": ["Snap time stamps to nearest occurring frequency."], "DatetimeIndex.snap": ["Snap time stamps to nearest occurring frequency."], "pandas.DatetimeIndex.snap": ["Snap time stamps to nearest occurring frequency."], "DatetimeIndex.tz_convert": ["Convert tz-aware Datetime Array/Index from one time zone to another."], "pandas.DatetimeIndex.tz_convert": ["Convert tz-aware Datetime Array/Index from one time zone to another."], "DatetimeIndex.tz_localize": ["Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index."], "pandas.DatetimeIndex.tz_localize": ["Localize tz-naive Datetime Array/Index to tz-aware Datetime Array/Index."], "DatetimeIndex.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "pandas.DatetimeIndex.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "DatetimeIndex.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "pandas.DatetimeIndex.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "DatetimeIndex.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "pandas.DatetimeIndex.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "DatetimeIndex.month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "pandas.DatetimeIndex.month_name": ["Return the month names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "DatetimeIndex.day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "pandas.DatetimeIndex.day_name": ["Return the day names of the <a class=\"reference internal\" href=\"api/pandas.Series.html#pandas.Series\" title=\"pandas.Series\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Series</span></code></a> or <a class=\"reference internal\" href=\"api/pandas.DatetimeIndex.html#pandas.DatetimeIndex\" title=\"pandas.DatetimeIndex\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DatetimeIndex</span></code></a> with specified locale."], "DatetimeIndex.to_period": ["Cast to PeriodArray/Index at a particular frequency."], "pandas.DatetimeIndex.to_period": ["Cast to PeriodArray/Index at a particular frequency."], "to_perioddelta": ["Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified freq."], "DatetimeIndex.to_perioddelta": ["Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified freq."], "pandas.DatetimeIndex.to_perioddelta": ["Calculate TimedeltaArray of difference between index values and index converted to PeriodArray at specified freq."], "DatetimeIndex.to_pydatetime": ["Return Datetime Array/Index as object ndarray of datetime.datetime objects."], "pandas.DatetimeIndex.to_pydatetime": ["Return Datetime Array/Index as object ndarray of datetime.datetime objects."], "DatetimeIndex.to_series": ["Create a Series with both index and values equal to the index keys useful with map for returning an indexer based on an index."], "pandas.DatetimeIndex.to_series": ["Create a Series with both index and values equal to the index keys useful with map for returning an indexer based on an index."], "DatetimeIndex.to_frame": ["Create a DataFrame with a column containing the Index."], "pandas.DatetimeIndex.to_frame": ["Create a DataFrame with a column containing the Index."], "DatetimeIndex.mean": ["Return the mean value of the Array."], "pandas.DatetimeIndex.mean": ["Return the mean value of the Array."], "DatetimeIndex.std": ["Return sample standard deviation over requested axis."], "pandas.DatetimeIndex.std": ["Return sample standard deviation over requested axis."], "TimedeltaIndex": ["Immutable ndarray of timedelta64 data, represented internally as int64, and which can be boxed to timedelta objects."], "pandas.TimedeltaIndex": ["Immutable ndarray of timedelta64 data, represented internally as int64, and which can be boxed to timedelta objects."], "TimedeltaIndex.days": ["Number of days for each element."], "pandas.TimedeltaIndex.days": ["Number of days for each element."], "TimedeltaIndex.seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element."], "pandas.TimedeltaIndex.seconds": ["Number of seconds (&gt;= 0 and less than 1 day) for each element."], "TimedeltaIndex.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element."], "pandas.TimedeltaIndex.microseconds": ["Number of microseconds (&gt;= 0 and less than 1 second) for each element."], "TimedeltaIndex.nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element."], "pandas.TimedeltaIndex.nanoseconds": ["Number of nanoseconds (&gt;= 0 and less than 1 microsecond) for each element."], "TimedeltaIndex.components": ["Return a dataframe of the components (days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas."], "pandas.TimedeltaIndex.components": ["Return a dataframe of the components (days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds) of the Timedeltas."], "TimedeltaIndex.inferred_freq": ["Tries to return a string representing a frequency guess, generated by infer_freq."], "pandas.TimedeltaIndex.inferred_freq": ["Tries to return a string representing a frequency guess, generated by infer_freq."], "TimedeltaIndex.to_pytimedelta": ["Return Timedelta Array/Index as object ndarray of datetime.timedelta objects."], "pandas.TimedeltaIndex.to_pytimedelta": ["Return Timedelta Array/Index as object ndarray of datetime.timedelta objects."], "TimedeltaIndex.to_series": ["Create a Series with both index and values equal to the index keys."], "pandas.TimedeltaIndex.to_series": ["Create a Series with both index and values equal to the index keys."], "TimedeltaIndex.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "pandas.TimedeltaIndex.round": ["Perform round operation on the data to the specified <cite>freq</cite>."], "TimedeltaIndex.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "pandas.TimedeltaIndex.floor": ["Perform floor operation on the data to the specified <cite>freq</cite>."], "TimedeltaIndex.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "pandas.TimedeltaIndex.ceil": ["Perform ceil operation on the data to the specified <cite>freq</cite>."], "TimedeltaIndex.to_frame": ["Create a DataFrame with a column containing the Index."], "pandas.TimedeltaIndex.to_frame": ["Create a DataFrame with a column containing the Index."], "TimedeltaIndex.mean": ["Return the mean value of the Array."], "pandas.TimedeltaIndex.mean": ["Return the mean value of the Array."], "PeriodIndex": ["Immutable ndarray holding ordinal values indicating regular periods in time."], "pandas.PeriodIndex": ["Immutable ndarray holding ordinal values indicating regular periods in time."], "PeriodIndex.day": ["The days of the period."], "pandas.PeriodIndex.day": ["The days of the period."], "PeriodIndex.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "pandas.PeriodIndex.dayofweek": ["The day of the week with Monday=0, Sunday=6."], "PeriodIndex.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "pandas.PeriodIndex.day_of_week": ["The day of the week with Monday=0, Sunday=6."], "PeriodIndex.dayofyear": ["The ordinal day of the year."], "pandas.PeriodIndex.dayofyear": ["The ordinal day of the year."], "PeriodIndex.day_of_year": ["The ordinal day of the year."], "pandas.PeriodIndex.day_of_year": ["The ordinal day of the year."], "PeriodIndex.days_in_month": ["The number of days in the month."], "pandas.PeriodIndex.days_in_month": ["The number of days in the month."], "PeriodIndex.daysinmonth": ["The number of days in the month."], "pandas.PeriodIndex.daysinmonth": ["The number of days in the month."], "PeriodIndex.end_time": [""], "pandas.PeriodIndex.end_time": [""], "PeriodIndex.freq": ["Return the frequency object if it is set, otherwise None."], "pandas.PeriodIndex.freq": ["Return the frequency object if it is set, otherwise None."], "PeriodIndex.freqstr": ["Return the frequency object as a string if its set, otherwise None."], "pandas.PeriodIndex.freqstr": ["Return the frequency object as a string if its set, otherwise None."], "PeriodIndex.hour": ["The hour of the period."], "pandas.PeriodIndex.hour": ["The hour of the period."], "PeriodIndex.is_leap_year": ["Logical indicating if the date belongs to a leap year."], "pandas.PeriodIndex.is_leap_year": ["Logical indicating if the date belongs to a leap year."], "PeriodIndex.minute": ["The minute of the period."], "pandas.PeriodIndex.minute": ["The minute of the period."], "PeriodIndex.month": ["The month as January=1, December=12."], "pandas.PeriodIndex.month": ["The month as January=1, December=12."], "PeriodIndex.quarter": ["The quarter of the date."], "pandas.PeriodIndex.quarter": ["The quarter of the date."], "PeriodIndex.qyear": [""], "pandas.PeriodIndex.qyear": [""], "PeriodIndex.second": ["The second of the period."], "pandas.PeriodIndex.second": ["The second of the period."], "PeriodIndex.start_time": [""], "pandas.PeriodIndex.start_time": [""], "PeriodIndex.week": ["The week ordinal of the year."], "pandas.PeriodIndex.week": ["The week ordinal of the year."], "PeriodIndex.weekday": ["The day of the week with Monday=0, Sunday=6."], "pandas.PeriodIndex.weekday": ["The day of the week with Monday=0, Sunday=6."], "PeriodIndex.weekofyear": ["The week ordinal of the year."], "pandas.PeriodIndex.weekofyear": ["The week ordinal of the year."], "PeriodIndex.year": ["The year of the period."], "pandas.PeriodIndex.year": ["The year of the period."], "PeriodIndex.asfreq": ["Convert the PeriodArray to the specified frequency <cite>freq</cite>."], "pandas.PeriodIndex.asfreq": ["Convert the PeriodArray to the specified frequency <cite>freq</cite>."], "PeriodIndex.strftime": ["Convert to Index using specified date_format."], "pandas.PeriodIndex.strftime": ["Convert to Index using specified date_format."], "PeriodIndex.to_timestamp": ["Cast to DatetimeArray/Index."], "pandas.PeriodIndex.to_timestamp": ["Cast to DatetimeArray/Index."], "DateOffset": ["Standard kind of date increment used for a date range."], "offsets.DateOffset": ["Standard kind of date increment used for a date range."], "tseries.offsets.DateOffset": ["Standard kind of date increment used for a date range."], "pandas.tseries.offsets.DateOffset": ["Standard kind of date increment used for a date range."], "DateOffset.freqstr": [""], "offsets.DateOffset.freqstr": [""], "tseries.offsets.DateOffset.freqstr": [""], "pandas.tseries.offsets.DateOffset.freqstr": [""], "kwds": [""], "DateOffset.kwds": [""], "offsets.DateOffset.kwds": [""], "tseries.offsets.DateOffset.kwds": [""], "pandas.tseries.offsets.DateOffset.kwds": [""], "DateOffset.name": [""], "offsets.DateOffset.name": [""], "tseries.offsets.DateOffset.name": [""], "pandas.tseries.offsets.DateOffset.name": [""], "nanos": [""], "DateOffset.nanos": [""], "offsets.DateOffset.nanos": [""], "tseries.offsets.DateOffset.nanos": [""], "pandas.tseries.offsets.DateOffset.nanos": [""], "DateOffset.normalize": [""], "offsets.DateOffset.normalize": [""], "tseries.offsets.DateOffset.normalize": [""], "pandas.tseries.offsets.DateOffset.normalize": [""], "rule_code": [""], "DateOffset.rule_code": [""], "offsets.DateOffset.rule_code": [""], "tseries.offsets.DateOffset.rule_code": [""], "pandas.tseries.offsets.DateOffset.rule_code": [""], "n": [""], "DateOffset.n": [""], "offsets.DateOffset.n": [""], "tseries.offsets.DateOffset.n": [""], "pandas.tseries.offsets.DateOffset.n": [""], "DateOffset.is_month_start": [""], "offsets.DateOffset.is_month_start": [""], "tseries.offsets.DateOffset.is_month_start": [""], "pandas.tseries.offsets.DateOffset.is_month_start": [""], "DateOffset.is_month_end": [""], "offsets.DateOffset.is_month_end": [""], "tseries.offsets.DateOffset.is_month_end": [""], "pandas.tseries.offsets.DateOffset.is_month_end": [""], "DateOffset.apply": [""], "offsets.DateOffset.apply": [""], "tseries.offsets.DateOffset.apply": [""], "pandas.tseries.offsets.DateOffset.apply": [""], "apply_index": ["", "Apply a CSS-styling function to the index or column headers, level-wise."], "DateOffset.apply_index": [""], "offsets.DateOffset.apply_index": [""], "tseries.offsets.DateOffset.apply_index": [""], "pandas.tseries.offsets.DateOffset.apply_index": [""], "DateOffset.copy": [""], "offsets.DateOffset.copy": [""], "tseries.offsets.DateOffset.copy": [""], "pandas.tseries.offsets.DateOffset.copy": [""], "isAnchored": [""], "DateOffset.isAnchored": [""], "offsets.DateOffset.isAnchored": [""], "tseries.offsets.DateOffset.isAnchored": [""], "pandas.tseries.offsets.DateOffset.isAnchored": [""], "onOffset": [""], "DateOffset.onOffset": [""], "offsets.DateOffset.onOffset": [""], "tseries.offsets.DateOffset.onOffset": [""], "pandas.tseries.offsets.DateOffset.onOffset": [""], "is_anchored": [""], "DateOffset.is_anchored": [""], "offsets.DateOffset.is_anchored": [""], "tseries.offsets.DateOffset.is_anchored": [""], "pandas.tseries.offsets.DateOffset.is_anchored": [""], "is_on_offset": [""], "DateOffset.is_on_offset": [""], "offsets.DateOffset.is_on_offset": [""], "tseries.offsets.DateOffset.is_on_offset": [""], "pandas.tseries.offsets.DateOffset.is_on_offset": [""], "__call__": ["Call self as a function."], "DateOffset.__call__": ["Call self as a function."], "offsets.DateOffset.__call__": ["Call self as a function."], "tseries.offsets.DateOffset.__call__": ["Call self as a function."], "pandas.tseries.offsets.DateOffset.__call__": ["Call self as a function."], "DateOffset.is_quarter_start": [""], "offsets.DateOffset.is_quarter_start": [""], "tseries.offsets.DateOffset.is_quarter_start": [""], "pandas.tseries.offsets.DateOffset.is_quarter_start": [""], "DateOffset.is_quarter_end": [""], "offsets.DateOffset.is_quarter_end": [""], "tseries.offsets.DateOffset.is_quarter_end": [""], "pandas.tseries.offsets.DateOffset.is_quarter_end": [""], "DateOffset.is_year_start": [""], "offsets.DateOffset.is_year_start": [""], "tseries.offsets.DateOffset.is_year_start": [""], "pandas.tseries.offsets.DateOffset.is_year_start": [""], "DateOffset.is_year_end": [""], "offsets.DateOffset.is_year_end": [""], "tseries.offsets.DateOffset.is_year_end": [""], "pandas.tseries.offsets.DateOffset.is_year_end": [""], "BusinessDay": ["DateOffset subclass representing possibly n business days."], "offsets.BusinessDay": ["DateOffset subclass representing possibly n business days."], "tseries.offsets.BusinessDay": ["DateOffset subclass representing possibly n business days."], "pandas.tseries.offsets.BusinessDay": ["DateOffset subclass representing possibly n business days."], "BDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay\" title=\"pandas._libs.tslibs.offsets.BusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessDay</span></code></a"], "offsets.BDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay\" title=\"pandas._libs.tslibs.offsets.BusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessDay</span></code></a"], "tseries.offsets.BDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay\" title=\"pandas._libs.tslibs.offsets.BusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessDay</span></code></a"], "pandas.tseries.offsets.BDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessDay.html#pandas.tseries.offsets.BusinessDay\" title=\"pandas._libs.tslibs.offsets.BusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessDay</span></code></a"], "BusinessDay.freqstr": [""], "offsets.BusinessDay.freqstr": [""], "tseries.offsets.BusinessDay.freqstr": [""], "pandas.tseries.offsets.BusinessDay.freqstr": [""], "BusinessDay.kwds": [""], "offsets.BusinessDay.kwds": [""], "tseries.offsets.BusinessDay.kwds": [""], "pandas.tseries.offsets.BusinessDay.kwds": [""], "BusinessDay.name": [""], "offsets.BusinessDay.name": [""], "tseries.offsets.BusinessDay.name": [""], "pandas.tseries.offsets.BusinessDay.name": [""], "BusinessDay.nanos": [""], "offsets.BusinessDay.nanos": [""], "tseries.offsets.BusinessDay.nanos": [""], "pandas.tseries.offsets.BusinessDay.nanos": [""], "BusinessDay.normalize": [""], "offsets.BusinessDay.normalize": [""], "tseries.offsets.BusinessDay.normalize": [""], "pandas.tseries.offsets.BusinessDay.normalize": [""], "BusinessDay.rule_code": [""], "offsets.BusinessDay.rule_code": [""], "tseries.offsets.BusinessDay.rule_code": [""], "pandas.tseries.offsets.BusinessDay.rule_code": [""], "BusinessDay.n": [""], "offsets.BusinessDay.n": [""], "tseries.offsets.BusinessDay.n": [""], "pandas.tseries.offsets.BusinessDay.n": [""], "weekmask": [""], "BusinessDay.weekmask": [""], "offsets.BusinessDay.weekmask": [""], "tseries.offsets.BusinessDay.weekmask": [""], "pandas.tseries.offsets.BusinessDay.weekmask": [""], "holidays": [""], "BusinessDay.holidays": [""], "offsets.BusinessDay.holidays": [""], "tseries.offsets.BusinessDay.holidays": [""], "pandas.tseries.offsets.BusinessDay.holidays": [""], "calendar": [""], "BusinessDay.calendar": [""], "offsets.BusinessDay.calendar": [""], "tseries.offsets.BusinessDay.calendar": [""], "pandas.tseries.offsets.BusinessDay.calendar": [""], "BusinessDay.apply": [""], "offsets.BusinessDay.apply": [""], "tseries.offsets.BusinessDay.apply": [""], "pandas.tseries.offsets.BusinessDay.apply": [""], "BusinessDay.apply_index": [""], "offsets.BusinessDay.apply_index": [""], "tseries.offsets.BusinessDay.apply_index": [""], "pandas.tseries.offsets.BusinessDay.apply_index": [""], "BusinessDay.copy": [""], "offsets.BusinessDay.copy": [""], "tseries.offsets.BusinessDay.copy": [""], "pandas.tseries.offsets.BusinessDay.copy": [""], "BusinessDay.isAnchored": [""], "offsets.BusinessDay.isAnchored": [""], "tseries.offsets.BusinessDay.isAnchored": [""], "pandas.tseries.offsets.BusinessDay.isAnchored": [""], "BusinessDay.onOffset": [""], "offsets.BusinessDay.onOffset": [""], "tseries.offsets.BusinessDay.onOffset": [""], "pandas.tseries.offsets.BusinessDay.onOffset": [""], "BusinessDay.is_anchored": [""], "offsets.BusinessDay.is_anchored": [""], "tseries.offsets.BusinessDay.is_anchored": [""], "pandas.tseries.offsets.BusinessDay.is_anchored": [""], "BusinessDay.is_on_offset": [""], "offsets.BusinessDay.is_on_offset": [""], "tseries.offsets.BusinessDay.is_on_offset": [""], "pandas.tseries.offsets.BusinessDay.is_on_offset": [""], "BusinessDay.__call__": ["Call self as a function."], "offsets.BusinessDay.__call__": ["Call self as a function."], "tseries.offsets.BusinessDay.__call__": ["Call self as a function."], "pandas.tseries.offsets.BusinessDay.__call__": ["Call self as a function."], "BusinessDay.is_month_start": [""], "offsets.BusinessDay.is_month_start": [""], "tseries.offsets.BusinessDay.is_month_start": [""], "pandas.tseries.offsets.BusinessDay.is_month_start": [""], "BusinessDay.is_month_end": [""], "offsets.BusinessDay.is_month_end": [""], "tseries.offsets.BusinessDay.is_month_end": [""], "pandas.tseries.offsets.BusinessDay.is_month_end": [""], "BusinessDay.is_quarter_start": [""], "offsets.BusinessDay.is_quarter_start": [""], "tseries.offsets.BusinessDay.is_quarter_start": [""], "pandas.tseries.offsets.BusinessDay.is_quarter_start": [""], "BusinessDay.is_quarter_end": [""], "offsets.BusinessDay.is_quarter_end": [""], "tseries.offsets.BusinessDay.is_quarter_end": [""], "pandas.tseries.offsets.BusinessDay.is_quarter_end": [""], "BusinessDay.is_year_start": [""], "offsets.BusinessDay.is_year_start": [""], "tseries.offsets.BusinessDay.is_year_start": [""], "pandas.tseries.offsets.BusinessDay.is_year_start": [""], "BusinessDay.is_year_end": [""], "offsets.BusinessDay.is_year_end": [""], "tseries.offsets.BusinessDay.is_year_end": [""], "pandas.tseries.offsets.BusinessDay.is_year_end": [""], "BusinessHour": ["DateOffset subclass representing possibly n business hours."], "offsets.BusinessHour": ["DateOffset subclass representing possibly n business hours."], "tseries.offsets.BusinessHour": ["DateOffset subclass representing possibly n business hours."], "pandas.tseries.offsets.BusinessHour": ["DateOffset subclass representing possibly n business hours."], "BusinessHour.freqstr": [""], "offsets.BusinessHour.freqstr": [""], "tseries.offsets.BusinessHour.freqstr": [""], "pandas.tseries.offsets.BusinessHour.freqstr": [""], "BusinessHour.kwds": [""], "offsets.BusinessHour.kwds": [""], "tseries.offsets.BusinessHour.kwds": [""], "pandas.tseries.offsets.BusinessHour.kwds": [""], "BusinessHour.name": [""], "offsets.BusinessHour.name": [""], "tseries.offsets.BusinessHour.name": [""], "pandas.tseries.offsets.BusinessHour.name": [""], "BusinessHour.nanos": [""], "offsets.BusinessHour.nanos": [""], "tseries.offsets.BusinessHour.nanos": [""], "pandas.tseries.offsets.BusinessHour.nanos": [""], "BusinessHour.normalize": [""], "offsets.BusinessHour.normalize": [""], "tseries.offsets.BusinessHour.normalize": [""], "pandas.tseries.offsets.BusinessHour.normalize": [""], "BusinessHour.rule_code": [""], "offsets.BusinessHour.rule_code": [""], "tseries.offsets.BusinessHour.rule_code": [""], "pandas.tseries.offsets.BusinessHour.rule_code": [""], "BusinessHour.n": [""], "offsets.BusinessHour.n": [""], "tseries.offsets.BusinessHour.n": [""], "pandas.tseries.offsets.BusinessHour.n": [""], "BusinessHour.start": [""], "offsets.BusinessHour.start": [""], "tseries.offsets.BusinessHour.start": [""], "pandas.tseries.offsets.BusinessHour.start": [""], "end": [""], "BusinessHour.end": [""], "offsets.BusinessHour.end": [""], "tseries.offsets.BusinessHour.end": [""], "pandas.tseries.offsets.BusinessHour.end": [""], "BusinessHour.weekmask": [""], "offsets.BusinessHour.weekmask": [""], "tseries.offsets.BusinessHour.weekmask": [""], "pandas.tseries.offsets.BusinessHour.weekmask": [""], "BusinessHour.holidays": [""], "offsets.BusinessHour.holidays": [""], "tseries.offsets.BusinessHour.holidays": [""], "pandas.tseries.offsets.BusinessHour.holidays": [""], "BusinessHour.calendar": [""], "offsets.BusinessHour.calendar": [""], "tseries.offsets.BusinessHour.calendar": [""], "pandas.tseries.offsets.BusinessHour.calendar": [""], "BusinessHour.apply": [""], "offsets.BusinessHour.apply": [""], "tseries.offsets.BusinessHour.apply": [""], "pandas.tseries.offsets.BusinessHour.apply": [""], "BusinessHour.apply_index": [""], "offsets.BusinessHour.apply_index": [""], "tseries.offsets.BusinessHour.apply_index": [""], "pandas.tseries.offsets.BusinessHour.apply_index": [""], "BusinessHour.copy": [""], "offsets.BusinessHour.copy": [""], "tseries.offsets.BusinessHour.copy": [""], "pandas.tseries.offsets.BusinessHour.copy": [""], "BusinessHour.isAnchored": [""], "offsets.BusinessHour.isAnchored": [""], "tseries.offsets.BusinessHour.isAnchored": [""], "pandas.tseries.offsets.BusinessHour.isAnchored": [""], "BusinessHour.onOffset": [""], "offsets.BusinessHour.onOffset": [""], "tseries.offsets.BusinessHour.onOffset": [""], "pandas.tseries.offsets.BusinessHour.onOffset": [""], "BusinessHour.is_anchored": [""], "offsets.BusinessHour.is_anchored": [""], "tseries.offsets.BusinessHour.is_anchored": [""], "pandas.tseries.offsets.BusinessHour.is_anchored": [""], "BusinessHour.is_on_offset": [""], "offsets.BusinessHour.is_on_offset": [""], "tseries.offsets.BusinessHour.is_on_offset": [""], "pandas.tseries.offsets.BusinessHour.is_on_offset": [""], "BusinessHour.__call__": ["Call self as a function."], "offsets.BusinessHour.__call__": ["Call self as a function."], "tseries.offsets.BusinessHour.__call__": ["Call self as a function."], "pandas.tseries.offsets.BusinessHour.__call__": ["Call self as a function."], "BusinessHour.is_month_start": [""], "offsets.BusinessHour.is_month_start": [""], "tseries.offsets.BusinessHour.is_month_start": [""], "pandas.tseries.offsets.BusinessHour.is_month_start": [""], "BusinessHour.is_month_end": [""], "offsets.BusinessHour.is_month_end": [""], "tseries.offsets.BusinessHour.is_month_end": [""], "pandas.tseries.offsets.BusinessHour.is_month_end": [""], "BusinessHour.is_quarter_start": [""], "offsets.BusinessHour.is_quarter_start": [""], "tseries.offsets.BusinessHour.is_quarter_start": [""], "pandas.tseries.offsets.BusinessHour.is_quarter_start": [""], "BusinessHour.is_quarter_end": [""], "offsets.BusinessHour.is_quarter_end": [""], "tseries.offsets.BusinessHour.is_quarter_end": [""], "pandas.tseries.offsets.BusinessHour.is_quarter_end": [""], "BusinessHour.is_year_start": [""], "offsets.BusinessHour.is_year_start": [""], "tseries.offsets.BusinessHour.is_year_start": [""], "pandas.tseries.offsets.BusinessHour.is_year_start": [""], "BusinessHour.is_year_end": [""], "offsets.BusinessHour.is_year_end": [""], "tseries.offsets.BusinessHour.is_year_end": [""], "pandas.tseries.offsets.BusinessHour.is_year_end": [""], "CustomBusinessDay": ["DateOffset subclass representing custom business days excluding holidays."], "offsets.CustomBusinessDay": ["DateOffset subclass representing custom business days excluding holidays."], "tseries.offsets.CustomBusinessDay": ["DateOffset subclass representing custom business days excluding holidays."], "pandas.tseries.offsets.CustomBusinessDay": ["DateOffset subclass representing custom business days excluding holidays."], "CDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay\" title=\"pandas._libs.tslibs.offsets.CustomBusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessDay</span></code></a"], "offsets.CDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay\" title=\"pandas._libs.tslibs.offsets.CustomBusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessDay</span></code></a"], "tseries.offsets.CDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay\" title=\"pandas._libs.tslibs.offsets.CustomBusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessDay</span></code></a"], "pandas.tseries.offsets.CDay": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessDay.html#pandas.tseries.offsets.CustomBusinessDay\" title=\"pandas._libs.tslibs.offsets.CustomBusinessDay\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessDay</span></code></a"], "CustomBusinessDay.freqstr": [""], "offsets.CustomBusinessDay.freqstr": [""], "tseries.offsets.CustomBusinessDay.freqstr": [""], "pandas.tseries.offsets.CustomBusinessDay.freqstr": [""], "CustomBusinessDay.kwds": [""], "offsets.CustomBusinessDay.kwds": [""], "tseries.offsets.CustomBusinessDay.kwds": [""], "pandas.tseries.offsets.CustomBusinessDay.kwds": [""], "CustomBusinessDay.name": [""], "offsets.CustomBusinessDay.name": [""], "tseries.offsets.CustomBusinessDay.name": [""], "pandas.tseries.offsets.CustomBusinessDay.name": [""], "CustomBusinessDay.nanos": [""], "offsets.CustomBusinessDay.nanos": [""], "tseries.offsets.CustomBusinessDay.nanos": [""], "pandas.tseries.offsets.CustomBusinessDay.nanos": [""], "CustomBusinessDay.normalize": [""], "offsets.CustomBusinessDay.normalize": [""], "tseries.offsets.CustomBusinessDay.normalize": [""], "pandas.tseries.offsets.CustomBusinessDay.normalize": [""], "CustomBusinessDay.rule_code": [""], "offsets.CustomBusinessDay.rule_code": [""], "tseries.offsets.CustomBusinessDay.rule_code": [""], "pandas.tseries.offsets.CustomBusinessDay.rule_code": [""], "CustomBusinessDay.n": [""], "offsets.CustomBusinessDay.n": [""], "tseries.offsets.CustomBusinessDay.n": [""], "pandas.tseries.offsets.CustomBusinessDay.n": [""], "CustomBusinessDay.weekmask": [""], "offsets.CustomBusinessDay.weekmask": [""], "tseries.offsets.CustomBusinessDay.weekmask": [""], "pandas.tseries.offsets.CustomBusinessDay.weekmask": [""], "CustomBusinessDay.calendar": [""], "offsets.CustomBusinessDay.calendar": [""], "tseries.offsets.CustomBusinessDay.calendar": [""], "pandas.tseries.offsets.CustomBusinessDay.calendar": [""], "CustomBusinessDay.holidays": [""], "offsets.CustomBusinessDay.holidays": [""], "tseries.offsets.CustomBusinessDay.holidays": [""], "pandas.tseries.offsets.CustomBusinessDay.holidays": [""], "CustomBusinessDay.apply_index": [""], "offsets.CustomBusinessDay.apply_index": [""], "tseries.offsets.CustomBusinessDay.apply_index": [""], "pandas.tseries.offsets.CustomBusinessDay.apply_index": [""], "CustomBusinessDay.apply": [""], "offsets.CustomBusinessDay.apply": [""], "tseries.offsets.CustomBusinessDay.apply": [""], "pandas.tseries.offsets.CustomBusinessDay.apply": [""], "CustomBusinessDay.copy": [""], "offsets.CustomBusinessDay.copy": [""], "tseries.offsets.CustomBusinessDay.copy": [""], "pandas.tseries.offsets.CustomBusinessDay.copy": [""], "CustomBusinessDay.isAnchored": [""], "offsets.CustomBusinessDay.isAnchored": [""], "tseries.offsets.CustomBusinessDay.isAnchored": [""], "pandas.tseries.offsets.CustomBusinessDay.isAnchored": [""], "CustomBusinessDay.onOffset": [""], "offsets.CustomBusinessDay.onOffset": [""], "tseries.offsets.CustomBusinessDay.onOffset": [""], "pandas.tseries.offsets.CustomBusinessDay.onOffset": [""], "CustomBusinessDay.is_anchored": [""], "offsets.CustomBusinessDay.is_anchored": [""], "tseries.offsets.CustomBusinessDay.is_anchored": [""], "pandas.tseries.offsets.CustomBusinessDay.is_anchored": [""], "CustomBusinessDay.is_on_offset": [""], "offsets.CustomBusinessDay.is_on_offset": [""], "tseries.offsets.CustomBusinessDay.is_on_offset": [""], "pandas.tseries.offsets.CustomBusinessDay.is_on_offset": [""], "CustomBusinessDay.__call__": ["Call self as a function."], "offsets.CustomBusinessDay.__call__": ["Call self as a function."], "tseries.offsets.CustomBusinessDay.__call__": ["Call self as a function."], "pandas.tseries.offsets.CustomBusinessDay.__call__": ["Call self as a function."], "CustomBusinessDay.is_month_start": [""], "offsets.CustomBusinessDay.is_month_start": [""], "tseries.offsets.CustomBusinessDay.is_month_start": [""], "pandas.tseries.offsets.CustomBusinessDay.is_month_start": [""], "CustomBusinessDay.is_month_end": [""], "offsets.CustomBusinessDay.is_month_end": [""], "tseries.offsets.CustomBusinessDay.is_month_end": [""], "pandas.tseries.offsets.CustomBusinessDay.is_month_end": [""], "CustomBusinessDay.is_quarter_start": [""], "offsets.CustomBusinessDay.is_quarter_start": [""], "tseries.offsets.CustomBusinessDay.is_quarter_start": [""], "pandas.tseries.offsets.CustomBusinessDay.is_quarter_start": [""], "CustomBusinessDay.is_quarter_end": [""], "offsets.CustomBusinessDay.is_quarter_end": [""], "tseries.offsets.CustomBusinessDay.is_quarter_end": [""], "pandas.tseries.offsets.CustomBusinessDay.is_quarter_end": [""], "CustomBusinessDay.is_year_start": [""], "offsets.CustomBusinessDay.is_year_start": [""], "tseries.offsets.CustomBusinessDay.is_year_start": [""], "pandas.tseries.offsets.CustomBusinessDay.is_year_start": [""], "CustomBusinessDay.is_year_end": [""], "offsets.CustomBusinessDay.is_year_end": [""], "tseries.offsets.CustomBusinessDay.is_year_end": [""], "pandas.tseries.offsets.CustomBusinessDay.is_year_end": [""], "CustomBusinessHour": ["DateOffset subclass representing possibly n custom business days."], "offsets.CustomBusinessHour": ["DateOffset subclass representing possibly n custom business days."], "tseries.offsets.CustomBusinessHour": ["DateOffset subclass representing possibly n custom business days."], "pandas.tseries.offsets.CustomBusinessHour": ["DateOffset subclass representing possibly n custom business days."], "CustomBusinessHour.freqstr": [""], "offsets.CustomBusinessHour.freqstr": [""], "tseries.offsets.CustomBusinessHour.freqstr": [""], "pandas.tseries.offsets.CustomBusinessHour.freqstr": [""], "CustomBusinessHour.kwds": [""], "offsets.CustomBusinessHour.kwds": [""], "tseries.offsets.CustomBusinessHour.kwds": [""], "pandas.tseries.offsets.CustomBusinessHour.kwds": [""], "CustomBusinessHour.name": [""], "offsets.CustomBusinessHour.name": [""], "tseries.offsets.CustomBusinessHour.name": [""], "pandas.tseries.offsets.CustomBusinessHour.name": [""], "CustomBusinessHour.nanos": [""], "offsets.CustomBusinessHour.nanos": [""], "tseries.offsets.CustomBusinessHour.nanos": [""], "pandas.tseries.offsets.CustomBusinessHour.nanos": [""], "CustomBusinessHour.normalize": [""], "offsets.CustomBusinessHour.normalize": [""], "tseries.offsets.CustomBusinessHour.normalize": [""], "pandas.tseries.offsets.CustomBusinessHour.normalize": [""], "CustomBusinessHour.rule_code": [""], "offsets.CustomBusinessHour.rule_code": [""], "tseries.offsets.CustomBusinessHour.rule_code": [""], "pandas.tseries.offsets.CustomBusinessHour.rule_code": [""], "CustomBusinessHour.n": [""], "offsets.CustomBusinessHour.n": [""], "tseries.offsets.CustomBusinessHour.n": [""], "pandas.tseries.offsets.CustomBusinessHour.n": [""], "CustomBusinessHour.weekmask": [""], "offsets.CustomBusinessHour.weekmask": [""], "tseries.offsets.CustomBusinessHour.weekmask": [""], "pandas.tseries.offsets.CustomBusinessHour.weekmask": [""], "CustomBusinessHour.calendar": [""], "offsets.CustomBusinessHour.calendar": [""], "tseries.offsets.CustomBusinessHour.calendar": [""], "pandas.tseries.offsets.CustomBusinessHour.calendar": [""], "CustomBusinessHour.holidays": [""], "offsets.CustomBusinessHour.holidays": [""], "tseries.offsets.CustomBusinessHour.holidays": [""], "pandas.tseries.offsets.CustomBusinessHour.holidays": [""], "CustomBusinessHour.start": [""], "offsets.CustomBusinessHour.start": [""], "tseries.offsets.CustomBusinessHour.start": [""], "pandas.tseries.offsets.CustomBusinessHour.start": [""], "CustomBusinessHour.end": [""], "offsets.CustomBusinessHour.end": [""], "tseries.offsets.CustomBusinessHour.end": [""], "pandas.tseries.offsets.CustomBusinessHour.end": [""], "CustomBusinessHour.apply": [""], "offsets.CustomBusinessHour.apply": [""], "tseries.offsets.CustomBusinessHour.apply": [""], "pandas.tseries.offsets.CustomBusinessHour.apply": [""], "CustomBusinessHour.apply_index": [""], "offsets.CustomBusinessHour.apply_index": [""], "tseries.offsets.CustomBusinessHour.apply_index": [""], "pandas.tseries.offsets.CustomBusinessHour.apply_index": [""], "CustomBusinessHour.copy": [""], "offsets.CustomBusinessHour.copy": [""], "tseries.offsets.CustomBusinessHour.copy": [""], "pandas.tseries.offsets.CustomBusinessHour.copy": [""], "CustomBusinessHour.isAnchored": [""], "offsets.CustomBusinessHour.isAnchored": [""], "tseries.offsets.CustomBusinessHour.isAnchored": [""], "pandas.tseries.offsets.CustomBusinessHour.isAnchored": [""], "CustomBusinessHour.onOffset": [""], "offsets.CustomBusinessHour.onOffset": [""], "tseries.offsets.CustomBusinessHour.onOffset": [""], "pandas.tseries.offsets.CustomBusinessHour.onOffset": [""], "CustomBusinessHour.is_anchored": [""], "offsets.CustomBusinessHour.is_anchored": [""], "tseries.offsets.CustomBusinessHour.is_anchored": [""], "pandas.tseries.offsets.CustomBusinessHour.is_anchored": [""], "CustomBusinessHour.is_on_offset": [""], "offsets.CustomBusinessHour.is_on_offset": [""], "tseries.offsets.CustomBusinessHour.is_on_offset": [""], "pandas.tseries.offsets.CustomBusinessHour.is_on_offset": [""], "CustomBusinessHour.__call__": ["Call self as a function."], "offsets.CustomBusinessHour.__call__": ["Call self as a function."], "tseries.offsets.CustomBusinessHour.__call__": ["Call self as a function."], "pandas.tseries.offsets.CustomBusinessHour.__call__": ["Call self as a function."], "CustomBusinessHour.is_month_start": [""], "offsets.CustomBusinessHour.is_month_start": [""], "tseries.offsets.CustomBusinessHour.is_month_start": [""], "pandas.tseries.offsets.CustomBusinessHour.is_month_start": [""], "CustomBusinessHour.is_month_end": [""], "offsets.CustomBusinessHour.is_month_end": [""], "tseries.offsets.CustomBusinessHour.is_month_end": [""], "pandas.tseries.offsets.CustomBusinessHour.is_month_end": [""], "CustomBusinessHour.is_quarter_start": [""], "offsets.CustomBusinessHour.is_quarter_start": [""], "tseries.offsets.CustomBusinessHour.is_quarter_start": [""], "pandas.tseries.offsets.CustomBusinessHour.is_quarter_start": [""], "CustomBusinessHour.is_quarter_end": [""], "offsets.CustomBusinessHour.is_quarter_end": [""], "tseries.offsets.CustomBusinessHour.is_quarter_end": [""], "pandas.tseries.offsets.CustomBusinessHour.is_quarter_end": [""], "CustomBusinessHour.is_year_start": [""], "offsets.CustomBusinessHour.is_year_start": [""], "tseries.offsets.CustomBusinessHour.is_year_start": [""], "pandas.tseries.offsets.CustomBusinessHour.is_year_start": [""], "CustomBusinessHour.is_year_end": [""], "offsets.CustomBusinessHour.is_year_end": [""], "tseries.offsets.CustomBusinessHour.is_year_end": [""], "pandas.tseries.offsets.CustomBusinessHour.is_year_end": [""], "MonthEnd": ["DateOffset of one month end."], "offsets.MonthEnd": ["DateOffset of one month end."], "tseries.offsets.MonthEnd": ["DateOffset of one month end."], "pandas.tseries.offsets.MonthEnd": ["DateOffset of one month end."], "MonthEnd.freqstr": [""], "offsets.MonthEnd.freqstr": [""], "tseries.offsets.MonthEnd.freqstr": [""], "pandas.tseries.offsets.MonthEnd.freqstr": [""], "MonthEnd.kwds": [""], "offsets.MonthEnd.kwds": [""], "tseries.offsets.MonthEnd.kwds": [""], "pandas.tseries.offsets.MonthEnd.kwds": [""], "MonthEnd.name": [""], "offsets.MonthEnd.name": [""], "tseries.offsets.MonthEnd.name": [""], "pandas.tseries.offsets.MonthEnd.name": [""], "MonthEnd.nanos": [""], "offsets.MonthEnd.nanos": [""], "tseries.offsets.MonthEnd.nanos": [""], "pandas.tseries.offsets.MonthEnd.nanos": [""], "MonthEnd.normalize": [""], "offsets.MonthEnd.normalize": [""], "tseries.offsets.MonthEnd.normalize": [""], "pandas.tseries.offsets.MonthEnd.normalize": [""], "MonthEnd.rule_code": [""], "offsets.MonthEnd.rule_code": [""], "tseries.offsets.MonthEnd.rule_code": [""], "pandas.tseries.offsets.MonthEnd.rule_code": [""], "MonthEnd.n": [""], "offsets.MonthEnd.n": [""], "tseries.offsets.MonthEnd.n": [""], "pandas.tseries.offsets.MonthEnd.n": [""], "MonthEnd.apply": [""], "offsets.MonthEnd.apply": [""], "tseries.offsets.MonthEnd.apply": [""], "pandas.tseries.offsets.MonthEnd.apply": [""], "MonthEnd.apply_index": [""], "offsets.MonthEnd.apply_index": [""], "tseries.offsets.MonthEnd.apply_index": [""], "pandas.tseries.offsets.MonthEnd.apply_index": [""], "MonthEnd.copy": [""], "offsets.MonthEnd.copy": [""], "tseries.offsets.MonthEnd.copy": [""], "pandas.tseries.offsets.MonthEnd.copy": [""], "MonthEnd.isAnchored": [""], "offsets.MonthEnd.isAnchored": [""], "tseries.offsets.MonthEnd.isAnchored": [""], "pandas.tseries.offsets.MonthEnd.isAnchored": [""], "MonthEnd.onOffset": [""], "offsets.MonthEnd.onOffset": [""], "tseries.offsets.MonthEnd.onOffset": [""], "pandas.tseries.offsets.MonthEnd.onOffset": [""], "MonthEnd.is_anchored": [""], "offsets.MonthEnd.is_anchored": [""], "tseries.offsets.MonthEnd.is_anchored": [""], "pandas.tseries.offsets.MonthEnd.is_anchored": [""], "MonthEnd.is_on_offset": [""], "offsets.MonthEnd.is_on_offset": [""], "tseries.offsets.MonthEnd.is_on_offset": [""], "pandas.tseries.offsets.MonthEnd.is_on_offset": [""], "MonthEnd.__call__": ["Call self as a function."], "offsets.MonthEnd.__call__": ["Call self as a function."], "tseries.offsets.MonthEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.MonthEnd.__call__": ["Call self as a function."], "MonthEnd.is_month_start": [""], "offsets.MonthEnd.is_month_start": [""], "tseries.offsets.MonthEnd.is_month_start": [""], "pandas.tseries.offsets.MonthEnd.is_month_start": [""], "MonthEnd.is_month_end": [""], "offsets.MonthEnd.is_month_end": [""], "tseries.offsets.MonthEnd.is_month_end": [""], "pandas.tseries.offsets.MonthEnd.is_month_end": [""], "MonthEnd.is_quarter_start": [""], "offsets.MonthEnd.is_quarter_start": [""], "tseries.offsets.MonthEnd.is_quarter_start": [""], "pandas.tseries.offsets.MonthEnd.is_quarter_start": [""], "MonthEnd.is_quarter_end": [""], "offsets.MonthEnd.is_quarter_end": [""], "tseries.offsets.MonthEnd.is_quarter_end": [""], "pandas.tseries.offsets.MonthEnd.is_quarter_end": [""], "MonthEnd.is_year_start": [""], "offsets.MonthEnd.is_year_start": [""], "tseries.offsets.MonthEnd.is_year_start": [""], "pandas.tseries.offsets.MonthEnd.is_year_start": [""], "MonthEnd.is_year_end": [""], "offsets.MonthEnd.is_year_end": [""], "tseries.offsets.MonthEnd.is_year_end": [""], "pandas.tseries.offsets.MonthEnd.is_year_end": [""], "MonthBegin": ["DateOffset of one month at beginning."], "offsets.MonthBegin": ["DateOffset of one month at beginning."], "tseries.offsets.MonthBegin": ["DateOffset of one month at beginning."], "pandas.tseries.offsets.MonthBegin": ["DateOffset of one month at beginning."], "MonthBegin.freqstr": [""], "offsets.MonthBegin.freqstr": [""], "tseries.offsets.MonthBegin.freqstr": [""], "pandas.tseries.offsets.MonthBegin.freqstr": [""], "MonthBegin.kwds": [""], "offsets.MonthBegin.kwds": [""], "tseries.offsets.MonthBegin.kwds": [""], "pandas.tseries.offsets.MonthBegin.kwds": [""], "MonthBegin.name": [""], "offsets.MonthBegin.name": [""], "tseries.offsets.MonthBegin.name": [""], "pandas.tseries.offsets.MonthBegin.name": [""], "MonthBegin.nanos": [""], "offsets.MonthBegin.nanos": [""], "tseries.offsets.MonthBegin.nanos": [""], "pandas.tseries.offsets.MonthBegin.nanos": [""], "MonthBegin.normalize": [""], "offsets.MonthBegin.normalize": [""], "tseries.offsets.MonthBegin.normalize": [""], "pandas.tseries.offsets.MonthBegin.normalize": [""], "MonthBegin.rule_code": [""], "offsets.MonthBegin.rule_code": [""], "tseries.offsets.MonthBegin.rule_code": [""], "pandas.tseries.offsets.MonthBegin.rule_code": [""], "MonthBegin.n": [""], "offsets.MonthBegin.n": [""], "tseries.offsets.MonthBegin.n": [""], "pandas.tseries.offsets.MonthBegin.n": [""], "MonthBegin.apply": [""], "offsets.MonthBegin.apply": [""], "tseries.offsets.MonthBegin.apply": [""], "pandas.tseries.offsets.MonthBegin.apply": [""], "MonthBegin.apply_index": [""], "offsets.MonthBegin.apply_index": [""], "tseries.offsets.MonthBegin.apply_index": [""], "pandas.tseries.offsets.MonthBegin.apply_index": [""], "MonthBegin.copy": [""], "offsets.MonthBegin.copy": [""], "tseries.offsets.MonthBegin.copy": [""], "pandas.tseries.offsets.MonthBegin.copy": [""], "MonthBegin.isAnchored": [""], "offsets.MonthBegin.isAnchored": [""], "tseries.offsets.MonthBegin.isAnchored": [""], "pandas.tseries.offsets.MonthBegin.isAnchored": [""], "MonthBegin.onOffset": [""], "offsets.MonthBegin.onOffset": [""], "tseries.offsets.MonthBegin.onOffset": [""], "pandas.tseries.offsets.MonthBegin.onOffset": [""], "MonthBegin.is_anchored": [""], "offsets.MonthBegin.is_anchored": [""], "tseries.offsets.MonthBegin.is_anchored": [""], "pandas.tseries.offsets.MonthBegin.is_anchored": [""], "MonthBegin.is_on_offset": [""], "offsets.MonthBegin.is_on_offset": [""], "tseries.offsets.MonthBegin.is_on_offset": [""], "pandas.tseries.offsets.MonthBegin.is_on_offset": [""], "MonthBegin.__call__": ["Call self as a function."], "offsets.MonthBegin.__call__": ["Call self as a function."], "tseries.offsets.MonthBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.MonthBegin.__call__": ["Call self as a function."], "MonthBegin.is_month_start": [""], "offsets.MonthBegin.is_month_start": [""], "tseries.offsets.MonthBegin.is_month_start": [""], "pandas.tseries.offsets.MonthBegin.is_month_start": [""], "MonthBegin.is_month_end": [""], "offsets.MonthBegin.is_month_end": [""], "tseries.offsets.MonthBegin.is_month_end": [""], "pandas.tseries.offsets.MonthBegin.is_month_end": [""], "MonthBegin.is_quarter_start": [""], "offsets.MonthBegin.is_quarter_start": [""], "tseries.offsets.MonthBegin.is_quarter_start": [""], "pandas.tseries.offsets.MonthBegin.is_quarter_start": [""], "MonthBegin.is_quarter_end": [""], "offsets.MonthBegin.is_quarter_end": [""], "tseries.offsets.MonthBegin.is_quarter_end": [""], "pandas.tseries.offsets.MonthBegin.is_quarter_end": [""], "MonthBegin.is_year_start": [""], "offsets.MonthBegin.is_year_start": [""], "tseries.offsets.MonthBegin.is_year_start": [""], "pandas.tseries.offsets.MonthBegin.is_year_start": [""], "MonthBegin.is_year_end": [""], "offsets.MonthBegin.is_year_end": [""], "tseries.offsets.MonthBegin.is_year_end": [""], "pandas.tseries.offsets.MonthBegin.is_year_end": [""], "BusinessMonthEnd": ["DateOffset increments between the last business day of the month."], "offsets.BusinessMonthEnd": ["DateOffset increments between the last business day of the month."], "tseries.offsets.BusinessMonthEnd": ["DateOffset increments between the last business day of the month."], "pandas.tseries.offsets.BusinessMonthEnd": ["DateOffset increments between the last business day of the month."], "BMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.BusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthEnd</span></code></a"], "offsets.BMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.BusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthEnd</span></code></a"], "tseries.offsets.BMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.BusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthEnd</span></code></a"], "pandas.tseries.offsets.BMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthEnd.html#pandas.tseries.offsets.BusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.BusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthEnd</span></code></a"], "BusinessMonthEnd.freqstr": [""], "offsets.BusinessMonthEnd.freqstr": [""], "tseries.offsets.BusinessMonthEnd.freqstr": [""], "pandas.tseries.offsets.BusinessMonthEnd.freqstr": [""], "BusinessMonthEnd.kwds": [""], "offsets.BusinessMonthEnd.kwds": [""], "tseries.offsets.BusinessMonthEnd.kwds": [""], "pandas.tseries.offsets.BusinessMonthEnd.kwds": [""], "BusinessMonthEnd.name": [""], "offsets.BusinessMonthEnd.name": [""], "tseries.offsets.BusinessMonthEnd.name": [""], "pandas.tseries.offsets.BusinessMonthEnd.name": [""], "BusinessMonthEnd.nanos": [""], "offsets.BusinessMonthEnd.nanos": [""], "tseries.offsets.BusinessMonthEnd.nanos": [""], "pandas.tseries.offsets.BusinessMonthEnd.nanos": [""], "BusinessMonthEnd.normalize": [""], "offsets.BusinessMonthEnd.normalize": [""], "tseries.offsets.BusinessMonthEnd.normalize": [""], "pandas.tseries.offsets.BusinessMonthEnd.normalize": [""], "BusinessMonthEnd.rule_code": [""], "offsets.BusinessMonthEnd.rule_code": [""], "tseries.offsets.BusinessMonthEnd.rule_code": [""], "pandas.tseries.offsets.BusinessMonthEnd.rule_code": [""], "BusinessMonthEnd.n": [""], "offsets.BusinessMonthEnd.n": [""], "tseries.offsets.BusinessMonthEnd.n": [""], "pandas.tseries.offsets.BusinessMonthEnd.n": [""], "BusinessMonthEnd.apply": [""], "offsets.BusinessMonthEnd.apply": [""], "tseries.offsets.BusinessMonthEnd.apply": [""], "pandas.tseries.offsets.BusinessMonthEnd.apply": [""], "BusinessMonthEnd.apply_index": [""], "offsets.BusinessMonthEnd.apply_index": [""], "tseries.offsets.BusinessMonthEnd.apply_index": [""], "pandas.tseries.offsets.BusinessMonthEnd.apply_index": [""], "BusinessMonthEnd.copy": [""], "offsets.BusinessMonthEnd.copy": [""], "tseries.offsets.BusinessMonthEnd.copy": [""], "pandas.tseries.offsets.BusinessMonthEnd.copy": [""], "BusinessMonthEnd.isAnchored": [""], "offsets.BusinessMonthEnd.isAnchored": [""], "tseries.offsets.BusinessMonthEnd.isAnchored": [""], "pandas.tseries.offsets.BusinessMonthEnd.isAnchored": [""], "BusinessMonthEnd.onOffset": [""], "offsets.BusinessMonthEnd.onOffset": [""], "tseries.offsets.BusinessMonthEnd.onOffset": [""], "pandas.tseries.offsets.BusinessMonthEnd.onOffset": [""], "BusinessMonthEnd.is_anchored": [""], "offsets.BusinessMonthEnd.is_anchored": [""], "tseries.offsets.BusinessMonthEnd.is_anchored": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_anchored": [""], "BusinessMonthEnd.is_on_offset": [""], "offsets.BusinessMonthEnd.is_on_offset": [""], "tseries.offsets.BusinessMonthEnd.is_on_offset": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_on_offset": [""], "BusinessMonthEnd.__call__": ["Call self as a function."], "offsets.BusinessMonthEnd.__call__": ["Call self as a function."], "tseries.offsets.BusinessMonthEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.BusinessMonthEnd.__call__": ["Call self as a function."], "BusinessMonthEnd.is_month_start": [""], "offsets.BusinessMonthEnd.is_month_start": [""], "tseries.offsets.BusinessMonthEnd.is_month_start": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_month_start": [""], "BusinessMonthEnd.is_month_end": [""], "offsets.BusinessMonthEnd.is_month_end": [""], "tseries.offsets.BusinessMonthEnd.is_month_end": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_month_end": [""], "BusinessMonthEnd.is_quarter_start": [""], "offsets.BusinessMonthEnd.is_quarter_start": [""], "tseries.offsets.BusinessMonthEnd.is_quarter_start": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_quarter_start": [""], "BusinessMonthEnd.is_quarter_end": [""], "offsets.BusinessMonthEnd.is_quarter_end": [""], "tseries.offsets.BusinessMonthEnd.is_quarter_end": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_quarter_end": [""], "BusinessMonthEnd.is_year_start": [""], "offsets.BusinessMonthEnd.is_year_start": [""], "tseries.offsets.BusinessMonthEnd.is_year_start": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_year_start": [""], "BusinessMonthEnd.is_year_end": [""], "offsets.BusinessMonthEnd.is_year_end": [""], "tseries.offsets.BusinessMonthEnd.is_year_end": [""], "pandas.tseries.offsets.BusinessMonthEnd.is_year_end": [""], "BusinessMonthBegin": ["DateOffset of one month at the first business day."], "offsets.BusinessMonthBegin": ["DateOffset of one month at the first business day."], "tseries.offsets.BusinessMonthBegin": ["DateOffset of one month at the first business day."], "pandas.tseries.offsets.BusinessMonthBegin": ["DateOffset of one month at the first business day."], "BMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.BusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthBegin</span></code></a"], "offsets.BMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.BusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthBegin</span></code></a"], "tseries.offsets.BMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.BusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthBegin</span></code></a"], "pandas.tseries.offsets.BMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.BusinessMonthBegin.html#pandas.tseries.offsets.BusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.BusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.BusinessMonthBegin</span></code></a"], "BusinessMonthBegin.freqstr": [""], "offsets.BusinessMonthBegin.freqstr": [""], "tseries.offsets.BusinessMonthBegin.freqstr": [""], "pandas.tseries.offsets.BusinessMonthBegin.freqstr": [""], "BusinessMonthBegin.kwds": [""], "offsets.BusinessMonthBegin.kwds": [""], "tseries.offsets.BusinessMonthBegin.kwds": [""], "pandas.tseries.offsets.BusinessMonthBegin.kwds": [""], "BusinessMonthBegin.name": [""], "offsets.BusinessMonthBegin.name": [""], "tseries.offsets.BusinessMonthBegin.name": [""], "pandas.tseries.offsets.BusinessMonthBegin.name": [""], "BusinessMonthBegin.nanos": [""], "offsets.BusinessMonthBegin.nanos": [""], "tseries.offsets.BusinessMonthBegin.nanos": [""], "pandas.tseries.offsets.BusinessMonthBegin.nanos": [""], "BusinessMonthBegin.normalize": [""], "offsets.BusinessMonthBegin.normalize": [""], "tseries.offsets.BusinessMonthBegin.normalize": [""], "pandas.tseries.offsets.BusinessMonthBegin.normalize": [""], "BusinessMonthBegin.rule_code": [""], "offsets.BusinessMonthBegin.rule_code": [""], "tseries.offsets.BusinessMonthBegin.rule_code": [""], "pandas.tseries.offsets.BusinessMonthBegin.rule_code": [""], "BusinessMonthBegin.n": [""], "offsets.BusinessMonthBegin.n": [""], "tseries.offsets.BusinessMonthBegin.n": [""], "pandas.tseries.offsets.BusinessMonthBegin.n": [""], "BusinessMonthBegin.apply": [""], "offsets.BusinessMonthBegin.apply": [""], "tseries.offsets.BusinessMonthBegin.apply": [""], "pandas.tseries.offsets.BusinessMonthBegin.apply": [""], "BusinessMonthBegin.apply_index": [""], "offsets.BusinessMonthBegin.apply_index": [""], "tseries.offsets.BusinessMonthBegin.apply_index": [""], "pandas.tseries.offsets.BusinessMonthBegin.apply_index": [""], "BusinessMonthBegin.copy": [""], "offsets.BusinessMonthBegin.copy": [""], "tseries.offsets.BusinessMonthBegin.copy": [""], "pandas.tseries.offsets.BusinessMonthBegin.copy": [""], "BusinessMonthBegin.isAnchored": [""], "offsets.BusinessMonthBegin.isAnchored": [""], "tseries.offsets.BusinessMonthBegin.isAnchored": [""], "pandas.tseries.offsets.BusinessMonthBegin.isAnchored": [""], "BusinessMonthBegin.onOffset": [""], "offsets.BusinessMonthBegin.onOffset": [""], "tseries.offsets.BusinessMonthBegin.onOffset": [""], "pandas.tseries.offsets.BusinessMonthBegin.onOffset": [""], "BusinessMonthBegin.is_anchored": [""], "offsets.BusinessMonthBegin.is_anchored": [""], "tseries.offsets.BusinessMonthBegin.is_anchored": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_anchored": [""], "BusinessMonthBegin.is_on_offset": [""], "offsets.BusinessMonthBegin.is_on_offset": [""], "tseries.offsets.BusinessMonthBegin.is_on_offset": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_on_offset": [""], "BusinessMonthBegin.__call__": ["Call self as a function."], "offsets.BusinessMonthBegin.__call__": ["Call self as a function."], "tseries.offsets.BusinessMonthBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.BusinessMonthBegin.__call__": ["Call self as a function."], "BusinessMonthBegin.is_month_start": [""], "offsets.BusinessMonthBegin.is_month_start": [""], "tseries.offsets.BusinessMonthBegin.is_month_start": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_month_start": [""], "BusinessMonthBegin.is_month_end": [""], "offsets.BusinessMonthBegin.is_month_end": [""], "tseries.offsets.BusinessMonthBegin.is_month_end": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_month_end": [""], "BusinessMonthBegin.is_quarter_start": [""], "offsets.BusinessMonthBegin.is_quarter_start": [""], "tseries.offsets.BusinessMonthBegin.is_quarter_start": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_quarter_start": [""], "BusinessMonthBegin.is_quarter_end": [""], "offsets.BusinessMonthBegin.is_quarter_end": [""], "tseries.offsets.BusinessMonthBegin.is_quarter_end": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_quarter_end": [""], "BusinessMonthBegin.is_year_start": [""], "offsets.BusinessMonthBegin.is_year_start": [""], "tseries.offsets.BusinessMonthBegin.is_year_start": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_year_start": [""], "BusinessMonthBegin.is_year_end": [""], "offsets.BusinessMonthBegin.is_year_end": [""], "tseries.offsets.BusinessMonthBegin.is_year_end": [""], "pandas.tseries.offsets.BusinessMonthBegin.is_year_end": [""], "CustomBusinessMonthEnd": [" class=\"rubric\">Attributes</p>\n"], "offsets.CustomBusinessMonthEnd": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.CustomBusinessMonthEnd": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.CustomBusinessMonthEnd": [" class=\"rubric\">Attributes</p>\n"], "CBMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthEnd</span></code></a"], "offsets.CBMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthEnd</span></code></a"], "tseries.offsets.CBMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthEnd</span></code></a"], "pandas.tseries.offsets.CBMonthEnd": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthEnd.html#pandas.tseries.offsets.CustomBusinessMonthEnd\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthEnd\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthEnd</span></code></a"], "CustomBusinessMonthEnd.freqstr": [""], "offsets.CustomBusinessMonthEnd.freqstr": [""], "tseries.offsets.CustomBusinessMonthEnd.freqstr": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.freqstr": [""], "CustomBusinessMonthEnd.kwds": [""], "offsets.CustomBusinessMonthEnd.kwds": [""], "tseries.offsets.CustomBusinessMonthEnd.kwds": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.kwds": [""], "m_offset": [""], "CustomBusinessMonthEnd.m_offset": [""], "offsets.CustomBusinessMonthEnd.m_offset": [""], "tseries.offsets.CustomBusinessMonthEnd.m_offset": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.m_offset": [""], "CustomBusinessMonthEnd.name": [""], "offsets.CustomBusinessMonthEnd.name": [""], "tseries.offsets.CustomBusinessMonthEnd.name": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.name": [""], "CustomBusinessMonthEnd.nanos": [""], "offsets.CustomBusinessMonthEnd.nanos": [""], "tseries.offsets.CustomBusinessMonthEnd.nanos": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.nanos": [""], "CustomBusinessMonthEnd.normalize": [""], "offsets.CustomBusinessMonthEnd.normalize": [""], "tseries.offsets.CustomBusinessMonthEnd.normalize": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.normalize": [""], "CustomBusinessMonthEnd.rule_code": [""], "offsets.CustomBusinessMonthEnd.rule_code": [""], "tseries.offsets.CustomBusinessMonthEnd.rule_code": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.rule_code": [""], "CustomBusinessMonthEnd.n": [""], "offsets.CustomBusinessMonthEnd.n": [""], "tseries.offsets.CustomBusinessMonthEnd.n": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.n": [""], "CustomBusinessMonthEnd.weekmask": [""], "offsets.CustomBusinessMonthEnd.weekmask": [""], "tseries.offsets.CustomBusinessMonthEnd.weekmask": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.weekmask": [""], "CustomBusinessMonthEnd.calendar": [""], "offsets.CustomBusinessMonthEnd.calendar": [""], "tseries.offsets.CustomBusinessMonthEnd.calendar": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.calendar": [""], "CustomBusinessMonthEnd.holidays": [""], "offsets.CustomBusinessMonthEnd.holidays": [""], "tseries.offsets.CustomBusinessMonthEnd.holidays": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.holidays": [""], "CustomBusinessMonthEnd.apply": [""], "offsets.CustomBusinessMonthEnd.apply": [""], "tseries.offsets.CustomBusinessMonthEnd.apply": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.apply": [""], "CustomBusinessMonthEnd.apply_index": [""], "offsets.CustomBusinessMonthEnd.apply_index": [""], "tseries.offsets.CustomBusinessMonthEnd.apply_index": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.apply_index": [""], "CustomBusinessMonthEnd.copy": [""], "offsets.CustomBusinessMonthEnd.copy": [""], "tseries.offsets.CustomBusinessMonthEnd.copy": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.copy": [""], "CustomBusinessMonthEnd.isAnchored": [""], "offsets.CustomBusinessMonthEnd.isAnchored": [""], "tseries.offsets.CustomBusinessMonthEnd.isAnchored": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.isAnchored": [""], "CustomBusinessMonthEnd.onOffset": [""], "offsets.CustomBusinessMonthEnd.onOffset": [""], "tseries.offsets.CustomBusinessMonthEnd.onOffset": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.onOffset": [""], "CustomBusinessMonthEnd.is_anchored": [""], "offsets.CustomBusinessMonthEnd.is_anchored": [""], "tseries.offsets.CustomBusinessMonthEnd.is_anchored": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_anchored": [""], "CustomBusinessMonthEnd.is_on_offset": [""], "offsets.CustomBusinessMonthEnd.is_on_offset": [""], "tseries.offsets.CustomBusinessMonthEnd.is_on_offset": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_on_offset": [""], "CustomBusinessMonthEnd.__call__": ["Call self as a function."], "offsets.CustomBusinessMonthEnd.__call__": ["Call self as a function."], "tseries.offsets.CustomBusinessMonthEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.CustomBusinessMonthEnd.__call__": ["Call self as a function."], "CustomBusinessMonthEnd.is_month_start": [""], "offsets.CustomBusinessMonthEnd.is_month_start": [""], "tseries.offsets.CustomBusinessMonthEnd.is_month_start": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_start": [""], "CustomBusinessMonthEnd.is_month_end": [""], "offsets.CustomBusinessMonthEnd.is_month_end": [""], "tseries.offsets.CustomBusinessMonthEnd.is_month_end": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_month_end": [""], "CustomBusinessMonthEnd.is_quarter_start": [""], "offsets.CustomBusinessMonthEnd.is_quarter_start": [""], "tseries.offsets.CustomBusinessMonthEnd.is_quarter_start": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_start": [""], "CustomBusinessMonthEnd.is_quarter_end": [""], "offsets.CustomBusinessMonthEnd.is_quarter_end": [""], "tseries.offsets.CustomBusinessMonthEnd.is_quarter_end": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_quarter_end": [""], "CustomBusinessMonthEnd.is_year_start": [""], "offsets.CustomBusinessMonthEnd.is_year_start": [""], "tseries.offsets.CustomBusinessMonthEnd.is_year_start": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_start": [""], "CustomBusinessMonthEnd.is_year_end": [""], "offsets.CustomBusinessMonthEnd.is_year_end": [""], "tseries.offsets.CustomBusinessMonthEnd.is_year_end": [""], "pandas.tseries.offsets.CustomBusinessMonthEnd.is_year_end": [""], "CustomBusinessMonthBegin": [" class=\"rubric\">Attributes</p>\n"], "offsets.CustomBusinessMonthBegin": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.CustomBusinessMonthBegin": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.CustomBusinessMonthBegin": [" class=\"rubric\">Attributes</p>\n"], "CBMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthBegin</span></code></a"], "offsets.CBMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthBegin</span></code></a"], "tseries.offsets.CBMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthBegin</span></code></a"], "pandas.tseries.offsets.CBMonthBegin": ["alias of <a class=\"reference internal\" href=\"api/pandas.tseries.offsets.CustomBusinessMonthBegin.html#pandas.tseries.offsets.CustomBusinessMonthBegin\" title=\"pandas._libs.tslibs.offsets.CustomBusinessMonthBegin\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">pandas._libs.tslibs.offsets.CustomBusinessMonthBegin</span></code></a"], "CustomBusinessMonthBegin.freqstr": [""], "offsets.CustomBusinessMonthBegin.freqstr": [""], "tseries.offsets.CustomBusinessMonthBegin.freqstr": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.freqstr": [""], "CustomBusinessMonthBegin.kwds": [""], "offsets.CustomBusinessMonthBegin.kwds": [""], "tseries.offsets.CustomBusinessMonthBegin.kwds": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.kwds": [""], "CustomBusinessMonthBegin.m_offset": [""], "offsets.CustomBusinessMonthBegin.m_offset": [""], "tseries.offsets.CustomBusinessMonthBegin.m_offset": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.m_offset": [""], "CustomBusinessMonthBegin.name": [""], "offsets.CustomBusinessMonthBegin.name": [""], "tseries.offsets.CustomBusinessMonthBegin.name": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.name": [""], "CustomBusinessMonthBegin.nanos": [""], "offsets.CustomBusinessMonthBegin.nanos": [""], "tseries.offsets.CustomBusinessMonthBegin.nanos": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.nanos": [""], "CustomBusinessMonthBegin.normalize": [""], "offsets.CustomBusinessMonthBegin.normalize": [""], "tseries.offsets.CustomBusinessMonthBegin.normalize": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.normalize": [""], "CustomBusinessMonthBegin.rule_code": [""], "offsets.CustomBusinessMonthBegin.rule_code": [""], "tseries.offsets.CustomBusinessMonthBegin.rule_code": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.rule_code": [""], "CustomBusinessMonthBegin.n": [""], "offsets.CustomBusinessMonthBegin.n": [""], "tseries.offsets.CustomBusinessMonthBegin.n": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.n": [""], "CustomBusinessMonthBegin.weekmask": [""], "offsets.CustomBusinessMonthBegin.weekmask": [""], "tseries.offsets.CustomBusinessMonthBegin.weekmask": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.weekmask": [""], "CustomBusinessMonthBegin.calendar": [""], "offsets.CustomBusinessMonthBegin.calendar": [""], "tseries.offsets.CustomBusinessMonthBegin.calendar": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.calendar": [""], "CustomBusinessMonthBegin.holidays": [""], "offsets.CustomBusinessMonthBegin.holidays": [""], "tseries.offsets.CustomBusinessMonthBegin.holidays": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.holidays": [""], "CustomBusinessMonthBegin.apply": [""], "offsets.CustomBusinessMonthBegin.apply": [""], "tseries.offsets.CustomBusinessMonthBegin.apply": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.apply": [""], "CustomBusinessMonthBegin.apply_index": [""], "offsets.CustomBusinessMonthBegin.apply_index": [""], "tseries.offsets.CustomBusinessMonthBegin.apply_index": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.apply_index": [""], "CustomBusinessMonthBegin.copy": [""], "offsets.CustomBusinessMonthBegin.copy": [""], "tseries.offsets.CustomBusinessMonthBegin.copy": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.copy": [""], "CustomBusinessMonthBegin.isAnchored": [""], "offsets.CustomBusinessMonthBegin.isAnchored": [""], "tseries.offsets.CustomBusinessMonthBegin.isAnchored": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.isAnchored": [""], "CustomBusinessMonthBegin.onOffset": [""], "offsets.CustomBusinessMonthBegin.onOffset": [""], "tseries.offsets.CustomBusinessMonthBegin.onOffset": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.onOffset": [""], "CustomBusinessMonthBegin.is_anchored": [""], "offsets.CustomBusinessMonthBegin.is_anchored": [""], "tseries.offsets.CustomBusinessMonthBegin.is_anchored": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_anchored": [""], "CustomBusinessMonthBegin.is_on_offset": [""], "offsets.CustomBusinessMonthBegin.is_on_offset": [""], "tseries.offsets.CustomBusinessMonthBegin.is_on_offset": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_on_offset": [""], "CustomBusinessMonthBegin.__call__": ["Call self as a function."], "offsets.CustomBusinessMonthBegin.__call__": ["Call self as a function."], "tseries.offsets.CustomBusinessMonthBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.CustomBusinessMonthBegin.__call__": ["Call self as a function."], "CustomBusinessMonthBegin.is_month_start": [""], "offsets.CustomBusinessMonthBegin.is_month_start": [""], "tseries.offsets.CustomBusinessMonthBegin.is_month_start": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_start": [""], "CustomBusinessMonthBegin.is_month_end": [""], "offsets.CustomBusinessMonthBegin.is_month_end": [""], "tseries.offsets.CustomBusinessMonthBegin.is_month_end": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_month_end": [""], "CustomBusinessMonthBegin.is_quarter_start": [""], "offsets.CustomBusinessMonthBegin.is_quarter_start": [""], "tseries.offsets.CustomBusinessMonthBegin.is_quarter_start": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_start": [""], "CustomBusinessMonthBegin.is_quarter_end": [""], "offsets.CustomBusinessMonthBegin.is_quarter_end": [""], "tseries.offsets.CustomBusinessMonthBegin.is_quarter_end": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_quarter_end": [""], "CustomBusinessMonthBegin.is_year_start": [""], "offsets.CustomBusinessMonthBegin.is_year_start": [""], "tseries.offsets.CustomBusinessMonthBegin.is_year_start": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_start": [""], "CustomBusinessMonthBegin.is_year_end": [""], "offsets.CustomBusinessMonthBegin.is_year_end": [""], "tseries.offsets.CustomBusinessMonthBegin.is_year_end": [""], "pandas.tseries.offsets.CustomBusinessMonthBegin.is_year_end": [""], "SemiMonthEnd": ["Two DateOffset's per month repeating on the last day of the month and day_of_month."], "offsets.SemiMonthEnd": ["Two DateOffset's per month repeating on the last day of the month and day_of_month."], "tseries.offsets.SemiMonthEnd": ["Two DateOffset's per month repeating on the last day of the month and day_of_month."], "pandas.tseries.offsets.SemiMonthEnd": ["Two DateOffset's per month repeating on the last day of the month and day_of_month."], "SemiMonthEnd.freqstr": [""], "offsets.SemiMonthEnd.freqstr": [""], "tseries.offsets.SemiMonthEnd.freqstr": [""], "pandas.tseries.offsets.SemiMonthEnd.freqstr": [""], "SemiMonthEnd.kwds": [""], "offsets.SemiMonthEnd.kwds": [""], "tseries.offsets.SemiMonthEnd.kwds": [""], "pandas.tseries.offsets.SemiMonthEnd.kwds": [""], "SemiMonthEnd.name": [""], "offsets.SemiMonthEnd.name": [""], "tseries.offsets.SemiMonthEnd.name": [""], "pandas.tseries.offsets.SemiMonthEnd.name": [""], "SemiMonthEnd.nanos": [""], "offsets.SemiMonthEnd.nanos": [""], "tseries.offsets.SemiMonthEnd.nanos": [""], "pandas.tseries.offsets.SemiMonthEnd.nanos": [""], "SemiMonthEnd.normalize": [""], "offsets.SemiMonthEnd.normalize": [""], "tseries.offsets.SemiMonthEnd.normalize": [""], "pandas.tseries.offsets.SemiMonthEnd.normalize": [""], "SemiMonthEnd.rule_code": [""], "offsets.SemiMonthEnd.rule_code": [""], "tseries.offsets.SemiMonthEnd.rule_code": [""], "pandas.tseries.offsets.SemiMonthEnd.rule_code": [""], "SemiMonthEnd.n": [""], "offsets.SemiMonthEnd.n": [""], "tseries.offsets.SemiMonthEnd.n": [""], "pandas.tseries.offsets.SemiMonthEnd.n": [""], "day_of_month": [""], "SemiMonthEnd.day_of_month": [""], "offsets.SemiMonthEnd.day_of_month": [""], "tseries.offsets.SemiMonthEnd.day_of_month": [""], "pandas.tseries.offsets.SemiMonthEnd.day_of_month": [""], "SemiMonthEnd.apply": [""], "offsets.SemiMonthEnd.apply": [""], "tseries.offsets.SemiMonthEnd.apply": [""], "pandas.tseries.offsets.SemiMonthEnd.apply": [""], "SemiMonthEnd.apply_index": [""], "offsets.SemiMonthEnd.apply_index": [""], "tseries.offsets.SemiMonthEnd.apply_index": [""], "pandas.tseries.offsets.SemiMonthEnd.apply_index": [""], "SemiMonthEnd.copy": [""], "offsets.SemiMonthEnd.copy": [""], "tseries.offsets.SemiMonthEnd.copy": [""], "pandas.tseries.offsets.SemiMonthEnd.copy": [""], "SemiMonthEnd.isAnchored": [""], "offsets.SemiMonthEnd.isAnchored": [""], "tseries.offsets.SemiMonthEnd.isAnchored": [""], "pandas.tseries.offsets.SemiMonthEnd.isAnchored": [""], "SemiMonthEnd.onOffset": [""], "offsets.SemiMonthEnd.onOffset": [""], "tseries.offsets.SemiMonthEnd.onOffset": [""], "pandas.tseries.offsets.SemiMonthEnd.onOffset": [""], "SemiMonthEnd.is_anchored": [""], "offsets.SemiMonthEnd.is_anchored": [""], "tseries.offsets.SemiMonthEnd.is_anchored": [""], "pandas.tseries.offsets.SemiMonthEnd.is_anchored": [""], "SemiMonthEnd.is_on_offset": [""], "offsets.SemiMonthEnd.is_on_offset": [""], "tseries.offsets.SemiMonthEnd.is_on_offset": [""], "pandas.tseries.offsets.SemiMonthEnd.is_on_offset": [""], "SemiMonthEnd.__call__": ["Call self as a function."], "offsets.SemiMonthEnd.__call__": ["Call self as a function."], "tseries.offsets.SemiMonthEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.SemiMonthEnd.__call__": ["Call self as a function."], "SemiMonthEnd.is_month_start": [""], "offsets.SemiMonthEnd.is_month_start": [""], "tseries.offsets.SemiMonthEnd.is_month_start": [""], "pandas.tseries.offsets.SemiMonthEnd.is_month_start": [""], "SemiMonthEnd.is_month_end": [""], "offsets.SemiMonthEnd.is_month_end": [""], "tseries.offsets.SemiMonthEnd.is_month_end": [""], "pandas.tseries.offsets.SemiMonthEnd.is_month_end": [""], "SemiMonthEnd.is_quarter_start": [""], "offsets.SemiMonthEnd.is_quarter_start": [""], "tseries.offsets.SemiMonthEnd.is_quarter_start": [""], "pandas.tseries.offsets.SemiMonthEnd.is_quarter_start": [""], "SemiMonthEnd.is_quarter_end": [""], "offsets.SemiMonthEnd.is_quarter_end": [""], "tseries.offsets.SemiMonthEnd.is_quarter_end": [""], "pandas.tseries.offsets.SemiMonthEnd.is_quarter_end": [""], "SemiMonthEnd.is_year_start": [""], "offsets.SemiMonthEnd.is_year_start": [""], "tseries.offsets.SemiMonthEnd.is_year_start": [""], "pandas.tseries.offsets.SemiMonthEnd.is_year_start": [""], "SemiMonthEnd.is_year_end": [""], "offsets.SemiMonthEnd.is_year_end": [""], "tseries.offsets.SemiMonthEnd.is_year_end": [""], "pandas.tseries.offsets.SemiMonthEnd.is_year_end": [""], "SemiMonthBegin": ["Two DateOffset's per month repeating on the first day of the month and day_of_month."], "offsets.SemiMonthBegin": ["Two DateOffset's per month repeating on the first day of the month and day_of_month."], "tseries.offsets.SemiMonthBegin": ["Two DateOffset's per month repeating on the first day of the month and day_of_month."], "pandas.tseries.offsets.SemiMonthBegin": ["Two DateOffset's per month repeating on the first day of the month and day_of_month."], "SemiMonthBegin.freqstr": [""], "offsets.SemiMonthBegin.freqstr": [""], "tseries.offsets.SemiMonthBegin.freqstr": [""], "pandas.tseries.offsets.SemiMonthBegin.freqstr": [""], "SemiMonthBegin.kwds": [""], "offsets.SemiMonthBegin.kwds": [""], "tseries.offsets.SemiMonthBegin.kwds": [""], "pandas.tseries.offsets.SemiMonthBegin.kwds": [""], "SemiMonthBegin.name": [""], "offsets.SemiMonthBegin.name": [""], "tseries.offsets.SemiMonthBegin.name": [""], "pandas.tseries.offsets.SemiMonthBegin.name": [""], "SemiMonthBegin.nanos": [""], "offsets.SemiMonthBegin.nanos": [""], "tseries.offsets.SemiMonthBegin.nanos": [""], "pandas.tseries.offsets.SemiMonthBegin.nanos": [""], "SemiMonthBegin.normalize": [""], "offsets.SemiMonthBegin.normalize": [""], "tseries.offsets.SemiMonthBegin.normalize": [""], "pandas.tseries.offsets.SemiMonthBegin.normalize": [""], "SemiMonthBegin.rule_code": [""], "offsets.SemiMonthBegin.rule_code": [""], "tseries.offsets.SemiMonthBegin.rule_code": [""], "pandas.tseries.offsets.SemiMonthBegin.rule_code": [""], "SemiMonthBegin.n": [""], "offsets.SemiMonthBegin.n": [""], "tseries.offsets.SemiMonthBegin.n": [""], "pandas.tseries.offsets.SemiMonthBegin.n": [""], "SemiMonthBegin.day_of_month": [""], "offsets.SemiMonthBegin.day_of_month": [""], "tseries.offsets.SemiMonthBegin.day_of_month": [""], "pandas.tseries.offsets.SemiMonthBegin.day_of_month": [""], "SemiMonthBegin.apply": [""], "offsets.SemiMonthBegin.apply": [""], "tseries.offsets.SemiMonthBegin.apply": [""], "pandas.tseries.offsets.SemiMonthBegin.apply": [""], "SemiMonthBegin.apply_index": [""], "offsets.SemiMonthBegin.apply_index": [""], "tseries.offsets.SemiMonthBegin.apply_index": [""], "pandas.tseries.offsets.SemiMonthBegin.apply_index": [""], "SemiMonthBegin.copy": [""], "offsets.SemiMonthBegin.copy": [""], "tseries.offsets.SemiMonthBegin.copy": [""], "pandas.tseries.offsets.SemiMonthBegin.copy": [""], "SemiMonthBegin.isAnchored": [""], "offsets.SemiMonthBegin.isAnchored": [""], "tseries.offsets.SemiMonthBegin.isAnchored": [""], "pandas.tseries.offsets.SemiMonthBegin.isAnchored": [""], "SemiMonthBegin.onOffset": [""], "offsets.SemiMonthBegin.onOffset": [""], "tseries.offsets.SemiMonthBegin.onOffset": [""], "pandas.tseries.offsets.SemiMonthBegin.onOffset": [""], "SemiMonthBegin.is_anchored": [""], "offsets.SemiMonthBegin.is_anchored": [""], "tseries.offsets.SemiMonthBegin.is_anchored": [""], "pandas.tseries.offsets.SemiMonthBegin.is_anchored": [""], "SemiMonthBegin.is_on_offset": [""], "offsets.SemiMonthBegin.is_on_offset": [""], "tseries.offsets.SemiMonthBegin.is_on_offset": [""], "pandas.tseries.offsets.SemiMonthBegin.is_on_offset": [""], "SemiMonthBegin.__call__": ["Call self as a function."], "offsets.SemiMonthBegin.__call__": ["Call self as a function."], "tseries.offsets.SemiMonthBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.SemiMonthBegin.__call__": ["Call self as a function."], "SemiMonthBegin.is_month_start": [""], "offsets.SemiMonthBegin.is_month_start": [""], "tseries.offsets.SemiMonthBegin.is_month_start": [""], "pandas.tseries.offsets.SemiMonthBegin.is_month_start": [""], "SemiMonthBegin.is_month_end": [""], "offsets.SemiMonthBegin.is_month_end": [""], "tseries.offsets.SemiMonthBegin.is_month_end": [""], "pandas.tseries.offsets.SemiMonthBegin.is_month_end": [""], "SemiMonthBegin.is_quarter_start": [""], "offsets.SemiMonthBegin.is_quarter_start": [""], "tseries.offsets.SemiMonthBegin.is_quarter_start": [""], "pandas.tseries.offsets.SemiMonthBegin.is_quarter_start": [""], "SemiMonthBegin.is_quarter_end": [""], "offsets.SemiMonthBegin.is_quarter_end": [""], "tseries.offsets.SemiMonthBegin.is_quarter_end": [""], "pandas.tseries.offsets.SemiMonthBegin.is_quarter_end": [""], "SemiMonthBegin.is_year_start": [""], "offsets.SemiMonthBegin.is_year_start": [""], "tseries.offsets.SemiMonthBegin.is_year_start": [""], "pandas.tseries.offsets.SemiMonthBegin.is_year_start": [""], "SemiMonthBegin.is_year_end": [""], "offsets.SemiMonthBegin.is_year_end": [""], "tseries.offsets.SemiMonthBegin.is_year_end": [""], "pandas.tseries.offsets.SemiMonthBegin.is_year_end": [""], "Week": ["Weekly offset."], "offsets.Week": ["Weekly offset."], "tseries.offsets.Week": ["Weekly offset."], "pandas.tseries.offsets.Week": ["Weekly offset."], "Week.freqstr": [""], "offsets.Week.freqstr": [""], "tseries.offsets.Week.freqstr": [""], "pandas.tseries.offsets.Week.freqstr": [""], "Week.kwds": [""], "offsets.Week.kwds": [""], "tseries.offsets.Week.kwds": [""], "pandas.tseries.offsets.Week.kwds": [""], "Week.name": [""], "offsets.Week.name": [""], "tseries.offsets.Week.name": [""], "pandas.tseries.offsets.Week.name": [""], "Week.nanos": [""], "offsets.Week.nanos": [""], "tseries.offsets.Week.nanos": [""], "pandas.tseries.offsets.Week.nanos": [""], "Week.normalize": [""], "offsets.Week.normalize": [""], "tseries.offsets.Week.normalize": [""], "pandas.tseries.offsets.Week.normalize": [""], "Week.rule_code": [""], "offsets.Week.rule_code": [""], "tseries.offsets.Week.rule_code": [""], "pandas.tseries.offsets.Week.rule_code": [""], "Week.n": [""], "offsets.Week.n": [""], "tseries.offsets.Week.n": [""], "pandas.tseries.offsets.Week.n": [""], "Week.weekday": [""], "offsets.Week.weekday": [""], "tseries.offsets.Week.weekday": [""], "pandas.tseries.offsets.Week.weekday": [""], "Week.apply": [""], "offsets.Week.apply": [""], "tseries.offsets.Week.apply": [""], "pandas.tseries.offsets.Week.apply": [""], "Week.apply_index": [""], "offsets.Week.apply_index": [""], "tseries.offsets.Week.apply_index": [""], "pandas.tseries.offsets.Week.apply_index": [""], "Week.copy": [""], "offsets.Week.copy": [""], "tseries.offsets.Week.copy": [""], "pandas.tseries.offsets.Week.copy": [""], "Week.isAnchored": [""], "offsets.Week.isAnchored": [""], "tseries.offsets.Week.isAnchored": [""], "pandas.tseries.offsets.Week.isAnchored": [""], "Week.onOffset": [""], "offsets.Week.onOffset": [""], "tseries.offsets.Week.onOffset": [""], "pandas.tseries.offsets.Week.onOffset": [""], "Week.is_anchored": [""], "offsets.Week.is_anchored": [""], "tseries.offsets.Week.is_anchored": [""], "pandas.tseries.offsets.Week.is_anchored": [""], "Week.is_on_offset": [""], "offsets.Week.is_on_offset": [""], "tseries.offsets.Week.is_on_offset": [""], "pandas.tseries.offsets.Week.is_on_offset": [""], "Week.__call__": ["Call self as a function."], "offsets.Week.__call__": ["Call self as a function."], "tseries.offsets.Week.__call__": ["Call self as a function."], "pandas.tseries.offsets.Week.__call__": ["Call self as a function."], "Week.is_month_start": [""], "offsets.Week.is_month_start": [""], "tseries.offsets.Week.is_month_start": [""], "pandas.tseries.offsets.Week.is_month_start": [""], "Week.is_month_end": [""], "offsets.Week.is_month_end": [""], "tseries.offsets.Week.is_month_end": [""], "pandas.tseries.offsets.Week.is_month_end": [""], "Week.is_quarter_start": [""], "offsets.Week.is_quarter_start": [""], "tseries.offsets.Week.is_quarter_start": [""], "pandas.tseries.offsets.Week.is_quarter_start": [""], "Week.is_quarter_end": [""], "offsets.Week.is_quarter_end": [""], "tseries.offsets.Week.is_quarter_end": [""], "pandas.tseries.offsets.Week.is_quarter_end": [""], "Week.is_year_start": [""], "offsets.Week.is_year_start": [""], "tseries.offsets.Week.is_year_start": [""], "pandas.tseries.offsets.Week.is_year_start": [""], "Week.is_year_end": [""], "offsets.Week.is_year_end": [""], "tseries.offsets.Week.is_year_end": [""], "pandas.tseries.offsets.Week.is_year_end": [""], "WeekOfMonth": ["Describes monthly dates like \"the Tuesday of the 2nd week of each month\"."], "offsets.WeekOfMonth": ["Describes monthly dates like \"the Tuesday of the 2nd week of each month\"."], "tseries.offsets.WeekOfMonth": ["Describes monthly dates like \"the Tuesday of the 2nd week of each month\"."], "pandas.tseries.offsets.WeekOfMonth": ["Describes monthly dates like \"the Tuesday of the 2nd week of each month\"."], "WeekOfMonth.freqstr": [""], "offsets.WeekOfMonth.freqstr": [""], "tseries.offsets.WeekOfMonth.freqstr": [""], "pandas.tseries.offsets.WeekOfMonth.freqstr": [""], "WeekOfMonth.kwds": [""], "offsets.WeekOfMonth.kwds": [""], "tseries.offsets.WeekOfMonth.kwds": [""], "pandas.tseries.offsets.WeekOfMonth.kwds": [""], "WeekOfMonth.name": [""], "offsets.WeekOfMonth.name": [""], "tseries.offsets.WeekOfMonth.name": [""], "pandas.tseries.offsets.WeekOfMonth.name": [""], "WeekOfMonth.nanos": [""], "offsets.WeekOfMonth.nanos": [""], "tseries.offsets.WeekOfMonth.nanos": [""], "pandas.tseries.offsets.WeekOfMonth.nanos": [""], "WeekOfMonth.normalize": [""], "offsets.WeekOfMonth.normalize": [""], "tseries.offsets.WeekOfMonth.normalize": [""], "pandas.tseries.offsets.WeekOfMonth.normalize": [""], "WeekOfMonth.rule_code": [""], "offsets.WeekOfMonth.rule_code": [""], "tseries.offsets.WeekOfMonth.rule_code": [""], "pandas.tseries.offsets.WeekOfMonth.rule_code": [""], "WeekOfMonth.n": [""], "offsets.WeekOfMonth.n": [""], "tseries.offsets.WeekOfMonth.n": [""], "pandas.tseries.offsets.WeekOfMonth.n": [""], "WeekOfMonth.week": [""], "offsets.WeekOfMonth.week": [""], "tseries.offsets.WeekOfMonth.week": [""], "pandas.tseries.offsets.WeekOfMonth.week": [""], "WeekOfMonth.apply": [""], "offsets.WeekOfMonth.apply": [""], "tseries.offsets.WeekOfMonth.apply": [""], "pandas.tseries.offsets.WeekOfMonth.apply": [""], "WeekOfMonth.apply_index": [""], "offsets.WeekOfMonth.apply_index": [""], "tseries.offsets.WeekOfMonth.apply_index": [""], "pandas.tseries.offsets.WeekOfMonth.apply_index": [""], "WeekOfMonth.copy": [""], "offsets.WeekOfMonth.copy": [""], "tseries.offsets.WeekOfMonth.copy": [""], "pandas.tseries.offsets.WeekOfMonth.copy": [""], "WeekOfMonth.isAnchored": [""], "offsets.WeekOfMonth.isAnchored": [""], "tseries.offsets.WeekOfMonth.isAnchored": [""], "pandas.tseries.offsets.WeekOfMonth.isAnchored": [""], "WeekOfMonth.onOffset": [""], "offsets.WeekOfMonth.onOffset": [""], "tseries.offsets.WeekOfMonth.onOffset": [""], "pandas.tseries.offsets.WeekOfMonth.onOffset": [""], "WeekOfMonth.is_anchored": [""], "offsets.WeekOfMonth.is_anchored": [""], "tseries.offsets.WeekOfMonth.is_anchored": [""], "pandas.tseries.offsets.WeekOfMonth.is_anchored": [""], "WeekOfMonth.is_on_offset": [""], "offsets.WeekOfMonth.is_on_offset": [""], "tseries.offsets.WeekOfMonth.is_on_offset": [""], "pandas.tseries.offsets.WeekOfMonth.is_on_offset": [""], "WeekOfMonth.__call__": ["Call self as a function."], "offsets.WeekOfMonth.__call__": ["Call self as a function."], "tseries.offsets.WeekOfMonth.__call__": ["Call self as a function."], "pandas.tseries.offsets.WeekOfMonth.__call__": ["Call self as a function."], "WeekOfMonth.weekday": [""], "offsets.WeekOfMonth.weekday": [""], "tseries.offsets.WeekOfMonth.weekday": [""], "pandas.tseries.offsets.WeekOfMonth.weekday": [""], "WeekOfMonth.is_month_start": [""], "offsets.WeekOfMonth.is_month_start": [""], "tseries.offsets.WeekOfMonth.is_month_start": [""], "pandas.tseries.offsets.WeekOfMonth.is_month_start": [""], "WeekOfMonth.is_month_end": [""], "offsets.WeekOfMonth.is_month_end": [""], "tseries.offsets.WeekOfMonth.is_month_end": [""], "pandas.tseries.offsets.WeekOfMonth.is_month_end": [""], "WeekOfMonth.is_quarter_start": [""], "offsets.WeekOfMonth.is_quarter_start": [""], "tseries.offsets.WeekOfMonth.is_quarter_start": [""], "pandas.tseries.offsets.WeekOfMonth.is_quarter_start": [""], "WeekOfMonth.is_quarter_end": [""], "offsets.WeekOfMonth.is_quarter_end": [""], "tseries.offsets.WeekOfMonth.is_quarter_end": [""], "pandas.tseries.offsets.WeekOfMonth.is_quarter_end": [""], "WeekOfMonth.is_year_start": [""], "offsets.WeekOfMonth.is_year_start": [""], "tseries.offsets.WeekOfMonth.is_year_start": [""], "pandas.tseries.offsets.WeekOfMonth.is_year_start": [""], "WeekOfMonth.is_year_end": [""], "offsets.WeekOfMonth.is_year_end": [""], "tseries.offsets.WeekOfMonth.is_year_end": [""], "pandas.tseries.offsets.WeekOfMonth.is_year_end": [""], "LastWeekOfMonth": ["Describes monthly dates in last week of month like \"the last Tuesday of each month\"."], "offsets.LastWeekOfMonth": ["Describes monthly dates in last week of month like \"the last Tuesday of each month\"."], "tseries.offsets.LastWeekOfMonth": ["Describes monthly dates in last week of month like \"the last Tuesday of each month\"."], "pandas.tseries.offsets.LastWeekOfMonth": ["Describes monthly dates in last week of month like \"the last Tuesday of each month\"."], "LastWeekOfMonth.freqstr": [""], "offsets.LastWeekOfMonth.freqstr": [""], "tseries.offsets.LastWeekOfMonth.freqstr": [""], "pandas.tseries.offsets.LastWeekOfMonth.freqstr": [""], "LastWeekOfMonth.kwds": [""], "offsets.LastWeekOfMonth.kwds": [""], "tseries.offsets.LastWeekOfMonth.kwds": [""], "pandas.tseries.offsets.LastWeekOfMonth.kwds": [""], "LastWeekOfMonth.name": [""], "offsets.LastWeekOfMonth.name": [""], "tseries.offsets.LastWeekOfMonth.name": [""], "pandas.tseries.offsets.LastWeekOfMonth.name": [""], "LastWeekOfMonth.nanos": [""], "offsets.LastWeekOfMonth.nanos": [""], "tseries.offsets.LastWeekOfMonth.nanos": [""], "pandas.tseries.offsets.LastWeekOfMonth.nanos": [""], "LastWeekOfMonth.normalize": [""], "offsets.LastWeekOfMonth.normalize": [""], "tseries.offsets.LastWeekOfMonth.normalize": [""], "pandas.tseries.offsets.LastWeekOfMonth.normalize": [""], "LastWeekOfMonth.rule_code": [""], "offsets.LastWeekOfMonth.rule_code": [""], "tseries.offsets.LastWeekOfMonth.rule_code": [""], "pandas.tseries.offsets.LastWeekOfMonth.rule_code": [""], "LastWeekOfMonth.n": [""], "offsets.LastWeekOfMonth.n": [""], "tseries.offsets.LastWeekOfMonth.n": [""], "pandas.tseries.offsets.LastWeekOfMonth.n": [""], "LastWeekOfMonth.weekday": [""], "offsets.LastWeekOfMonth.weekday": [""], "tseries.offsets.LastWeekOfMonth.weekday": [""], "pandas.tseries.offsets.LastWeekOfMonth.weekday": [""], "LastWeekOfMonth.week": [""], "offsets.LastWeekOfMonth.week": [""], "tseries.offsets.LastWeekOfMonth.week": [""], "pandas.tseries.offsets.LastWeekOfMonth.week": [""], "LastWeekOfMonth.apply": [""], "offsets.LastWeekOfMonth.apply": [""], "tseries.offsets.LastWeekOfMonth.apply": [""], "pandas.tseries.offsets.LastWeekOfMonth.apply": [""], "LastWeekOfMonth.apply_index": [""], "offsets.LastWeekOfMonth.apply_index": [""], "tseries.offsets.LastWeekOfMonth.apply_index": [""], "pandas.tseries.offsets.LastWeekOfMonth.apply_index": [""], "LastWeekOfMonth.copy": [""], "offsets.LastWeekOfMonth.copy": [""], "tseries.offsets.LastWeekOfMonth.copy": [""], "pandas.tseries.offsets.LastWeekOfMonth.copy": [""], "LastWeekOfMonth.isAnchored": [""], "offsets.LastWeekOfMonth.isAnchored": [""], "tseries.offsets.LastWeekOfMonth.isAnchored": [""], "pandas.tseries.offsets.LastWeekOfMonth.isAnchored": [""], "LastWeekOfMonth.onOffset": [""], "offsets.LastWeekOfMonth.onOffset": [""], "tseries.offsets.LastWeekOfMonth.onOffset": [""], "pandas.tseries.offsets.LastWeekOfMonth.onOffset": [""], "LastWeekOfMonth.is_anchored": [""], "offsets.LastWeekOfMonth.is_anchored": [""], "tseries.offsets.LastWeekOfMonth.is_anchored": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_anchored": [""], "LastWeekOfMonth.is_on_offset": [""], "offsets.LastWeekOfMonth.is_on_offset": [""], "tseries.offsets.LastWeekOfMonth.is_on_offset": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_on_offset": [""], "LastWeekOfMonth.__call__": ["Call self as a function."], "offsets.LastWeekOfMonth.__call__": ["Call self as a function."], "tseries.offsets.LastWeekOfMonth.__call__": ["Call self as a function."], "pandas.tseries.offsets.LastWeekOfMonth.__call__": ["Call self as a function."], "LastWeekOfMonth.is_month_start": [""], "offsets.LastWeekOfMonth.is_month_start": [""], "tseries.offsets.LastWeekOfMonth.is_month_start": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_month_start": [""], "LastWeekOfMonth.is_month_end": [""], "offsets.LastWeekOfMonth.is_month_end": [""], "tseries.offsets.LastWeekOfMonth.is_month_end": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_month_end": [""], "LastWeekOfMonth.is_quarter_start": [""], "offsets.LastWeekOfMonth.is_quarter_start": [""], "tseries.offsets.LastWeekOfMonth.is_quarter_start": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_quarter_start": [""], "LastWeekOfMonth.is_quarter_end": [""], "offsets.LastWeekOfMonth.is_quarter_end": [""], "tseries.offsets.LastWeekOfMonth.is_quarter_end": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_quarter_end": [""], "LastWeekOfMonth.is_year_start": [""], "offsets.LastWeekOfMonth.is_year_start": [""], "tseries.offsets.LastWeekOfMonth.is_year_start": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_year_start": [""], "LastWeekOfMonth.is_year_end": [""], "offsets.LastWeekOfMonth.is_year_end": [""], "tseries.offsets.LastWeekOfMonth.is_year_end": [""], "pandas.tseries.offsets.LastWeekOfMonth.is_year_end": [""], "BQuarterEnd": ["DateOffset increments between the last business day of each Quarter."], "offsets.BQuarterEnd": ["DateOffset increments between the last business day of each Quarter."], "tseries.offsets.BQuarterEnd": ["DateOffset increments between the last business day of each Quarter."], "pandas.tseries.offsets.BQuarterEnd": ["DateOffset increments between the last business day of each Quarter."], "BQuarterEnd.freqstr": [""], "offsets.BQuarterEnd.freqstr": [""], "tseries.offsets.BQuarterEnd.freqstr": [""], "pandas.tseries.offsets.BQuarterEnd.freqstr": [""], "BQuarterEnd.kwds": [""], "offsets.BQuarterEnd.kwds": [""], "tseries.offsets.BQuarterEnd.kwds": [""], "pandas.tseries.offsets.BQuarterEnd.kwds": [""], "BQuarterEnd.name": [""], "offsets.BQuarterEnd.name": [""], "tseries.offsets.BQuarterEnd.name": [""], "pandas.tseries.offsets.BQuarterEnd.name": [""], "BQuarterEnd.nanos": [""], "offsets.BQuarterEnd.nanos": [""], "tseries.offsets.BQuarterEnd.nanos": [""], "pandas.tseries.offsets.BQuarterEnd.nanos": [""], "BQuarterEnd.normalize": [""], "offsets.BQuarterEnd.normalize": [""], "tseries.offsets.BQuarterEnd.normalize": [""], "pandas.tseries.offsets.BQuarterEnd.normalize": [""], "BQuarterEnd.rule_code": [""], "offsets.BQuarterEnd.rule_code": [""], "tseries.offsets.BQuarterEnd.rule_code": [""], "pandas.tseries.offsets.BQuarterEnd.rule_code": [""], "BQuarterEnd.n": [""], "offsets.BQuarterEnd.n": [""], "tseries.offsets.BQuarterEnd.n": [""], "pandas.tseries.offsets.BQuarterEnd.n": [""], "startingMonth": [""], "BQuarterEnd.startingMonth": [""], "offsets.BQuarterEnd.startingMonth": [""], "tseries.offsets.BQuarterEnd.startingMonth": [""], "pandas.tseries.offsets.BQuarterEnd.startingMonth": [""], "BQuarterEnd.apply": [""], "offsets.BQuarterEnd.apply": [""], "tseries.offsets.BQuarterEnd.apply": [""], "pandas.tseries.offsets.BQuarterEnd.apply": [""], "BQuarterEnd.apply_index": [""], "offsets.BQuarterEnd.apply_index": [""], "tseries.offsets.BQuarterEnd.apply_index": [""], "pandas.tseries.offsets.BQuarterEnd.apply_index": [""], "BQuarterEnd.copy": [""], "offsets.BQuarterEnd.copy": [""], "tseries.offsets.BQuarterEnd.copy": [""], "pandas.tseries.offsets.BQuarterEnd.copy": [""], "BQuarterEnd.isAnchored": [""], "offsets.BQuarterEnd.isAnchored": [""], "tseries.offsets.BQuarterEnd.isAnchored": [""], "pandas.tseries.offsets.BQuarterEnd.isAnchored": [""], "BQuarterEnd.onOffset": [""], "offsets.BQuarterEnd.onOffset": [""], "tseries.offsets.BQuarterEnd.onOffset": [""], "pandas.tseries.offsets.BQuarterEnd.onOffset": [""], "BQuarterEnd.is_anchored": [""], "offsets.BQuarterEnd.is_anchored": [""], "tseries.offsets.BQuarterEnd.is_anchored": [""], "pandas.tseries.offsets.BQuarterEnd.is_anchored": [""], "BQuarterEnd.is_on_offset": [""], "offsets.BQuarterEnd.is_on_offset": [""], "tseries.offsets.BQuarterEnd.is_on_offset": [""], "pandas.tseries.offsets.BQuarterEnd.is_on_offset": [""], "BQuarterEnd.__call__": ["Call self as a function."], "offsets.BQuarterEnd.__call__": ["Call self as a function."], "tseries.offsets.BQuarterEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.BQuarterEnd.__call__": ["Call self as a function."], "BQuarterEnd.is_month_start": [""], "offsets.BQuarterEnd.is_month_start": [""], "tseries.offsets.BQuarterEnd.is_month_start": [""], "pandas.tseries.offsets.BQuarterEnd.is_month_start": [""], "BQuarterEnd.is_month_end": [""], "offsets.BQuarterEnd.is_month_end": [""], "tseries.offsets.BQuarterEnd.is_month_end": [""], "pandas.tseries.offsets.BQuarterEnd.is_month_end": [""], "BQuarterEnd.is_quarter_start": [""], "offsets.BQuarterEnd.is_quarter_start": [""], "tseries.offsets.BQuarterEnd.is_quarter_start": [""], "pandas.tseries.offsets.BQuarterEnd.is_quarter_start": [""], "BQuarterEnd.is_quarter_end": [""], "offsets.BQuarterEnd.is_quarter_end": [""], "tseries.offsets.BQuarterEnd.is_quarter_end": [""], "pandas.tseries.offsets.BQuarterEnd.is_quarter_end": [""], "BQuarterEnd.is_year_start": [""], "offsets.BQuarterEnd.is_year_start": [""], "tseries.offsets.BQuarterEnd.is_year_start": [""], "pandas.tseries.offsets.BQuarterEnd.is_year_start": [""], "BQuarterEnd.is_year_end": [""], "offsets.BQuarterEnd.is_year_end": [""], "tseries.offsets.BQuarterEnd.is_year_end": [""], "pandas.tseries.offsets.BQuarterEnd.is_year_end": [""], "BQuarterBegin": ["DateOffset increments between the first business day of each Quarter."], "offsets.BQuarterBegin": ["DateOffset increments between the first business day of each Quarter."], "tseries.offsets.BQuarterBegin": ["DateOffset increments between the first business day of each Quarter."], "pandas.tseries.offsets.BQuarterBegin": ["DateOffset increments between the first business day of each Quarter."], "BQuarterBegin.freqstr": [""], "offsets.BQuarterBegin.freqstr": [""], "tseries.offsets.BQuarterBegin.freqstr": [""], "pandas.tseries.offsets.BQuarterBegin.freqstr": [""], "BQuarterBegin.kwds": [""], "offsets.BQuarterBegin.kwds": [""], "tseries.offsets.BQuarterBegin.kwds": [""], "pandas.tseries.offsets.BQuarterBegin.kwds": [""], "BQuarterBegin.name": [""], "offsets.BQuarterBegin.name": [""], "tseries.offsets.BQuarterBegin.name": [""], "pandas.tseries.offsets.BQuarterBegin.name": [""], "BQuarterBegin.nanos": [""], "offsets.BQuarterBegin.nanos": [""], "tseries.offsets.BQuarterBegin.nanos": [""], "pandas.tseries.offsets.BQuarterBegin.nanos": [""], "BQuarterBegin.normalize": [""], "offsets.BQuarterBegin.normalize": [""], "tseries.offsets.BQuarterBegin.normalize": [""], "pandas.tseries.offsets.BQuarterBegin.normalize": [""], "BQuarterBegin.rule_code": [""], "offsets.BQuarterBegin.rule_code": [""], "tseries.offsets.BQuarterBegin.rule_code": [""], "pandas.tseries.offsets.BQuarterBegin.rule_code": [""], "BQuarterBegin.n": [""], "offsets.BQuarterBegin.n": [""], "tseries.offsets.BQuarterBegin.n": [""], "pandas.tseries.offsets.BQuarterBegin.n": [""], "BQuarterBegin.startingMonth": [""], "offsets.BQuarterBegin.startingMonth": [""], "tseries.offsets.BQuarterBegin.startingMonth": [""], "pandas.tseries.offsets.BQuarterBegin.startingMonth": [""], "BQuarterBegin.apply": [""], "offsets.BQuarterBegin.apply": [""], "tseries.offsets.BQuarterBegin.apply": [""], "pandas.tseries.offsets.BQuarterBegin.apply": [""], "BQuarterBegin.apply_index": [""], "offsets.BQuarterBegin.apply_index": [""], "tseries.offsets.BQuarterBegin.apply_index": [""], "pandas.tseries.offsets.BQuarterBegin.apply_index": [""], "BQuarterBegin.copy": [""], "offsets.BQuarterBegin.copy": [""], "tseries.offsets.BQuarterBegin.copy": [""], "pandas.tseries.offsets.BQuarterBegin.copy": [""], "BQuarterBegin.isAnchored": [""], "offsets.BQuarterBegin.isAnchored": [""], "tseries.offsets.BQuarterBegin.isAnchored": [""], "pandas.tseries.offsets.BQuarterBegin.isAnchored": [""], "BQuarterBegin.onOffset": [""], "offsets.BQuarterBegin.onOffset": [""], "tseries.offsets.BQuarterBegin.onOffset": [""], "pandas.tseries.offsets.BQuarterBegin.onOffset": [""], "BQuarterBegin.is_anchored": [""], "offsets.BQuarterBegin.is_anchored": [""], "tseries.offsets.BQuarterBegin.is_anchored": [""], "pandas.tseries.offsets.BQuarterBegin.is_anchored": [""], "BQuarterBegin.is_on_offset": [""], "offsets.BQuarterBegin.is_on_offset": [""], "tseries.offsets.BQuarterBegin.is_on_offset": [""], "pandas.tseries.offsets.BQuarterBegin.is_on_offset": [""], "BQuarterBegin.__call__": ["Call self as a function."], "offsets.BQuarterBegin.__call__": ["Call self as a function."], "tseries.offsets.BQuarterBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.BQuarterBegin.__call__": ["Call self as a function."], "BQuarterBegin.is_month_start": [""], "offsets.BQuarterBegin.is_month_start": [""], "tseries.offsets.BQuarterBegin.is_month_start": [""], "pandas.tseries.offsets.BQuarterBegin.is_month_start": [""], "BQuarterBegin.is_month_end": [""], "offsets.BQuarterBegin.is_month_end": [""], "tseries.offsets.BQuarterBegin.is_month_end": [""], "pandas.tseries.offsets.BQuarterBegin.is_month_end": [""], "BQuarterBegin.is_quarter_start": [""], "offsets.BQuarterBegin.is_quarter_start": [""], "tseries.offsets.BQuarterBegin.is_quarter_start": [""], "pandas.tseries.offsets.BQuarterBegin.is_quarter_start": [""], "BQuarterBegin.is_quarter_end": [""], "offsets.BQuarterBegin.is_quarter_end": [""], "tseries.offsets.BQuarterBegin.is_quarter_end": [""], "pandas.tseries.offsets.BQuarterBegin.is_quarter_end": [""], "BQuarterBegin.is_year_start": [""], "offsets.BQuarterBegin.is_year_start": [""], "tseries.offsets.BQuarterBegin.is_year_start": [""], "pandas.tseries.offsets.BQuarterBegin.is_year_start": [""], "BQuarterBegin.is_year_end": [""], "offsets.BQuarterBegin.is_year_end": [""], "tseries.offsets.BQuarterBegin.is_year_end": [""], "pandas.tseries.offsets.BQuarterBegin.is_year_end": [""], "QuarterEnd": ["DateOffset increments between Quarter end dates."], "offsets.QuarterEnd": ["DateOffset increments between Quarter end dates."], "tseries.offsets.QuarterEnd": ["DateOffset increments between Quarter end dates."], "pandas.tseries.offsets.QuarterEnd": ["DateOffset increments between Quarter end dates."], "QuarterEnd.freqstr": [""], "offsets.QuarterEnd.freqstr": [""], "tseries.offsets.QuarterEnd.freqstr": [""], "pandas.tseries.offsets.QuarterEnd.freqstr": [""], "QuarterEnd.kwds": [""], "offsets.QuarterEnd.kwds": [""], "tseries.offsets.QuarterEnd.kwds": [""], "pandas.tseries.offsets.QuarterEnd.kwds": [""], "QuarterEnd.name": [""], "offsets.QuarterEnd.name": [""], "tseries.offsets.QuarterEnd.name": [""], "pandas.tseries.offsets.QuarterEnd.name": [""], "QuarterEnd.nanos": [""], "offsets.QuarterEnd.nanos": [""], "tseries.offsets.QuarterEnd.nanos": [""], "pandas.tseries.offsets.QuarterEnd.nanos": [""], "QuarterEnd.normalize": [""], "offsets.QuarterEnd.normalize": [""], "tseries.offsets.QuarterEnd.normalize": [""], "pandas.tseries.offsets.QuarterEnd.normalize": [""], "QuarterEnd.rule_code": [""], "offsets.QuarterEnd.rule_code": [""], "tseries.offsets.QuarterEnd.rule_code": [""], "pandas.tseries.offsets.QuarterEnd.rule_code": [""], "QuarterEnd.n": [""], "offsets.QuarterEnd.n": [""], "tseries.offsets.QuarterEnd.n": [""], "pandas.tseries.offsets.QuarterEnd.n": [""], "QuarterEnd.startingMonth": [""], "offsets.QuarterEnd.startingMonth": [""], "tseries.offsets.QuarterEnd.startingMonth": [""], "pandas.tseries.offsets.QuarterEnd.startingMonth": [""], "QuarterEnd.apply": [""], "offsets.QuarterEnd.apply": [""], "tseries.offsets.QuarterEnd.apply": [""], "pandas.tseries.offsets.QuarterEnd.apply": [""], "QuarterEnd.apply_index": [""], "offsets.QuarterEnd.apply_index": [""], "tseries.offsets.QuarterEnd.apply_index": [""], "pandas.tseries.offsets.QuarterEnd.apply_index": [""], "QuarterEnd.copy": [""], "offsets.QuarterEnd.copy": [""], "tseries.offsets.QuarterEnd.copy": [""], "pandas.tseries.offsets.QuarterEnd.copy": [""], "QuarterEnd.isAnchored": [""], "offsets.QuarterEnd.isAnchored": [""], "tseries.offsets.QuarterEnd.isAnchored": [""], "pandas.tseries.offsets.QuarterEnd.isAnchored": [""], "QuarterEnd.onOffset": [""], "offsets.QuarterEnd.onOffset": [""], "tseries.offsets.QuarterEnd.onOffset": [""], "pandas.tseries.offsets.QuarterEnd.onOffset": [""], "QuarterEnd.is_anchored": [""], "offsets.QuarterEnd.is_anchored": [""], "tseries.offsets.QuarterEnd.is_anchored": [""], "pandas.tseries.offsets.QuarterEnd.is_anchored": [""], "QuarterEnd.is_on_offset": [""], "offsets.QuarterEnd.is_on_offset": [""], "tseries.offsets.QuarterEnd.is_on_offset": [""], "pandas.tseries.offsets.QuarterEnd.is_on_offset": [""], "QuarterEnd.__call__": ["Call self as a function."], "offsets.QuarterEnd.__call__": ["Call self as a function."], "tseries.offsets.QuarterEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.QuarterEnd.__call__": ["Call self as a function."], "QuarterEnd.is_month_start": [""], "offsets.QuarterEnd.is_month_start": [""], "tseries.offsets.QuarterEnd.is_month_start": [""], "pandas.tseries.offsets.QuarterEnd.is_month_start": [""], "QuarterEnd.is_month_end": [""], "offsets.QuarterEnd.is_month_end": [""], "tseries.offsets.QuarterEnd.is_month_end": [""], "pandas.tseries.offsets.QuarterEnd.is_month_end": [""], "QuarterEnd.is_quarter_start": [""], "offsets.QuarterEnd.is_quarter_start": [""], "tseries.offsets.QuarterEnd.is_quarter_start": [""], "pandas.tseries.offsets.QuarterEnd.is_quarter_start": [""], "QuarterEnd.is_quarter_end": [""], "offsets.QuarterEnd.is_quarter_end": [""], "tseries.offsets.QuarterEnd.is_quarter_end": [""], "pandas.tseries.offsets.QuarterEnd.is_quarter_end": [""], "QuarterEnd.is_year_start": [""], "offsets.QuarterEnd.is_year_start": [""], "tseries.offsets.QuarterEnd.is_year_start": [""], "pandas.tseries.offsets.QuarterEnd.is_year_start": [""], "QuarterEnd.is_year_end": [""], "offsets.QuarterEnd.is_year_end": [""], "tseries.offsets.QuarterEnd.is_year_end": [""], "pandas.tseries.offsets.QuarterEnd.is_year_end": [""], "QuarterBegin": ["DateOffset increments between Quarter start dates."], "offsets.QuarterBegin": ["DateOffset increments between Quarter start dates."], "tseries.offsets.QuarterBegin": ["DateOffset increments between Quarter start dates."], "pandas.tseries.offsets.QuarterBegin": ["DateOffset increments between Quarter start dates."], "QuarterBegin.freqstr": [""], "offsets.QuarterBegin.freqstr": [""], "tseries.offsets.QuarterBegin.freqstr": [""], "pandas.tseries.offsets.QuarterBegin.freqstr": [""], "QuarterBegin.kwds": [""], "offsets.QuarterBegin.kwds": [""], "tseries.offsets.QuarterBegin.kwds": [""], "pandas.tseries.offsets.QuarterBegin.kwds": [""], "QuarterBegin.name": [""], "offsets.QuarterBegin.name": [""], "tseries.offsets.QuarterBegin.name": [""], "pandas.tseries.offsets.QuarterBegin.name": [""], "QuarterBegin.nanos": [""], "offsets.QuarterBegin.nanos": [""], "tseries.offsets.QuarterBegin.nanos": [""], "pandas.tseries.offsets.QuarterBegin.nanos": [""], "QuarterBegin.normalize": [""], "offsets.QuarterBegin.normalize": [""], "tseries.offsets.QuarterBegin.normalize": [""], "pandas.tseries.offsets.QuarterBegin.normalize": [""], "QuarterBegin.rule_code": [""], "offsets.QuarterBegin.rule_code": [""], "tseries.offsets.QuarterBegin.rule_code": [""], "pandas.tseries.offsets.QuarterBegin.rule_code": [""], "QuarterBegin.n": [""], "offsets.QuarterBegin.n": [""], "tseries.offsets.QuarterBegin.n": [""], "pandas.tseries.offsets.QuarterBegin.n": [""], "QuarterBegin.startingMonth": [""], "offsets.QuarterBegin.startingMonth": [""], "tseries.offsets.QuarterBegin.startingMonth": [""], "pandas.tseries.offsets.QuarterBegin.startingMonth": [""], "QuarterBegin.apply": [""], "offsets.QuarterBegin.apply": [""], "tseries.offsets.QuarterBegin.apply": [""], "pandas.tseries.offsets.QuarterBegin.apply": [""], "QuarterBegin.apply_index": [""], "offsets.QuarterBegin.apply_index": [""], "tseries.offsets.QuarterBegin.apply_index": [""], "pandas.tseries.offsets.QuarterBegin.apply_index": [""], "QuarterBegin.copy": [""], "offsets.QuarterBegin.copy": [""], "tseries.offsets.QuarterBegin.copy": [""], "pandas.tseries.offsets.QuarterBegin.copy": [""], "QuarterBegin.isAnchored": [""], "offsets.QuarterBegin.isAnchored": [""], "tseries.offsets.QuarterBegin.isAnchored": [""], "pandas.tseries.offsets.QuarterBegin.isAnchored": [""], "QuarterBegin.onOffset": [""], "offsets.QuarterBegin.onOffset": [""], "tseries.offsets.QuarterBegin.onOffset": [""], "pandas.tseries.offsets.QuarterBegin.onOffset": [""], "QuarterBegin.is_anchored": [""], "offsets.QuarterBegin.is_anchored": [""], "tseries.offsets.QuarterBegin.is_anchored": [""], "pandas.tseries.offsets.QuarterBegin.is_anchored": [""], "QuarterBegin.is_on_offset": [""], "offsets.QuarterBegin.is_on_offset": [""], "tseries.offsets.QuarterBegin.is_on_offset": [""], "pandas.tseries.offsets.QuarterBegin.is_on_offset": [""], "QuarterBegin.__call__": ["Call self as a function."], "offsets.QuarterBegin.__call__": ["Call self as a function."], "tseries.offsets.QuarterBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.QuarterBegin.__call__": ["Call self as a function."], "QuarterBegin.is_month_start": [""], "offsets.QuarterBegin.is_month_start": [""], "tseries.offsets.QuarterBegin.is_month_start": [""], "pandas.tseries.offsets.QuarterBegin.is_month_start": [""], "QuarterBegin.is_month_end": [""], "offsets.QuarterBegin.is_month_end": [""], "tseries.offsets.QuarterBegin.is_month_end": [""], "pandas.tseries.offsets.QuarterBegin.is_month_end": [""], "QuarterBegin.is_quarter_start": [""], "offsets.QuarterBegin.is_quarter_start": [""], "tseries.offsets.QuarterBegin.is_quarter_start": [""], "pandas.tseries.offsets.QuarterBegin.is_quarter_start": [""], "QuarterBegin.is_quarter_end": [""], "offsets.QuarterBegin.is_quarter_end": [""], "tseries.offsets.QuarterBegin.is_quarter_end": [""], "pandas.tseries.offsets.QuarterBegin.is_quarter_end": [""], "QuarterBegin.is_year_start": [""], "offsets.QuarterBegin.is_year_start": [""], "tseries.offsets.QuarterBegin.is_year_start": [""], "pandas.tseries.offsets.QuarterBegin.is_year_start": [""], "QuarterBegin.is_year_end": [""], "offsets.QuarterBegin.is_year_end": [""], "tseries.offsets.QuarterBegin.is_year_end": [""], "pandas.tseries.offsets.QuarterBegin.is_year_end": [""], "BYearEnd": ["DateOffset increments between the last business day of the year."], "offsets.BYearEnd": ["DateOffset increments between the last business day of the year."], "tseries.offsets.BYearEnd": ["DateOffset increments between the last business day of the year."], "pandas.tseries.offsets.BYearEnd": ["DateOffset increments between the last business day of the year."], "BYearEnd.freqstr": [""], "offsets.BYearEnd.freqstr": [""], "tseries.offsets.BYearEnd.freqstr": [""], "pandas.tseries.offsets.BYearEnd.freqstr": [""], "BYearEnd.kwds": [""], "offsets.BYearEnd.kwds": [""], "tseries.offsets.BYearEnd.kwds": [""], "pandas.tseries.offsets.BYearEnd.kwds": [""], "BYearEnd.name": [""], "offsets.BYearEnd.name": [""], "tseries.offsets.BYearEnd.name": [""], "pandas.tseries.offsets.BYearEnd.name": [""], "BYearEnd.nanos": [""], "offsets.BYearEnd.nanos": [""], "tseries.offsets.BYearEnd.nanos": [""], "pandas.tseries.offsets.BYearEnd.nanos": [""], "BYearEnd.normalize": [""], "offsets.BYearEnd.normalize": [""], "tseries.offsets.BYearEnd.normalize": [""], "pandas.tseries.offsets.BYearEnd.normalize": [""], "BYearEnd.rule_code": [""], "offsets.BYearEnd.rule_code": [""], "tseries.offsets.BYearEnd.rule_code": [""], "pandas.tseries.offsets.BYearEnd.rule_code": [""], "BYearEnd.n": [""], "offsets.BYearEnd.n": [""], "tseries.offsets.BYearEnd.n": [""], "pandas.tseries.offsets.BYearEnd.n": [""], "BYearEnd.month": [""], "offsets.BYearEnd.month": [""], "tseries.offsets.BYearEnd.month": [""], "pandas.tseries.offsets.BYearEnd.month": [""], "BYearEnd.apply": [""], "offsets.BYearEnd.apply": [""], "tseries.offsets.BYearEnd.apply": [""], "pandas.tseries.offsets.BYearEnd.apply": [""], "BYearEnd.apply_index": [""], "offsets.BYearEnd.apply_index": [""], "tseries.offsets.BYearEnd.apply_index": [""], "pandas.tseries.offsets.BYearEnd.apply_index": [""], "BYearEnd.copy": [""], "offsets.BYearEnd.copy": [""], "tseries.offsets.BYearEnd.copy": [""], "pandas.tseries.offsets.BYearEnd.copy": [""], "BYearEnd.isAnchored": [""], "offsets.BYearEnd.isAnchored": [""], "tseries.offsets.BYearEnd.isAnchored": [""], "pandas.tseries.offsets.BYearEnd.isAnchored": [""], "BYearEnd.onOffset": [""], "offsets.BYearEnd.onOffset": [""], "tseries.offsets.BYearEnd.onOffset": [""], "pandas.tseries.offsets.BYearEnd.onOffset": [""], "BYearEnd.is_anchored": [""], "offsets.BYearEnd.is_anchored": [""], "tseries.offsets.BYearEnd.is_anchored": [""], "pandas.tseries.offsets.BYearEnd.is_anchored": [""], "BYearEnd.is_on_offset": [""], "offsets.BYearEnd.is_on_offset": [""], "tseries.offsets.BYearEnd.is_on_offset": [""], "pandas.tseries.offsets.BYearEnd.is_on_offset": [""], "BYearEnd.__call__": ["Call self as a function."], "offsets.BYearEnd.__call__": ["Call self as a function."], "tseries.offsets.BYearEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.BYearEnd.__call__": ["Call self as a function."], "BYearEnd.is_month_start": [""], "offsets.BYearEnd.is_month_start": [""], "tseries.offsets.BYearEnd.is_month_start": [""], "pandas.tseries.offsets.BYearEnd.is_month_start": [""], "BYearEnd.is_month_end": [""], "offsets.BYearEnd.is_month_end": [""], "tseries.offsets.BYearEnd.is_month_end": [""], "pandas.tseries.offsets.BYearEnd.is_month_end": [""], "BYearEnd.is_quarter_start": [""], "offsets.BYearEnd.is_quarter_start": [""], "tseries.offsets.BYearEnd.is_quarter_start": [""], "pandas.tseries.offsets.BYearEnd.is_quarter_start": [""], "BYearEnd.is_quarter_end": [""], "offsets.BYearEnd.is_quarter_end": [""], "tseries.offsets.BYearEnd.is_quarter_end": [""], "pandas.tseries.offsets.BYearEnd.is_quarter_end": [""], "BYearEnd.is_year_start": [""], "offsets.BYearEnd.is_year_start": [""], "tseries.offsets.BYearEnd.is_year_start": [""], "pandas.tseries.offsets.BYearEnd.is_year_start": [""], "BYearEnd.is_year_end": [""], "offsets.BYearEnd.is_year_end": [""], "tseries.offsets.BYearEnd.is_year_end": [""], "pandas.tseries.offsets.BYearEnd.is_year_end": [""], "BYearBegin": ["DateOffset increments between the first business day of the year."], "offsets.BYearBegin": ["DateOffset increments between the first business day of the year."], "tseries.offsets.BYearBegin": ["DateOffset increments between the first business day of the year."], "pandas.tseries.offsets.BYearBegin": ["DateOffset increments between the first business day of the year."], "BYearBegin.freqstr": [""], "offsets.BYearBegin.freqstr": [""], "tseries.offsets.BYearBegin.freqstr": [""], "pandas.tseries.offsets.BYearBegin.freqstr": [""], "BYearBegin.kwds": [""], "offsets.BYearBegin.kwds": [""], "tseries.offsets.BYearBegin.kwds": [""], "pandas.tseries.offsets.BYearBegin.kwds": [""], "BYearBegin.name": [""], "offsets.BYearBegin.name": [""], "tseries.offsets.BYearBegin.name": [""], "pandas.tseries.offsets.BYearBegin.name": [""], "BYearBegin.nanos": [""], "offsets.BYearBegin.nanos": [""], "tseries.offsets.BYearBegin.nanos": [""], "pandas.tseries.offsets.BYearBegin.nanos": [""], "BYearBegin.normalize": [""], "offsets.BYearBegin.normalize": [""], "tseries.offsets.BYearBegin.normalize": [""], "pandas.tseries.offsets.BYearBegin.normalize": [""], "BYearBegin.rule_code": [""], "offsets.BYearBegin.rule_code": [""], "tseries.offsets.BYearBegin.rule_code": [""], "pandas.tseries.offsets.BYearBegin.rule_code": [""], "BYearBegin.n": [""], "offsets.BYearBegin.n": [""], "tseries.offsets.BYearBegin.n": [""], "pandas.tseries.offsets.BYearBegin.n": [""], "BYearBegin.month": [""], "offsets.BYearBegin.month": [""], "tseries.offsets.BYearBegin.month": [""], "pandas.tseries.offsets.BYearBegin.month": [""], "BYearBegin.apply": [""], "offsets.BYearBegin.apply": [""], "tseries.offsets.BYearBegin.apply": [""], "pandas.tseries.offsets.BYearBegin.apply": [""], "BYearBegin.apply_index": [""], "offsets.BYearBegin.apply_index": [""], "tseries.offsets.BYearBegin.apply_index": [""], "pandas.tseries.offsets.BYearBegin.apply_index": [""], "BYearBegin.copy": [""], "offsets.BYearBegin.copy": [""], "tseries.offsets.BYearBegin.copy": [""], "pandas.tseries.offsets.BYearBegin.copy": [""], "BYearBegin.isAnchored": [""], "offsets.BYearBegin.isAnchored": [""], "tseries.offsets.BYearBegin.isAnchored": [""], "pandas.tseries.offsets.BYearBegin.isAnchored": [""], "BYearBegin.onOffset": [""], "offsets.BYearBegin.onOffset": [""], "tseries.offsets.BYearBegin.onOffset": [""], "pandas.tseries.offsets.BYearBegin.onOffset": [""], "BYearBegin.is_anchored": [""], "offsets.BYearBegin.is_anchored": [""], "tseries.offsets.BYearBegin.is_anchored": [""], "pandas.tseries.offsets.BYearBegin.is_anchored": [""], "BYearBegin.is_on_offset": [""], "offsets.BYearBegin.is_on_offset": [""], "tseries.offsets.BYearBegin.is_on_offset": [""], "pandas.tseries.offsets.BYearBegin.is_on_offset": [""], "BYearBegin.__call__": ["Call self as a function."], "offsets.BYearBegin.__call__": ["Call self as a function."], "tseries.offsets.BYearBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.BYearBegin.__call__": ["Call self as a function."], "BYearBegin.is_month_start": [""], "offsets.BYearBegin.is_month_start": [""], "tseries.offsets.BYearBegin.is_month_start": [""], "pandas.tseries.offsets.BYearBegin.is_month_start": [""], "BYearBegin.is_month_end": [""], "offsets.BYearBegin.is_month_end": [""], "tseries.offsets.BYearBegin.is_month_end": [""], "pandas.tseries.offsets.BYearBegin.is_month_end": [""], "BYearBegin.is_quarter_start": [""], "offsets.BYearBegin.is_quarter_start": [""], "tseries.offsets.BYearBegin.is_quarter_start": [""], "pandas.tseries.offsets.BYearBegin.is_quarter_start": [""], "BYearBegin.is_quarter_end": [""], "offsets.BYearBegin.is_quarter_end": [""], "tseries.offsets.BYearBegin.is_quarter_end": [""], "pandas.tseries.offsets.BYearBegin.is_quarter_end": [""], "BYearBegin.is_year_start": [""], "offsets.BYearBegin.is_year_start": [""], "tseries.offsets.BYearBegin.is_year_start": [""], "pandas.tseries.offsets.BYearBegin.is_year_start": [""], "BYearBegin.is_year_end": [""], "offsets.BYearBegin.is_year_end": [""], "tseries.offsets.BYearBegin.is_year_end": [""], "pandas.tseries.offsets.BYearBegin.is_year_end": [""], "YearEnd": ["DateOffset increments between calendar year ends."], "offsets.YearEnd": ["DateOffset increments between calendar year ends."], "tseries.offsets.YearEnd": ["DateOffset increments between calendar year ends."], "pandas.tseries.offsets.YearEnd": ["DateOffset increments between calendar year ends."], "YearEnd.freqstr": [""], "offsets.YearEnd.freqstr": [""], "tseries.offsets.YearEnd.freqstr": [""], "pandas.tseries.offsets.YearEnd.freqstr": [""], "YearEnd.kwds": [""], "offsets.YearEnd.kwds": [""], "tseries.offsets.YearEnd.kwds": [""], "pandas.tseries.offsets.YearEnd.kwds": [""], "YearEnd.name": [""], "offsets.YearEnd.name": [""], "tseries.offsets.YearEnd.name": [""], "pandas.tseries.offsets.YearEnd.name": [""], "YearEnd.nanos": [""], "offsets.YearEnd.nanos": [""], "tseries.offsets.YearEnd.nanos": [""], "pandas.tseries.offsets.YearEnd.nanos": [""], "YearEnd.normalize": [""], "offsets.YearEnd.normalize": [""], "tseries.offsets.YearEnd.normalize": [""], "pandas.tseries.offsets.YearEnd.normalize": [""], "YearEnd.rule_code": [""], "offsets.YearEnd.rule_code": [""], "tseries.offsets.YearEnd.rule_code": [""], "pandas.tseries.offsets.YearEnd.rule_code": [""], "YearEnd.n": [""], "offsets.YearEnd.n": [""], "tseries.offsets.YearEnd.n": [""], "pandas.tseries.offsets.YearEnd.n": [""], "YearEnd.month": [""], "offsets.YearEnd.month": [""], "tseries.offsets.YearEnd.month": [""], "pandas.tseries.offsets.YearEnd.month": [""], "YearEnd.apply": [""], "offsets.YearEnd.apply": [""], "tseries.offsets.YearEnd.apply": [""], "pandas.tseries.offsets.YearEnd.apply": [""], "YearEnd.apply_index": [""], "offsets.YearEnd.apply_index": [""], "tseries.offsets.YearEnd.apply_index": [""], "pandas.tseries.offsets.YearEnd.apply_index": [""], "YearEnd.copy": [""], "offsets.YearEnd.copy": [""], "tseries.offsets.YearEnd.copy": [""], "pandas.tseries.offsets.YearEnd.copy": [""], "YearEnd.isAnchored": [""], "offsets.YearEnd.isAnchored": [""], "tseries.offsets.YearEnd.isAnchored": [""], "pandas.tseries.offsets.YearEnd.isAnchored": [""], "YearEnd.onOffset": [""], "offsets.YearEnd.onOffset": [""], "tseries.offsets.YearEnd.onOffset": [""], "pandas.tseries.offsets.YearEnd.onOffset": [""], "YearEnd.is_anchored": [""], "offsets.YearEnd.is_anchored": [""], "tseries.offsets.YearEnd.is_anchored": [""], "pandas.tseries.offsets.YearEnd.is_anchored": [""], "YearEnd.is_on_offset": [""], "offsets.YearEnd.is_on_offset": [""], "tseries.offsets.YearEnd.is_on_offset": [""], "pandas.tseries.offsets.YearEnd.is_on_offset": [""], "YearEnd.__call__": ["Call self as a function."], "offsets.YearEnd.__call__": ["Call self as a function."], "tseries.offsets.YearEnd.__call__": ["Call self as a function."], "pandas.tseries.offsets.YearEnd.__call__": ["Call self as a function."], "YearEnd.is_month_start": [""], "offsets.YearEnd.is_month_start": [""], "tseries.offsets.YearEnd.is_month_start": [""], "pandas.tseries.offsets.YearEnd.is_month_start": [""], "YearEnd.is_month_end": [""], "offsets.YearEnd.is_month_end": [""], "tseries.offsets.YearEnd.is_month_end": [""], "pandas.tseries.offsets.YearEnd.is_month_end": [""], "YearEnd.is_quarter_start": [""], "offsets.YearEnd.is_quarter_start": [""], "tseries.offsets.YearEnd.is_quarter_start": [""], "pandas.tseries.offsets.YearEnd.is_quarter_start": [""], "YearEnd.is_quarter_end": [""], "offsets.YearEnd.is_quarter_end": [""], "tseries.offsets.YearEnd.is_quarter_end": [""], "pandas.tseries.offsets.YearEnd.is_quarter_end": [""], "YearEnd.is_year_start": [""], "offsets.YearEnd.is_year_start": [""], "tseries.offsets.YearEnd.is_year_start": [""], "pandas.tseries.offsets.YearEnd.is_year_start": [""], "YearEnd.is_year_end": [""], "offsets.YearEnd.is_year_end": [""], "tseries.offsets.YearEnd.is_year_end": [""], "pandas.tseries.offsets.YearEnd.is_year_end": [""], "YearBegin": ["DateOffset increments between calendar year begin dates."], "offsets.YearBegin": ["DateOffset increments between calendar year begin dates."], "tseries.offsets.YearBegin": ["DateOffset increments between calendar year begin dates."], "pandas.tseries.offsets.YearBegin": ["DateOffset increments between calendar year begin dates."], "YearBegin.freqstr": [""], "offsets.YearBegin.freqstr": [""], "tseries.offsets.YearBegin.freqstr": [""], "pandas.tseries.offsets.YearBegin.freqstr": [""], "YearBegin.kwds": [""], "offsets.YearBegin.kwds": [""], "tseries.offsets.YearBegin.kwds": [""], "pandas.tseries.offsets.YearBegin.kwds": [""], "YearBegin.name": [""], "offsets.YearBegin.name": [""], "tseries.offsets.YearBegin.name": [""], "pandas.tseries.offsets.YearBegin.name": [""], "YearBegin.nanos": [""], "offsets.YearBegin.nanos": [""], "tseries.offsets.YearBegin.nanos": [""], "pandas.tseries.offsets.YearBegin.nanos": [""], "YearBegin.normalize": [""], "offsets.YearBegin.normalize": [""], "tseries.offsets.YearBegin.normalize": [""], "pandas.tseries.offsets.YearBegin.normalize": [""], "YearBegin.rule_code": [""], "offsets.YearBegin.rule_code": [""], "tseries.offsets.YearBegin.rule_code": [""], "pandas.tseries.offsets.YearBegin.rule_code": [""], "YearBegin.n": [""], "offsets.YearBegin.n": [""], "tseries.offsets.YearBegin.n": [""], "pandas.tseries.offsets.YearBegin.n": [""], "YearBegin.month": [""], "offsets.YearBegin.month": [""], "tseries.offsets.YearBegin.month": [""], "pandas.tseries.offsets.YearBegin.month": [""], "YearBegin.apply": [""], "offsets.YearBegin.apply": [""], "tseries.offsets.YearBegin.apply": [""], "pandas.tseries.offsets.YearBegin.apply": [""], "YearBegin.apply_index": [""], "offsets.YearBegin.apply_index": [""], "tseries.offsets.YearBegin.apply_index": [""], "pandas.tseries.offsets.YearBegin.apply_index": [""], "YearBegin.copy": [""], "offsets.YearBegin.copy": [""], "tseries.offsets.YearBegin.copy": [""], "pandas.tseries.offsets.YearBegin.copy": [""], "YearBegin.isAnchored": [""], "offsets.YearBegin.isAnchored": [""], "tseries.offsets.YearBegin.isAnchored": [""], "pandas.tseries.offsets.YearBegin.isAnchored": [""], "YearBegin.onOffset": [""], "offsets.YearBegin.onOffset": [""], "tseries.offsets.YearBegin.onOffset": [""], "pandas.tseries.offsets.YearBegin.onOffset": [""], "YearBegin.is_anchored": [""], "offsets.YearBegin.is_anchored": [""], "tseries.offsets.YearBegin.is_anchored": [""], "pandas.tseries.offsets.YearBegin.is_anchored": [""], "YearBegin.is_on_offset": [""], "offsets.YearBegin.is_on_offset": [""], "tseries.offsets.YearBegin.is_on_offset": [""], "pandas.tseries.offsets.YearBegin.is_on_offset": [""], "YearBegin.__call__": ["Call self as a function."], "offsets.YearBegin.__call__": ["Call self as a function."], "tseries.offsets.YearBegin.__call__": ["Call self as a function."], "pandas.tseries.offsets.YearBegin.__call__": ["Call self as a function."], "YearBegin.is_month_start": [""], "offsets.YearBegin.is_month_start": [""], "tseries.offsets.YearBegin.is_month_start": [""], "pandas.tseries.offsets.YearBegin.is_month_start": [""], "YearBegin.is_month_end": [""], "offsets.YearBegin.is_month_end": [""], "tseries.offsets.YearBegin.is_month_end": [""], "pandas.tseries.offsets.YearBegin.is_month_end": [""], "YearBegin.is_quarter_start": [""], "offsets.YearBegin.is_quarter_start": [""], "tseries.offsets.YearBegin.is_quarter_start": [""], "pandas.tseries.offsets.YearBegin.is_quarter_start": [""], "YearBegin.is_quarter_end": [""], "offsets.YearBegin.is_quarter_end": [""], "tseries.offsets.YearBegin.is_quarter_end": [""], "pandas.tseries.offsets.YearBegin.is_quarter_end": [""], "YearBegin.is_year_start": [""], "offsets.YearBegin.is_year_start": [""], "tseries.offsets.YearBegin.is_year_start": [""], "pandas.tseries.offsets.YearBegin.is_year_start": [""], "YearBegin.is_year_end": [""], "offsets.YearBegin.is_year_end": [""], "tseries.offsets.YearBegin.is_year_end": [""], "pandas.tseries.offsets.YearBegin.is_year_end": [""], "FY5253": ["Describes 52-53 week fiscal year."], "offsets.FY5253": ["Describes 52-53 week fiscal year."], "tseries.offsets.FY5253": ["Describes 52-53 week fiscal year."], "pandas.tseries.offsets.FY5253": ["Describes 52-53 week fiscal year."], "FY5253.freqstr": [""], "offsets.FY5253.freqstr": [""], "tseries.offsets.FY5253.freqstr": [""], "pandas.tseries.offsets.FY5253.freqstr": [""], "FY5253.kwds": [""], "offsets.FY5253.kwds": [""], "tseries.offsets.FY5253.kwds": [""], "pandas.tseries.offsets.FY5253.kwds": [""], "FY5253.name": [""], "offsets.FY5253.name": [""], "tseries.offsets.FY5253.name": [""], "pandas.tseries.offsets.FY5253.name": [""], "FY5253.nanos": [""], "offsets.FY5253.nanos": [""], "tseries.offsets.FY5253.nanos": [""], "pandas.tseries.offsets.FY5253.nanos": [""], "FY5253.normalize": [""], "offsets.FY5253.normalize": [""], "tseries.offsets.FY5253.normalize": [""], "pandas.tseries.offsets.FY5253.normalize": [""], "FY5253.rule_code": [""], "offsets.FY5253.rule_code": [""], "tseries.offsets.FY5253.rule_code": [""], "pandas.tseries.offsets.FY5253.rule_code": [""], "FY5253.n": [""], "offsets.FY5253.n": [""], "tseries.offsets.FY5253.n": [""], "pandas.tseries.offsets.FY5253.n": [""], "FY5253.startingMonth": [""], "offsets.FY5253.startingMonth": [""], "tseries.offsets.FY5253.startingMonth": [""], "pandas.tseries.offsets.FY5253.startingMonth": [""], "variation": [""], "FY5253.variation": [""], "offsets.FY5253.variation": [""], "tseries.offsets.FY5253.variation": [""], "pandas.tseries.offsets.FY5253.variation": [""], "FY5253.weekday": [""], "offsets.FY5253.weekday": [""], "tseries.offsets.FY5253.weekday": [""], "pandas.tseries.offsets.FY5253.weekday": [""], "FY5253.apply": [""], "offsets.FY5253.apply": [""], "tseries.offsets.FY5253.apply": [""], "pandas.tseries.offsets.FY5253.apply": [""], "FY5253.apply_index": [""], "offsets.FY5253.apply_index": [""], "tseries.offsets.FY5253.apply_index": [""], "pandas.tseries.offsets.FY5253.apply_index": [""], "FY5253.copy": [""], "offsets.FY5253.copy": [""], "tseries.offsets.FY5253.copy": [""], "pandas.tseries.offsets.FY5253.copy": [""], "get_rule_code_suffix": [""], "FY5253.get_rule_code_suffix": [""], "offsets.FY5253.get_rule_code_suffix": [""], "tseries.offsets.FY5253.get_rule_code_suffix": [""], "pandas.tseries.offsets.FY5253.get_rule_code_suffix": [""], "get_year_end": [""], "FY5253.get_year_end": [""], "offsets.FY5253.get_year_end": [""], "tseries.offsets.FY5253.get_year_end": [""], "pandas.tseries.offsets.FY5253.get_year_end": [""], "FY5253.isAnchored": [""], "offsets.FY5253.isAnchored": [""], "tseries.offsets.FY5253.isAnchored": [""], "pandas.tseries.offsets.FY5253.isAnchored": [""], "FY5253.onOffset": [""], "offsets.FY5253.onOffset": [""], "tseries.offsets.FY5253.onOffset": [""], "pandas.tseries.offsets.FY5253.onOffset": [""], "FY5253.is_anchored": [""], "offsets.FY5253.is_anchored": [""], "tseries.offsets.FY5253.is_anchored": [""], "pandas.tseries.offsets.FY5253.is_anchored": [""], "FY5253.is_on_offset": [""], "offsets.FY5253.is_on_offset": [""], "tseries.offsets.FY5253.is_on_offset": [""], "pandas.tseries.offsets.FY5253.is_on_offset": [""], "FY5253.__call__": ["Call self as a function."], "offsets.FY5253.__call__": ["Call self as a function."], "tseries.offsets.FY5253.__call__": ["Call self as a function."], "pandas.tseries.offsets.FY5253.__call__": ["Call self as a function."], "FY5253.is_month_start": [""], "offsets.FY5253.is_month_start": [""], "tseries.offsets.FY5253.is_month_start": [""], "pandas.tseries.offsets.FY5253.is_month_start": [""], "FY5253.is_month_end": [""], "offsets.FY5253.is_month_end": [""], "tseries.offsets.FY5253.is_month_end": [""], "pandas.tseries.offsets.FY5253.is_month_end": [""], "FY5253.is_quarter_start": [""], "offsets.FY5253.is_quarter_start": [""], "tseries.offsets.FY5253.is_quarter_start": [""], "pandas.tseries.offsets.FY5253.is_quarter_start": [""], "FY5253.is_quarter_end": [""], "offsets.FY5253.is_quarter_end": [""], "tseries.offsets.FY5253.is_quarter_end": [""], "pandas.tseries.offsets.FY5253.is_quarter_end": [""], "FY5253.is_year_start": [""], "offsets.FY5253.is_year_start": [""], "tseries.offsets.FY5253.is_year_start": [""], "pandas.tseries.offsets.FY5253.is_year_start": [""], "FY5253.is_year_end": [""], "offsets.FY5253.is_year_end": [""], "tseries.offsets.FY5253.is_year_end": [""], "pandas.tseries.offsets.FY5253.is_year_end": [""], "FY5253Quarter": ["DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar)."], "offsets.FY5253Quarter": ["DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar)."], "tseries.offsets.FY5253Quarter": ["DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar)."], "pandas.tseries.offsets.FY5253Quarter": ["DateOffset increments between business quarter dates for 52-53 week fiscal year (also known as a 4-4-5 calendar)."], "FY5253Quarter.freqstr": [""], "offsets.FY5253Quarter.freqstr": [""], "tseries.offsets.FY5253Quarter.freqstr": [""], "pandas.tseries.offsets.FY5253Quarter.freqstr": [""], "FY5253Quarter.kwds": [""], "offsets.FY5253Quarter.kwds": [""], "tseries.offsets.FY5253Quarter.kwds": [""], "pandas.tseries.offsets.FY5253Quarter.kwds": [""], "FY5253Quarter.name": [""], "offsets.FY5253Quarter.name": [""], "tseries.offsets.FY5253Quarter.name": [""], "pandas.tseries.offsets.FY5253Quarter.name": [""], "FY5253Quarter.nanos": [""], "offsets.FY5253Quarter.nanos": [""], "tseries.offsets.FY5253Quarter.nanos": [""], "pandas.tseries.offsets.FY5253Quarter.nanos": [""], "FY5253Quarter.normalize": [""], "offsets.FY5253Quarter.normalize": [""], "tseries.offsets.FY5253Quarter.normalize": [""], "pandas.tseries.offsets.FY5253Quarter.normalize": [""], "FY5253Quarter.rule_code": [""], "offsets.FY5253Quarter.rule_code": [""], "tseries.offsets.FY5253Quarter.rule_code": [""], "pandas.tseries.offsets.FY5253Quarter.rule_code": [""], "FY5253Quarter.n": [""], "offsets.FY5253Quarter.n": [""], "tseries.offsets.FY5253Quarter.n": [""], "pandas.tseries.offsets.FY5253Quarter.n": [""], "qtr_with_extra_week": [""], "FY5253Quarter.qtr_with_extra_week": [""], "offsets.FY5253Quarter.qtr_with_extra_week": [""], "tseries.offsets.FY5253Quarter.qtr_with_extra_week": [""], "pandas.tseries.offsets.FY5253Quarter.qtr_with_extra_week": [""], "FY5253Quarter.startingMonth": [""], "offsets.FY5253Quarter.startingMonth": [""], "tseries.offsets.FY5253Quarter.startingMonth": [""], "pandas.tseries.offsets.FY5253Quarter.startingMonth": [""], "FY5253Quarter.variation": [""], "offsets.FY5253Quarter.variation": [""], "tseries.offsets.FY5253Quarter.variation": [""], "pandas.tseries.offsets.FY5253Quarter.variation": [""], "FY5253Quarter.weekday": [""], "offsets.FY5253Quarter.weekday": [""], "tseries.offsets.FY5253Quarter.weekday": [""], "pandas.tseries.offsets.FY5253Quarter.weekday": [""], "FY5253Quarter.apply": [""], "offsets.FY5253Quarter.apply": [""], "tseries.offsets.FY5253Quarter.apply": [""], "pandas.tseries.offsets.FY5253Quarter.apply": [""], "FY5253Quarter.apply_index": [""], "offsets.FY5253Quarter.apply_index": [""], "tseries.offsets.FY5253Quarter.apply_index": [""], "pandas.tseries.offsets.FY5253Quarter.apply_index": [""], "FY5253Quarter.copy": [""], "offsets.FY5253Quarter.copy": [""], "tseries.offsets.FY5253Quarter.copy": [""], "pandas.tseries.offsets.FY5253Quarter.copy": [""], "FY5253Quarter.get_rule_code_suffix": [""], "offsets.FY5253Quarter.get_rule_code_suffix": [""], "tseries.offsets.FY5253Quarter.get_rule_code_suffix": [""], "pandas.tseries.offsets.FY5253Quarter.get_rule_code_suffix": [""], "get_weeks": [""], "FY5253Quarter.get_weeks": [""], "offsets.FY5253Quarter.get_weeks": [""], "tseries.offsets.FY5253Quarter.get_weeks": [""], "pandas.tseries.offsets.FY5253Quarter.get_weeks": [""], "FY5253Quarter.isAnchored": [""], "offsets.FY5253Quarter.isAnchored": [""], "tseries.offsets.FY5253Quarter.isAnchored": [""], "pandas.tseries.offsets.FY5253Quarter.isAnchored": [""], "FY5253Quarter.onOffset": [""], "offsets.FY5253Quarter.onOffset": [""], "tseries.offsets.FY5253Quarter.onOffset": [""], "pandas.tseries.offsets.FY5253Quarter.onOffset": [""], "FY5253Quarter.is_anchored": [""], "offsets.FY5253Quarter.is_anchored": [""], "tseries.offsets.FY5253Quarter.is_anchored": [""], "pandas.tseries.offsets.FY5253Quarter.is_anchored": [""], "FY5253Quarter.is_on_offset": [""], "offsets.FY5253Quarter.is_on_offset": [""], "tseries.offsets.FY5253Quarter.is_on_offset": [""], "pandas.tseries.offsets.FY5253Quarter.is_on_offset": [""], "year_has_extra_week": [""], "FY5253Quarter.year_has_extra_week": [""], "offsets.FY5253Quarter.year_has_extra_week": [""], "tseries.offsets.FY5253Quarter.year_has_extra_week": [""], "pandas.tseries.offsets.FY5253Quarter.year_has_extra_week": [""], "FY5253Quarter.__call__": ["Call self as a function."], "offsets.FY5253Quarter.__call__": ["Call self as a function."], "tseries.offsets.FY5253Quarter.__call__": ["Call self as a function."], "pandas.tseries.offsets.FY5253Quarter.__call__": ["Call self as a function."], "FY5253Quarter.is_month_start": [""], "offsets.FY5253Quarter.is_month_start": [""], "tseries.offsets.FY5253Quarter.is_month_start": [""], "pandas.tseries.offsets.FY5253Quarter.is_month_start": [""], "FY5253Quarter.is_month_end": [""], "offsets.FY5253Quarter.is_month_end": [""], "tseries.offsets.FY5253Quarter.is_month_end": [""], "pandas.tseries.offsets.FY5253Quarter.is_month_end": [""], "FY5253Quarter.is_quarter_start": [""], "offsets.FY5253Quarter.is_quarter_start": [""], "tseries.offsets.FY5253Quarter.is_quarter_start": [""], "pandas.tseries.offsets.FY5253Quarter.is_quarter_start": [""], "FY5253Quarter.is_quarter_end": [""], "offsets.FY5253Quarter.is_quarter_end": [""], "tseries.offsets.FY5253Quarter.is_quarter_end": [""], "pandas.tseries.offsets.FY5253Quarter.is_quarter_end": [""], "FY5253Quarter.is_year_start": [""], "offsets.FY5253Quarter.is_year_start": [""], "tseries.offsets.FY5253Quarter.is_year_start": [""], "pandas.tseries.offsets.FY5253Quarter.is_year_start": [""], "FY5253Quarter.is_year_end": [""], "offsets.FY5253Quarter.is_year_end": [""], "tseries.offsets.FY5253Quarter.is_year_end": [""], "pandas.tseries.offsets.FY5253Quarter.is_year_end": [""], "Easter": ["DateOffset for the Easter holiday using logic defined in dateutil."], "offsets.Easter": ["DateOffset for the Easter holiday using logic defined in dateutil."], "tseries.offsets.Easter": ["DateOffset for the Easter holiday using logic defined in dateutil."], "pandas.tseries.offsets.Easter": ["DateOffset for the Easter holiday using logic defined in dateutil."], "Easter.freqstr": [""], "offsets.Easter.freqstr": [""], "tseries.offsets.Easter.freqstr": [""], "pandas.tseries.offsets.Easter.freqstr": [""], "Easter.kwds": [""], "offsets.Easter.kwds": [""], "tseries.offsets.Easter.kwds": [""], "pandas.tseries.offsets.Easter.kwds": [""], "Easter.name": [""], "offsets.Easter.name": [""], "tseries.offsets.Easter.name": [""], "pandas.tseries.offsets.Easter.name": [""], "Easter.nanos": [""], "offsets.Easter.nanos": [""], "tseries.offsets.Easter.nanos": [""], "pandas.tseries.offsets.Easter.nanos": [""], "Easter.normalize": [""], "offsets.Easter.normalize": [""], "tseries.offsets.Easter.normalize": [""], "pandas.tseries.offsets.Easter.normalize": [""], "Easter.rule_code": [""], "offsets.Easter.rule_code": [""], "tseries.offsets.Easter.rule_code": [""], "pandas.tseries.offsets.Easter.rule_code": [""], "Easter.n": [""], "offsets.Easter.n": [""], "tseries.offsets.Easter.n": [""], "pandas.tseries.offsets.Easter.n": [""], "Easter.apply": [""], "offsets.Easter.apply": [""], "tseries.offsets.Easter.apply": [""], "pandas.tseries.offsets.Easter.apply": [""], "Easter.apply_index": [""], "offsets.Easter.apply_index": [""], "tseries.offsets.Easter.apply_index": [""], "pandas.tseries.offsets.Easter.apply_index": [""], "Easter.copy": [""], "offsets.Easter.copy": [""], "tseries.offsets.Easter.copy": [""], "pandas.tseries.offsets.Easter.copy": [""], "Easter.isAnchored": [""], "offsets.Easter.isAnchored": [""], "tseries.offsets.Easter.isAnchored": [""], "pandas.tseries.offsets.Easter.isAnchored": [""], "Easter.onOffset": [""], "offsets.Easter.onOffset": [""], "tseries.offsets.Easter.onOffset": [""], "pandas.tseries.offsets.Easter.onOffset": [""], "Easter.is_anchored": [""], "offsets.Easter.is_anchored": [""], "tseries.offsets.Easter.is_anchored": [""], "pandas.tseries.offsets.Easter.is_anchored": [""], "Easter.is_on_offset": [""], "offsets.Easter.is_on_offset": [""], "tseries.offsets.Easter.is_on_offset": [""], "pandas.tseries.offsets.Easter.is_on_offset": [""], "Easter.__call__": ["Call self as a function."], "offsets.Easter.__call__": ["Call self as a function."], "tseries.offsets.Easter.__call__": ["Call self as a function."], "pandas.tseries.offsets.Easter.__call__": ["Call self as a function."], "Easter.is_month_start": [""], "offsets.Easter.is_month_start": [""], "tseries.offsets.Easter.is_month_start": [""], "pandas.tseries.offsets.Easter.is_month_start": [""], "Easter.is_month_end": [""], "offsets.Easter.is_month_end": [""], "tseries.offsets.Easter.is_month_end": [""], "pandas.tseries.offsets.Easter.is_month_end": [""], "Easter.is_quarter_start": [""], "offsets.Easter.is_quarter_start": [""], "tseries.offsets.Easter.is_quarter_start": [""], "pandas.tseries.offsets.Easter.is_quarter_start": [""], "Easter.is_quarter_end": [""], "offsets.Easter.is_quarter_end": [""], "tseries.offsets.Easter.is_quarter_end": [""], "pandas.tseries.offsets.Easter.is_quarter_end": [""], "Easter.is_year_start": [""], "offsets.Easter.is_year_start": [""], "tseries.offsets.Easter.is_year_start": [""], "pandas.tseries.offsets.Easter.is_year_start": [""], "Easter.is_year_end": [""], "offsets.Easter.is_year_end": [""], "tseries.offsets.Easter.is_year_end": [""], "pandas.tseries.offsets.Easter.is_year_end": [""], "Tick": [" class=\"rubric\">Attributes</p>\n"], "offsets.Tick": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Tick": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Tick": [" class=\"rubric\">Attributes</p>\n"], "Tick.delta": [""], "offsets.Tick.delta": [""], "tseries.offsets.Tick.delta": [""], "pandas.tseries.offsets.Tick.delta": [""], "Tick.freqstr": [""], "offsets.Tick.freqstr": [""], "tseries.offsets.Tick.freqstr": [""], "pandas.tseries.offsets.Tick.freqstr": [""], "Tick.kwds": [""], "offsets.Tick.kwds": [""], "tseries.offsets.Tick.kwds": [""], "pandas.tseries.offsets.Tick.kwds": [""], "Tick.name": [""], "offsets.Tick.name": [""], "tseries.offsets.Tick.name": [""], "pandas.tseries.offsets.Tick.name": [""], "Tick.nanos": [""], "offsets.Tick.nanos": [""], "tseries.offsets.Tick.nanos": [""], "pandas.tseries.offsets.Tick.nanos": [""], "Tick.normalize": [""], "offsets.Tick.normalize": [""], "tseries.offsets.Tick.normalize": [""], "pandas.tseries.offsets.Tick.normalize": [""], "Tick.rule_code": [""], "offsets.Tick.rule_code": [""], "tseries.offsets.Tick.rule_code": [""], "pandas.tseries.offsets.Tick.rule_code": [""], "Tick.n": [""], "offsets.Tick.n": [""], "tseries.offsets.Tick.n": [""], "pandas.tseries.offsets.Tick.n": [""], "Tick.copy": [""], "offsets.Tick.copy": [""], "tseries.offsets.Tick.copy": [""], "pandas.tseries.offsets.Tick.copy": [""], "Tick.isAnchored": [""], "offsets.Tick.isAnchored": [""], "tseries.offsets.Tick.isAnchored": [""], "pandas.tseries.offsets.Tick.isAnchored": [""], "Tick.onOffset": [""], "offsets.Tick.onOffset": [""], "tseries.offsets.Tick.onOffset": [""], "pandas.tseries.offsets.Tick.onOffset": [""], "Tick.is_anchored": [""], "offsets.Tick.is_anchored": [""], "tseries.offsets.Tick.is_anchored": [""], "pandas.tseries.offsets.Tick.is_anchored": [""], "Tick.is_on_offset": [""], "offsets.Tick.is_on_offset": [""], "tseries.offsets.Tick.is_on_offset": [""], "pandas.tseries.offsets.Tick.is_on_offset": [""], "Tick.__call__": ["Call self as a function."], "offsets.Tick.__call__": ["Call self as a function."], "tseries.offsets.Tick.__call__": ["Call self as a function."], "pandas.tseries.offsets.Tick.__call__": ["Call self as a function."], "Tick.apply": [""], "offsets.Tick.apply": [""], "tseries.offsets.Tick.apply": [""], "pandas.tseries.offsets.Tick.apply": [""], "Tick.apply_index": [""], "offsets.Tick.apply_index": [""], "tseries.offsets.Tick.apply_index": [""], "pandas.tseries.offsets.Tick.apply_index": [""], "Tick.is_month_start": [""], "offsets.Tick.is_month_start": [""], "tseries.offsets.Tick.is_month_start": [""], "pandas.tseries.offsets.Tick.is_month_start": [""], "Tick.is_month_end": [""], "offsets.Tick.is_month_end": [""], "tseries.offsets.Tick.is_month_end": [""], "pandas.tseries.offsets.Tick.is_month_end": [""], "Tick.is_quarter_start": [""], "offsets.Tick.is_quarter_start": [""], "tseries.offsets.Tick.is_quarter_start": [""], "pandas.tseries.offsets.Tick.is_quarter_start": [""], "Tick.is_quarter_end": [""], "offsets.Tick.is_quarter_end": [""], "tseries.offsets.Tick.is_quarter_end": [""], "pandas.tseries.offsets.Tick.is_quarter_end": [""], "Tick.is_year_start": [""], "offsets.Tick.is_year_start": [""], "tseries.offsets.Tick.is_year_start": [""], "pandas.tseries.offsets.Tick.is_year_start": [""], "Tick.is_year_end": [""], "offsets.Tick.is_year_end": [""], "tseries.offsets.Tick.is_year_end": [""], "pandas.tseries.offsets.Tick.is_year_end": [""], "Day": [" class=\"rubric\">Attributes</p>\n"], "offsets.Day": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Day": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Day": [" class=\"rubric\">Attributes</p>\n"], "Day.delta": [""], "offsets.Day.delta": [""], "tseries.offsets.Day.delta": [""], "pandas.tseries.offsets.Day.delta": [""], "Day.freqstr": [""], "offsets.Day.freqstr": [""], "tseries.offsets.Day.freqstr": [""], "pandas.tseries.offsets.Day.freqstr": [""], "Day.kwds": [""], "offsets.Day.kwds": [""], "tseries.offsets.Day.kwds": [""], "pandas.tseries.offsets.Day.kwds": [""], "Day.name": [""], "offsets.Day.name": [""], "tseries.offsets.Day.name": [""], "pandas.tseries.offsets.Day.name": [""], "Day.nanos": [""], "offsets.Day.nanos": [""], "tseries.offsets.Day.nanos": [""], "pandas.tseries.offsets.Day.nanos": [""], "Day.normalize": [""], "offsets.Day.normalize": [""], "tseries.offsets.Day.normalize": [""], "pandas.tseries.offsets.Day.normalize": [""], "Day.rule_code": [""], "offsets.Day.rule_code": [""], "tseries.offsets.Day.rule_code": [""], "pandas.tseries.offsets.Day.rule_code": [""], "Day.n": [""], "offsets.Day.n": [""], "tseries.offsets.Day.n": [""], "pandas.tseries.offsets.Day.n": [""], "Day.copy": [""], "offsets.Day.copy": [""], "tseries.offsets.Day.copy": [""], "pandas.tseries.offsets.Day.copy": [""], "Day.isAnchored": [""], "offsets.Day.isAnchored": [""], "tseries.offsets.Day.isAnchored": [""], "pandas.tseries.offsets.Day.isAnchored": [""], "Day.onOffset": [""], "offsets.Day.onOffset": [""], "tseries.offsets.Day.onOffset": [""], "pandas.tseries.offsets.Day.onOffset": [""], "Day.is_anchored": [""], "offsets.Day.is_anchored": [""], "tseries.offsets.Day.is_anchored": [""], "pandas.tseries.offsets.Day.is_anchored": [""], "Day.is_on_offset": [""], "offsets.Day.is_on_offset": [""], "tseries.offsets.Day.is_on_offset": [""], "pandas.tseries.offsets.Day.is_on_offset": [""], "Day.__call__": ["Call self as a function."], "offsets.Day.__call__": ["Call self as a function."], "tseries.offsets.Day.__call__": ["Call self as a function."], "pandas.tseries.offsets.Day.__call__": ["Call self as a function."], "Day.apply": [""], "offsets.Day.apply": [""], "tseries.offsets.Day.apply": [""], "pandas.tseries.offsets.Day.apply": [""], "Day.apply_index": [""], "offsets.Day.apply_index": [""], "tseries.offsets.Day.apply_index": [""], "pandas.tseries.offsets.Day.apply_index": [""], "Day.is_month_start": [""], "offsets.Day.is_month_start": [""], "tseries.offsets.Day.is_month_start": [""], "pandas.tseries.offsets.Day.is_month_start": [""], "Day.is_month_end": [""], "offsets.Day.is_month_end": [""], "tseries.offsets.Day.is_month_end": [""], "pandas.tseries.offsets.Day.is_month_end": [""], "Day.is_quarter_start": [""], "offsets.Day.is_quarter_start": [""], "tseries.offsets.Day.is_quarter_start": [""], "pandas.tseries.offsets.Day.is_quarter_start": [""], "Day.is_quarter_end": [""], "offsets.Day.is_quarter_end": [""], "tseries.offsets.Day.is_quarter_end": [""], "pandas.tseries.offsets.Day.is_quarter_end": [""], "Day.is_year_start": [""], "offsets.Day.is_year_start": [""], "tseries.offsets.Day.is_year_start": [""], "pandas.tseries.offsets.Day.is_year_start": [""], "Day.is_year_end": [""], "offsets.Day.is_year_end": [""], "tseries.offsets.Day.is_year_end": [""], "pandas.tseries.offsets.Day.is_year_end": [""], "Hour": [" class=\"rubric\">Attributes</p>\n"], "offsets.Hour": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Hour": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Hour": [" class=\"rubric\">Attributes</p>\n"], "Hour.delta": [""], "offsets.Hour.delta": [""], "tseries.offsets.Hour.delta": [""], "pandas.tseries.offsets.Hour.delta": [""], "Hour.freqstr": [""], "offsets.Hour.freqstr": [""], "tseries.offsets.Hour.freqstr": [""], "pandas.tseries.offsets.Hour.freqstr": [""], "Hour.kwds": [""], "offsets.Hour.kwds": [""], "tseries.offsets.Hour.kwds": [""], "pandas.tseries.offsets.Hour.kwds": [""], "Hour.name": [""], "offsets.Hour.name": [""], "tseries.offsets.Hour.name": [""], "pandas.tseries.offsets.Hour.name": [""], "Hour.nanos": [""], "offsets.Hour.nanos": [""], "tseries.offsets.Hour.nanos": [""], "pandas.tseries.offsets.Hour.nanos": [""], "Hour.normalize": [""], "offsets.Hour.normalize": [""], "tseries.offsets.Hour.normalize": [""], "pandas.tseries.offsets.Hour.normalize": [""], "Hour.rule_code": [""], "offsets.Hour.rule_code": [""], "tseries.offsets.Hour.rule_code": [""], "pandas.tseries.offsets.Hour.rule_code": [""], "Hour.n": [""], "offsets.Hour.n": [""], "tseries.offsets.Hour.n": [""], "pandas.tseries.offsets.Hour.n": [""], "Hour.copy": [""], "offsets.Hour.copy": [""], "tseries.offsets.Hour.copy": [""], "pandas.tseries.offsets.Hour.copy": [""], "Hour.isAnchored": [""], "offsets.Hour.isAnchored": [""], "tseries.offsets.Hour.isAnchored": [""], "pandas.tseries.offsets.Hour.isAnchored": [""], "Hour.onOffset": [""], "offsets.Hour.onOffset": [""], "tseries.offsets.Hour.onOffset": [""], "pandas.tseries.offsets.Hour.onOffset": [""], "Hour.is_anchored": [""], "offsets.Hour.is_anchored": [""], "tseries.offsets.Hour.is_anchored": [""], "pandas.tseries.offsets.Hour.is_anchored": [""], "Hour.is_on_offset": [""], "offsets.Hour.is_on_offset": [""], "tseries.offsets.Hour.is_on_offset": [""], "pandas.tseries.offsets.Hour.is_on_offset": [""], "Hour.__call__": ["Call self as a function."], "offsets.Hour.__call__": ["Call self as a function."], "tseries.offsets.Hour.__call__": ["Call self as a function."], "pandas.tseries.offsets.Hour.__call__": ["Call self as a function."], "Hour.apply": [""], "offsets.Hour.apply": [""], "tseries.offsets.Hour.apply": [""], "pandas.tseries.offsets.Hour.apply": [""], "Hour.apply_index": [""], "offsets.Hour.apply_index": [""], "tseries.offsets.Hour.apply_index": [""], "pandas.tseries.offsets.Hour.apply_index": [""], "Hour.is_month_start": [""], "offsets.Hour.is_month_start": [""], "tseries.offsets.Hour.is_month_start": [""], "pandas.tseries.offsets.Hour.is_month_start": [""], "Hour.is_month_end": [""], "offsets.Hour.is_month_end": [""], "tseries.offsets.Hour.is_month_end": [""], "pandas.tseries.offsets.Hour.is_month_end": [""], "Hour.is_quarter_start": [""], "offsets.Hour.is_quarter_start": [""], "tseries.offsets.Hour.is_quarter_start": [""], "pandas.tseries.offsets.Hour.is_quarter_start": [""], "Hour.is_quarter_end": [""], "offsets.Hour.is_quarter_end": [""], "tseries.offsets.Hour.is_quarter_end": [""], "pandas.tseries.offsets.Hour.is_quarter_end": [""], "Hour.is_year_start": [""], "offsets.Hour.is_year_start": [""], "tseries.offsets.Hour.is_year_start": [""], "pandas.tseries.offsets.Hour.is_year_start": [""], "Hour.is_year_end": [""], "offsets.Hour.is_year_end": [""], "tseries.offsets.Hour.is_year_end": [""], "pandas.tseries.offsets.Hour.is_year_end": [""], "Minute": [" class=\"rubric\">Attributes</p>\n"], "offsets.Minute": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Minute": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Minute": [" class=\"rubric\">Attributes</p>\n"], "Minute.delta": [""], "offsets.Minute.delta": [""], "tseries.offsets.Minute.delta": [""], "pandas.tseries.offsets.Minute.delta": [""], "Minute.freqstr": [""], "offsets.Minute.freqstr": [""], "tseries.offsets.Minute.freqstr": [""], "pandas.tseries.offsets.Minute.freqstr": [""], "Minute.kwds": [""], "offsets.Minute.kwds": [""], "tseries.offsets.Minute.kwds": [""], "pandas.tseries.offsets.Minute.kwds": [""], "Minute.name": [""], "offsets.Minute.name": [""], "tseries.offsets.Minute.name": [""], "pandas.tseries.offsets.Minute.name": [""], "Minute.nanos": [""], "offsets.Minute.nanos": [""], "tseries.offsets.Minute.nanos": [""], "pandas.tseries.offsets.Minute.nanos": [""], "Minute.normalize": [""], "offsets.Minute.normalize": [""], "tseries.offsets.Minute.normalize": [""], "pandas.tseries.offsets.Minute.normalize": [""], "Minute.rule_code": [""], "offsets.Minute.rule_code": [""], "tseries.offsets.Minute.rule_code": [""], "pandas.tseries.offsets.Minute.rule_code": [""], "Minute.n": [""], "offsets.Minute.n": [""], "tseries.offsets.Minute.n": [""], "pandas.tseries.offsets.Minute.n": [""], "Minute.copy": [""], "offsets.Minute.copy": [""], "tseries.offsets.Minute.copy": [""], "pandas.tseries.offsets.Minute.copy": [""], "Minute.isAnchored": [""], "offsets.Minute.isAnchored": [""], "tseries.offsets.Minute.isAnchored": [""], "pandas.tseries.offsets.Minute.isAnchored": [""], "Minute.onOffset": [""], "offsets.Minute.onOffset": [""], "tseries.offsets.Minute.onOffset": [""], "pandas.tseries.offsets.Minute.onOffset": [""], "Minute.is_anchored": [""], "offsets.Minute.is_anchored": [""], "tseries.offsets.Minute.is_anchored": [""], "pandas.tseries.offsets.Minute.is_anchored": [""], "Minute.is_on_offset": [""], "offsets.Minute.is_on_offset": [""], "tseries.offsets.Minute.is_on_offset": [""], "pandas.tseries.offsets.Minute.is_on_offset": [""], "Minute.__call__": ["Call self as a function."], "offsets.Minute.__call__": ["Call self as a function."], "tseries.offsets.Minute.__call__": ["Call self as a function."], "pandas.tseries.offsets.Minute.__call__": ["Call self as a function."], "Minute.apply": [""], "offsets.Minute.apply": [""], "tseries.offsets.Minute.apply": [""], "pandas.tseries.offsets.Minute.apply": [""], "Minute.apply_index": [""], "offsets.Minute.apply_index": [""], "tseries.offsets.Minute.apply_index": [""], "pandas.tseries.offsets.Minute.apply_index": [""], "Minute.is_month_start": [""], "offsets.Minute.is_month_start": [""], "tseries.offsets.Minute.is_month_start": [""], "pandas.tseries.offsets.Minute.is_month_start": [""], "Minute.is_month_end": [""], "offsets.Minute.is_month_end": [""], "tseries.offsets.Minute.is_month_end": [""], "pandas.tseries.offsets.Minute.is_month_end": [""], "Minute.is_quarter_start": [""], "offsets.Minute.is_quarter_start": [""], "tseries.offsets.Minute.is_quarter_start": [""], "pandas.tseries.offsets.Minute.is_quarter_start": [""], "Minute.is_quarter_end": [""], "offsets.Minute.is_quarter_end": [""], "tseries.offsets.Minute.is_quarter_end": [""], "pandas.tseries.offsets.Minute.is_quarter_end": [""], "Minute.is_year_start": [""], "offsets.Minute.is_year_start": [""], "tseries.offsets.Minute.is_year_start": [""], "pandas.tseries.offsets.Minute.is_year_start": [""], "Minute.is_year_end": [""], "offsets.Minute.is_year_end": [""], "tseries.offsets.Minute.is_year_end": [""], "pandas.tseries.offsets.Minute.is_year_end": [""], "Second": [" class=\"rubric\">Attributes</p>\n"], "offsets.Second": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Second": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Second": [" class=\"rubric\">Attributes</p>\n"], "Second.delta": [""], "offsets.Second.delta": [""], "tseries.offsets.Second.delta": [""], "pandas.tseries.offsets.Second.delta": [""], "Second.freqstr": [""], "offsets.Second.freqstr": [""], "tseries.offsets.Second.freqstr": [""], "pandas.tseries.offsets.Second.freqstr": [""], "Second.kwds": [""], "offsets.Second.kwds": [""], "tseries.offsets.Second.kwds": [""], "pandas.tseries.offsets.Second.kwds": [""], "Second.name": [""], "offsets.Second.name": [""], "tseries.offsets.Second.name": [""], "pandas.tseries.offsets.Second.name": [""], "Second.nanos": [""], "offsets.Second.nanos": [""], "tseries.offsets.Second.nanos": [""], "pandas.tseries.offsets.Second.nanos": [""], "Second.normalize": [""], "offsets.Second.normalize": [""], "tseries.offsets.Second.normalize": [""], "pandas.tseries.offsets.Second.normalize": [""], "Second.rule_code": [""], "offsets.Second.rule_code": [""], "tseries.offsets.Second.rule_code": [""], "pandas.tseries.offsets.Second.rule_code": [""], "Second.n": [""], "offsets.Second.n": [""], "tseries.offsets.Second.n": [""], "pandas.tseries.offsets.Second.n": [""], "Second.copy": [""], "offsets.Second.copy": [""], "tseries.offsets.Second.copy": [""], "pandas.tseries.offsets.Second.copy": [""], "Second.isAnchored": [""], "offsets.Second.isAnchored": [""], "tseries.offsets.Second.isAnchored": [""], "pandas.tseries.offsets.Second.isAnchored": [""], "Second.onOffset": [""], "offsets.Second.onOffset": [""], "tseries.offsets.Second.onOffset": [""], "pandas.tseries.offsets.Second.onOffset": [""], "Second.is_anchored": [""], "offsets.Second.is_anchored": [""], "tseries.offsets.Second.is_anchored": [""], "pandas.tseries.offsets.Second.is_anchored": [""], "Second.is_on_offset": [""], "offsets.Second.is_on_offset": [""], "tseries.offsets.Second.is_on_offset": [""], "pandas.tseries.offsets.Second.is_on_offset": [""], "Second.__call__": ["Call self as a function."], "offsets.Second.__call__": ["Call self as a function."], "tseries.offsets.Second.__call__": ["Call self as a function."], "pandas.tseries.offsets.Second.__call__": ["Call self as a function."], "Second.apply": [""], "offsets.Second.apply": [""], "tseries.offsets.Second.apply": [""], "pandas.tseries.offsets.Second.apply": [""], "Second.apply_index": [""], "offsets.Second.apply_index": [""], "tseries.offsets.Second.apply_index": [""], "pandas.tseries.offsets.Second.apply_index": [""], "Second.is_month_start": [""], "offsets.Second.is_month_start": [""], "tseries.offsets.Second.is_month_start": [""], "pandas.tseries.offsets.Second.is_month_start": [""], "Second.is_month_end": [""], "offsets.Second.is_month_end": [""], "tseries.offsets.Second.is_month_end": [""], "pandas.tseries.offsets.Second.is_month_end": [""], "Second.is_quarter_start": [""], "offsets.Second.is_quarter_start": [""], "tseries.offsets.Second.is_quarter_start": [""], "pandas.tseries.offsets.Second.is_quarter_start": [""], "Second.is_quarter_end": [""], "offsets.Second.is_quarter_end": [""], "tseries.offsets.Second.is_quarter_end": [""], "pandas.tseries.offsets.Second.is_quarter_end": [""], "Second.is_year_start": [""], "offsets.Second.is_year_start": [""], "tseries.offsets.Second.is_year_start": [""], "pandas.tseries.offsets.Second.is_year_start": [""], "Second.is_year_end": [""], "offsets.Second.is_year_end": [""], "tseries.offsets.Second.is_year_end": [""], "pandas.tseries.offsets.Second.is_year_end": [""], "Milli": [" class=\"rubric\">Attributes</p>\n"], "offsets.Milli": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Milli": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Milli": [" class=\"rubric\">Attributes</p>\n"], "Milli.delta": [""], "offsets.Milli.delta": [""], "tseries.offsets.Milli.delta": [""], "pandas.tseries.offsets.Milli.delta": [""], "Milli.freqstr": [""], "offsets.Milli.freqstr": [""], "tseries.offsets.Milli.freqstr": [""], "pandas.tseries.offsets.Milli.freqstr": [""], "Milli.kwds": [""], "offsets.Milli.kwds": [""], "tseries.offsets.Milli.kwds": [""], "pandas.tseries.offsets.Milli.kwds": [""], "Milli.name": [""], "offsets.Milli.name": [""], "tseries.offsets.Milli.name": [""], "pandas.tseries.offsets.Milli.name": [""], "Milli.nanos": [""], "offsets.Milli.nanos": [""], "tseries.offsets.Milli.nanos": [""], "pandas.tseries.offsets.Milli.nanos": [""], "Milli.normalize": [""], "offsets.Milli.normalize": [""], "tseries.offsets.Milli.normalize": [""], "pandas.tseries.offsets.Milli.normalize": [""], "Milli.rule_code": [""], "offsets.Milli.rule_code": [""], "tseries.offsets.Milli.rule_code": [""], "pandas.tseries.offsets.Milli.rule_code": [""], "Milli.n": [""], "offsets.Milli.n": [""], "tseries.offsets.Milli.n": [""], "pandas.tseries.offsets.Milli.n": [""], "Milli.copy": [""], "offsets.Milli.copy": [""], "tseries.offsets.Milli.copy": [""], "pandas.tseries.offsets.Milli.copy": [""], "Milli.isAnchored": [""], "offsets.Milli.isAnchored": [""], "tseries.offsets.Milli.isAnchored": [""], "pandas.tseries.offsets.Milli.isAnchored": [""], "Milli.onOffset": [""], "offsets.Milli.onOffset": [""], "tseries.offsets.Milli.onOffset": [""], "pandas.tseries.offsets.Milli.onOffset": [""], "Milli.is_anchored": [""], "offsets.Milli.is_anchored": [""], "tseries.offsets.Milli.is_anchored": [""], "pandas.tseries.offsets.Milli.is_anchored": [""], "Milli.is_on_offset": [""], "offsets.Milli.is_on_offset": [""], "tseries.offsets.Milli.is_on_offset": [""], "pandas.tseries.offsets.Milli.is_on_offset": [""], "Milli.__call__": ["Call self as a function."], "offsets.Milli.__call__": ["Call self as a function."], "tseries.offsets.Milli.__call__": ["Call self as a function."], "pandas.tseries.offsets.Milli.__call__": ["Call self as a function."], "Milli.apply": [""], "offsets.Milli.apply": [""], "tseries.offsets.Milli.apply": [""], "pandas.tseries.offsets.Milli.apply": [""], "Milli.apply_index": [""], "offsets.Milli.apply_index": [""], "tseries.offsets.Milli.apply_index": [""], "pandas.tseries.offsets.Milli.apply_index": [""], "Milli.is_month_start": [""], "offsets.Milli.is_month_start": [""], "tseries.offsets.Milli.is_month_start": [""], "pandas.tseries.offsets.Milli.is_month_start": [""], "Milli.is_month_end": [""], "offsets.Milli.is_month_end": [""], "tseries.offsets.Milli.is_month_end": [""], "pandas.tseries.offsets.Milli.is_month_end": [""], "Milli.is_quarter_start": [""], "offsets.Milli.is_quarter_start": [""], "tseries.offsets.Milli.is_quarter_start": [""], "pandas.tseries.offsets.Milli.is_quarter_start": [""], "Milli.is_quarter_end": [""], "offsets.Milli.is_quarter_end": [""], "tseries.offsets.Milli.is_quarter_end": [""], "pandas.tseries.offsets.Milli.is_quarter_end": [""], "Milli.is_year_start": [""], "offsets.Milli.is_year_start": [""], "tseries.offsets.Milli.is_year_start": [""], "pandas.tseries.offsets.Milli.is_year_start": [""], "Milli.is_year_end": [""], "offsets.Milli.is_year_end": [""], "tseries.offsets.Milli.is_year_end": [""], "pandas.tseries.offsets.Milli.is_year_end": [""], "Micro": [" class=\"rubric\">Attributes</p>\n"], "offsets.Micro": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Micro": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Micro": [" class=\"rubric\">Attributes</p>\n"], "Micro.delta": [""], "offsets.Micro.delta": [""], "tseries.offsets.Micro.delta": [""], "pandas.tseries.offsets.Micro.delta": [""], "Micro.freqstr": [""], "offsets.Micro.freqstr": [""], "tseries.offsets.Micro.freqstr": [""], "pandas.tseries.offsets.Micro.freqstr": [""], "Micro.kwds": [""], "offsets.Micro.kwds": [""], "tseries.offsets.Micro.kwds": [""], "pandas.tseries.offsets.Micro.kwds": [""], "Micro.name": [""], "offsets.Micro.name": [""], "tseries.offsets.Micro.name": [""], "pandas.tseries.offsets.Micro.name": [""], "Micro.nanos": [""], "offsets.Micro.nanos": [""], "tseries.offsets.Micro.nanos": [""], "pandas.tseries.offsets.Micro.nanos": [""], "Micro.normalize": [""], "offsets.Micro.normalize": [""], "tseries.offsets.Micro.normalize": [""], "pandas.tseries.offsets.Micro.normalize": [""], "Micro.rule_code": [""], "offsets.Micro.rule_code": [""], "tseries.offsets.Micro.rule_code": [""], "pandas.tseries.offsets.Micro.rule_code": [""], "Micro.n": [""], "offsets.Micro.n": [""], "tseries.offsets.Micro.n": [""], "pandas.tseries.offsets.Micro.n": [""], "Micro.copy": [""], "offsets.Micro.copy": [""], "tseries.offsets.Micro.copy": [""], "pandas.tseries.offsets.Micro.copy": [""], "Micro.isAnchored": [""], "offsets.Micro.isAnchored": [""], "tseries.offsets.Micro.isAnchored": [""], "pandas.tseries.offsets.Micro.isAnchored": [""], "Micro.onOffset": [""], "offsets.Micro.onOffset": [""], "tseries.offsets.Micro.onOffset": [""], "pandas.tseries.offsets.Micro.onOffset": [""], "Micro.is_anchored": [""], "offsets.Micro.is_anchored": [""], "tseries.offsets.Micro.is_anchored": [""], "pandas.tseries.offsets.Micro.is_anchored": [""], "Micro.is_on_offset": [""], "offsets.Micro.is_on_offset": [""], "tseries.offsets.Micro.is_on_offset": [""], "pandas.tseries.offsets.Micro.is_on_offset": [""], "Micro.__call__": ["Call self as a function."], "offsets.Micro.__call__": ["Call self as a function."], "tseries.offsets.Micro.__call__": ["Call self as a function."], "pandas.tseries.offsets.Micro.__call__": ["Call self as a function."], "Micro.apply": [""], "offsets.Micro.apply": [""], "tseries.offsets.Micro.apply": [""], "pandas.tseries.offsets.Micro.apply": [""], "Micro.apply_index": [""], "offsets.Micro.apply_index": [""], "tseries.offsets.Micro.apply_index": [""], "pandas.tseries.offsets.Micro.apply_index": [""], "Micro.is_month_start": [""], "offsets.Micro.is_month_start": [""], "tseries.offsets.Micro.is_month_start": [""], "pandas.tseries.offsets.Micro.is_month_start": [""], "Micro.is_month_end": [""], "offsets.Micro.is_month_end": [""], "tseries.offsets.Micro.is_month_end": [""], "pandas.tseries.offsets.Micro.is_month_end": [""], "Micro.is_quarter_start": [""], "offsets.Micro.is_quarter_start": [""], "tseries.offsets.Micro.is_quarter_start": [""], "pandas.tseries.offsets.Micro.is_quarter_start": [""], "Micro.is_quarter_end": [""], "offsets.Micro.is_quarter_end": [""], "tseries.offsets.Micro.is_quarter_end": [""], "pandas.tseries.offsets.Micro.is_quarter_end": [""], "Micro.is_year_start": [""], "offsets.Micro.is_year_start": [""], "tseries.offsets.Micro.is_year_start": [""], "pandas.tseries.offsets.Micro.is_year_start": [""], "Micro.is_year_end": [""], "offsets.Micro.is_year_end": [""], "tseries.offsets.Micro.is_year_end": [""], "pandas.tseries.offsets.Micro.is_year_end": [""], "Nano": [" class=\"rubric\">Attributes</p>\n"], "offsets.Nano": [" class=\"rubric\">Attributes</p>\n"], "tseries.offsets.Nano": [" class=\"rubric\">Attributes</p>\n"], "pandas.tseries.offsets.Nano": [" class=\"rubric\">Attributes</p>\n"], "Nano.delta": [""], "offsets.Nano.delta": [""], "tseries.offsets.Nano.delta": [""], "pandas.tseries.offsets.Nano.delta": [""], "Nano.freqstr": [""], "offsets.Nano.freqstr": [""], "tseries.offsets.Nano.freqstr": [""], "pandas.tseries.offsets.Nano.freqstr": [""], "Nano.kwds": [""], "offsets.Nano.kwds": [""], "tseries.offsets.Nano.kwds": [""], "pandas.tseries.offsets.Nano.kwds": [""], "Nano.name": [""], "offsets.Nano.name": [""], "tseries.offsets.Nano.name": [""], "pandas.tseries.offsets.Nano.name": [""], "Nano.nanos": [""], "offsets.Nano.nanos": [""], "tseries.offsets.Nano.nanos": [""], "pandas.tseries.offsets.Nano.nanos": [""], "Nano.normalize": [""], "offsets.Nano.normalize": [""], "tseries.offsets.Nano.normalize": [""], "pandas.tseries.offsets.Nano.normalize": [""], "Nano.rule_code": [""], "offsets.Nano.rule_code": [""], "tseries.offsets.Nano.rule_code": [""], "pandas.tseries.offsets.Nano.rule_code": [""], "Nano.n": [""], "offsets.Nano.n": [""], "tseries.offsets.Nano.n": [""], "pandas.tseries.offsets.Nano.n": [""], "Nano.copy": [""], "offsets.Nano.copy": [""], "tseries.offsets.Nano.copy": [""], "pandas.tseries.offsets.Nano.copy": [""], "Nano.isAnchored": [""], "offsets.Nano.isAnchored": [""], "tseries.offsets.Nano.isAnchored": [""], "pandas.tseries.offsets.Nano.isAnchored": [""], "Nano.onOffset": [""], "offsets.Nano.onOffset": [""], "tseries.offsets.Nano.onOffset": [""], "pandas.tseries.offsets.Nano.onOffset": [""], "Nano.is_anchored": [""], "offsets.Nano.is_anchored": [""], "tseries.offsets.Nano.is_anchored": [""], "pandas.tseries.offsets.Nano.is_anchored": [""], "Nano.is_on_offset": [""], "offsets.Nano.is_on_offset": [""], "tseries.offsets.Nano.is_on_offset": [""], "pandas.tseries.offsets.Nano.is_on_offset": [""], "Nano.__call__": ["Call self as a function."], "offsets.Nano.__call__": ["Call self as a function."], "tseries.offsets.Nano.__call__": ["Call self as a function."], "pandas.tseries.offsets.Nano.__call__": ["Call self as a function."], "Nano.apply": [""], "offsets.Nano.apply": [""], "tseries.offsets.Nano.apply": [""], "pandas.tseries.offsets.Nano.apply": [""], "Nano.apply_index": [""], "offsets.Nano.apply_index": [""], "tseries.offsets.Nano.apply_index": [""], "pandas.tseries.offsets.Nano.apply_index": [""], "Nano.is_month_start": [""], "offsets.Nano.is_month_start": [""], "tseries.offsets.Nano.is_month_start": [""], "pandas.tseries.offsets.Nano.is_month_start": [""], "Nano.is_month_end": [""], "offsets.Nano.is_month_end": [""], "tseries.offsets.Nano.is_month_end": [""], "pandas.tseries.offsets.Nano.is_month_end": [""], "Nano.is_quarter_start": [""], "offsets.Nano.is_quarter_start": [""], "tseries.offsets.Nano.is_quarter_start": [""], "pandas.tseries.offsets.Nano.is_quarter_start": [""], "Nano.is_quarter_end": [""], "offsets.Nano.is_quarter_end": [""], "tseries.offsets.Nano.is_quarter_end": [""], "pandas.tseries.offsets.Nano.is_quarter_end": [""], "Nano.is_year_start": [""], "offsets.Nano.is_year_start": [""], "tseries.offsets.Nano.is_year_start": [""], "pandas.tseries.offsets.Nano.is_year_start": [""], "Nano.is_year_end": [""], "offsets.Nano.is_year_end": [""], "tseries.offsets.Nano.is_year_end": [""], "pandas.tseries.offsets.Nano.is_year_end": [""], "to_offset": ["Return DateOffset object from string or tuple representation or datetime.timedelta object."], "frequencies.to_offset": ["Return DateOffset object from string or tuple representation or datetime.timedelta object."], "tseries.frequencies.to_offset": ["Return DateOffset object from string or tuple representation or datetime.timedelta object."], "pandas.tseries.frequencies.to_offset": ["Return DateOffset object from string or tuple representation or datetime.timedelta object."], "Rolling.count": ["Calculate the rolling count of non NaN observations."], "rolling.Rolling.count": ["Calculate the rolling count of non NaN observations."], "window.rolling.Rolling.count": ["Calculate the rolling count of non NaN observations."], "core.window.rolling.Rolling.count": ["Calculate the rolling count of non NaN observations."], "pandas.core.window.rolling.Rolling.count": ["Calculate the rolling count of non NaN observations."], "Rolling.sum": ["Calculate the rolling sum."], "rolling.Rolling.sum": ["Calculate the rolling sum."], "window.rolling.Rolling.sum": ["Calculate the rolling sum."], "core.window.rolling.Rolling.sum": ["Calculate the rolling sum."], "pandas.core.window.rolling.Rolling.sum": ["Calculate the rolling sum."], "Rolling.mean": ["Calculate the rolling mean."], "rolling.Rolling.mean": ["Calculate the rolling mean."], "window.rolling.Rolling.mean": ["Calculate the rolling mean."], "core.window.rolling.Rolling.mean": ["Calculate the rolling mean."], "pandas.core.window.rolling.Rolling.mean": ["Calculate the rolling mean."], "Rolling.median": ["Calculate the rolling median."], "rolling.Rolling.median": ["Calculate the rolling median."], "window.rolling.Rolling.median": ["Calculate the rolling median."], "core.window.rolling.Rolling.median": ["Calculate the rolling median."], "pandas.core.window.rolling.Rolling.median": ["Calculate the rolling median."], "Rolling.var": ["Calculate the rolling variance."], "rolling.Rolling.var": ["Calculate the rolling variance."], "window.rolling.Rolling.var": ["Calculate the rolling variance."], "core.window.rolling.Rolling.var": ["Calculate the rolling variance."], "pandas.core.window.rolling.Rolling.var": ["Calculate the rolling variance."], "Rolling.std": ["Calculate the rolling standard deviation."], "rolling.Rolling.std": ["Calculate the rolling standard deviation."], "window.rolling.Rolling.std": ["Calculate the rolling standard deviation."], "core.window.rolling.Rolling.std": ["Calculate the rolling standard deviation."], "pandas.core.window.rolling.Rolling.std": ["Calculate the rolling standard deviation."], "Rolling.min": ["Calculate the rolling minimum."], "rolling.Rolling.min": ["Calculate the rolling minimum."], "window.rolling.Rolling.min": ["Calculate the rolling minimum."], "core.window.rolling.Rolling.min": ["Calculate the rolling minimum."], "pandas.core.window.rolling.Rolling.min": ["Calculate the rolling minimum."], "Rolling.max": ["Calculate the rolling maximum."], "rolling.Rolling.max": ["Calculate the rolling maximum."], "window.rolling.Rolling.max": ["Calculate the rolling maximum."], "core.window.rolling.Rolling.max": ["Calculate the rolling maximum."], "pandas.core.window.rolling.Rolling.max": ["Calculate the rolling maximum."], "Rolling.corr": ["Calculate the rolling correlation."], "rolling.Rolling.corr": ["Calculate the rolling correlation."], "window.rolling.Rolling.corr": ["Calculate the rolling correlation."], "core.window.rolling.Rolling.corr": ["Calculate the rolling correlation."], "pandas.core.window.rolling.Rolling.corr": ["Calculate the rolling correlation."], "Rolling.cov": ["Calculate the rolling sample covariance."], "rolling.Rolling.cov": ["Calculate the rolling sample covariance."], "window.rolling.Rolling.cov": ["Calculate the rolling sample covariance."], "core.window.rolling.Rolling.cov": ["Calculate the rolling sample covariance."], "pandas.core.window.rolling.Rolling.cov": ["Calculate the rolling sample covariance."], "Rolling.skew": ["Calculate the rolling unbiased skewness."], "rolling.Rolling.skew": ["Calculate the rolling unbiased skewness."], "window.rolling.Rolling.skew": ["Calculate the rolling unbiased skewness."], "core.window.rolling.Rolling.skew": ["Calculate the rolling unbiased skewness."], "pandas.core.window.rolling.Rolling.skew": ["Calculate the rolling unbiased skewness."], "Rolling.kurt": ["Calculate the rolling Fisher's definition of kurtosis without bias."], "rolling.Rolling.kurt": ["Calculate the rolling Fisher's definition of kurtosis without bias."], "window.rolling.Rolling.kurt": ["Calculate the rolling Fisher's definition of kurtosis without bias."], "core.window.rolling.Rolling.kurt": ["Calculate the rolling Fisher's definition of kurtosis without bias."], "pandas.core.window.rolling.Rolling.kurt": ["Calculate the rolling Fisher's definition of kurtosis without bias."], "Rolling.apply": ["Calculate the rolling custom aggregation function."], "rolling.Rolling.apply": ["Calculate the rolling custom aggregation function."], "window.rolling.Rolling.apply": ["Calculate the rolling custom aggregation function."], "core.window.rolling.Rolling.apply": ["Calculate the rolling custom aggregation function."], "pandas.core.window.rolling.Rolling.apply": ["Calculate the rolling custom aggregation function."], "Rolling.aggregate": ["Aggregate using one or more operations over the specified axis."], "rolling.Rolling.aggregate": ["Aggregate using one or more operations over the specified axis."], "window.rolling.Rolling.aggregate": ["Aggregate using one or more operations over the specified axis."], "core.window.rolling.Rolling.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.core.window.rolling.Rolling.aggregate": ["Aggregate using one or more operations over the specified axis."], "Rolling.quantile": ["Calculate the rolling quantile."], "rolling.Rolling.quantile": ["Calculate the rolling quantile."], "window.rolling.Rolling.quantile": ["Calculate the rolling quantile."], "core.window.rolling.Rolling.quantile": ["Calculate the rolling quantile."], "pandas.core.window.rolling.Rolling.quantile": ["Calculate the rolling quantile."], "Rolling.sem": ["Calculate the rolling standard error of mean."], "rolling.Rolling.sem": ["Calculate the rolling standard error of mean."], "window.rolling.Rolling.sem": ["Calculate the rolling standard error of mean."], "core.window.rolling.Rolling.sem": ["Calculate the rolling standard error of mean."], "pandas.core.window.rolling.Rolling.sem": ["Calculate the rolling standard error of mean."], "Rolling.rank": ["Calculate the rolling rank."], "rolling.Rolling.rank": ["Calculate the rolling rank."], "window.rolling.Rolling.rank": ["Calculate the rolling rank."], "core.window.rolling.Rolling.rank": ["Calculate the rolling rank."], "pandas.core.window.rolling.Rolling.rank": ["Calculate the rolling rank."], "Window.mean": ["Calculate the rolling weighted window mean."], "rolling.Window.mean": ["Calculate the rolling weighted window mean."], "window.rolling.Window.mean": ["Calculate the rolling weighted window mean."], "core.window.rolling.Window.mean": ["Calculate the rolling weighted window mean."], "pandas.core.window.rolling.Window.mean": ["Calculate the rolling weighted window mean."], "Window.sum": ["Calculate the rolling weighted window sum."], "rolling.Window.sum": ["Calculate the rolling weighted window sum."], "window.rolling.Window.sum": ["Calculate the rolling weighted window sum."], "core.window.rolling.Window.sum": ["Calculate the rolling weighted window sum."], "pandas.core.window.rolling.Window.sum": ["Calculate the rolling weighted window sum."], "Window.var": ["Calculate the rolling weighted window variance."], "rolling.Window.var": ["Calculate the rolling weighted window variance."], "window.rolling.Window.var": ["Calculate the rolling weighted window variance."], "core.window.rolling.Window.var": ["Calculate the rolling weighted window variance."], "pandas.core.window.rolling.Window.var": ["Calculate the rolling weighted window variance."], "Window.std": ["Calculate the rolling weighted window standard deviation."], "rolling.Window.std": ["Calculate the rolling weighted window standard deviation."], "window.rolling.Window.std": ["Calculate the rolling weighted window standard deviation."], "core.window.rolling.Window.std": ["Calculate the rolling weighted window standard deviation."], "pandas.core.window.rolling.Window.std": ["Calculate the rolling weighted window standard deviation."], "Expanding.count": ["Calculate the expanding count of non NaN observations."], "expanding.Expanding.count": ["Calculate the expanding count of non NaN observations."], "window.expanding.Expanding.count": ["Calculate the expanding count of non NaN observations."], "core.window.expanding.Expanding.count": ["Calculate the expanding count of non NaN observations."], "pandas.core.window.expanding.Expanding.count": ["Calculate the expanding count of non NaN observations."], "Expanding.sum": ["Calculate the expanding sum."], "expanding.Expanding.sum": ["Calculate the expanding sum."], "window.expanding.Expanding.sum": ["Calculate the expanding sum."], "core.window.expanding.Expanding.sum": ["Calculate the expanding sum."], "pandas.core.window.expanding.Expanding.sum": ["Calculate the expanding sum."], "Expanding.mean": ["Calculate the expanding mean."], "expanding.Expanding.mean": ["Calculate the expanding mean."], "window.expanding.Expanding.mean": ["Calculate the expanding mean."], "core.window.expanding.Expanding.mean": ["Calculate the expanding mean."], "pandas.core.window.expanding.Expanding.mean": ["Calculate the expanding mean."], "Expanding.median": ["Calculate the expanding median."], "expanding.Expanding.median": ["Calculate the expanding median."], "window.expanding.Expanding.median": ["Calculate the expanding median."], "core.window.expanding.Expanding.median": ["Calculate the expanding median."], "pandas.core.window.expanding.Expanding.median": ["Calculate the expanding median."], "Expanding.var": ["Calculate the expanding variance."], "expanding.Expanding.var": ["Calculate the expanding variance."], "window.expanding.Expanding.var": ["Calculate the expanding variance."], "core.window.expanding.Expanding.var": ["Calculate the expanding variance."], "pandas.core.window.expanding.Expanding.var": ["Calculate the expanding variance."], "Expanding.std": ["Calculate the expanding standard deviation."], "expanding.Expanding.std": ["Calculate the expanding standard deviation."], "window.expanding.Expanding.std": ["Calculate the expanding standard deviation."], "core.window.expanding.Expanding.std": ["Calculate the expanding standard deviation."], "pandas.core.window.expanding.Expanding.std": ["Calculate the expanding standard deviation."], "Expanding.min": ["Calculate the expanding minimum."], "expanding.Expanding.min": ["Calculate the expanding minimum."], "window.expanding.Expanding.min": ["Calculate the expanding minimum."], "core.window.expanding.Expanding.min": ["Calculate the expanding minimum."], "pandas.core.window.expanding.Expanding.min": ["Calculate the expanding minimum."], "Expanding.max": ["Calculate the expanding maximum."], "expanding.Expanding.max": ["Calculate the expanding maximum."], "window.expanding.Expanding.max": ["Calculate the expanding maximum."], "core.window.expanding.Expanding.max": ["Calculate the expanding maximum."], "pandas.core.window.expanding.Expanding.max": ["Calculate the expanding maximum."], "Expanding.corr": ["Calculate the expanding correlation."], "expanding.Expanding.corr": ["Calculate the expanding correlation."], "window.expanding.Expanding.corr": ["Calculate the expanding correlation."], "core.window.expanding.Expanding.corr": ["Calculate the expanding correlation."], "pandas.core.window.expanding.Expanding.corr": ["Calculate the expanding correlation."], "Expanding.cov": ["Calculate the expanding sample covariance."], "expanding.Expanding.cov": ["Calculate the expanding sample covariance."], "window.expanding.Expanding.cov": ["Calculate the expanding sample covariance."], "core.window.expanding.Expanding.cov": ["Calculate the expanding sample covariance."], "pandas.core.window.expanding.Expanding.cov": ["Calculate the expanding sample covariance."], "Expanding.skew": ["Calculate the expanding unbiased skewness."], "expanding.Expanding.skew": ["Calculate the expanding unbiased skewness."], "window.expanding.Expanding.skew": ["Calculate the expanding unbiased skewness."], "core.window.expanding.Expanding.skew": ["Calculate the expanding unbiased skewness."], "pandas.core.window.expanding.Expanding.skew": ["Calculate the expanding unbiased skewness."], "Expanding.kurt": ["Calculate the expanding Fisher's definition of kurtosis without bias."], "expanding.Expanding.kurt": ["Calculate the expanding Fisher's definition of kurtosis without bias."], "window.expanding.Expanding.kurt": ["Calculate the expanding Fisher's definition of kurtosis without bias."], "core.window.expanding.Expanding.kurt": ["Calculate the expanding Fisher's definition of kurtosis without bias."], "pandas.core.window.expanding.Expanding.kurt": ["Calculate the expanding Fisher's definition of kurtosis without bias."], "Expanding.apply": ["Calculate the expanding custom aggregation function."], "expanding.Expanding.apply": ["Calculate the expanding custom aggregation function."], "window.expanding.Expanding.apply": ["Calculate the expanding custom aggregation function."], "core.window.expanding.Expanding.apply": ["Calculate the expanding custom aggregation function."], "pandas.core.window.expanding.Expanding.apply": ["Calculate the expanding custom aggregation function."], "Expanding.aggregate": ["Aggregate using one or more operations over the specified axis."], "expanding.Expanding.aggregate": ["Aggregate using one or more operations over the specified axis."], "window.expanding.Expanding.aggregate": ["Aggregate using one or more operations over the specified axis."], "core.window.expanding.Expanding.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.core.window.expanding.Expanding.aggregate": ["Aggregate using one or more operations over the specified axis."], "Expanding.quantile": ["Calculate the expanding quantile."], "expanding.Expanding.quantile": ["Calculate the expanding quantile."], "window.expanding.Expanding.quantile": ["Calculate the expanding quantile."], "core.window.expanding.Expanding.quantile": ["Calculate the expanding quantile."], "pandas.core.window.expanding.Expanding.quantile": ["Calculate the expanding quantile."], "Expanding.sem": ["Calculate the expanding standard error of mean."], "expanding.Expanding.sem": ["Calculate the expanding standard error of mean."], "window.expanding.Expanding.sem": ["Calculate the expanding standard error of mean."], "core.window.expanding.Expanding.sem": ["Calculate the expanding standard error of mean."], "pandas.core.window.expanding.Expanding.sem": ["Calculate the expanding standard error of mean."], "Expanding.rank": ["Calculate the expanding rank."], "expanding.Expanding.rank": ["Calculate the expanding rank."], "window.expanding.Expanding.rank": ["Calculate the expanding rank."], "core.window.expanding.Expanding.rank": ["Calculate the expanding rank."], "pandas.core.window.expanding.Expanding.rank": ["Calculate the expanding rank."], "ExponentialMovingWindow.mean": ["Calculate the ewm (exponential weighted moment) mean."], "ewm.ExponentialMovingWindow.mean": ["Calculate the ewm (exponential weighted moment) mean."], "window.ewm.ExponentialMovingWindow.mean": ["Calculate the ewm (exponential weighted moment) mean."], "core.window.ewm.ExponentialMovingWindow.mean": ["Calculate the ewm (exponential weighted moment) mean."], "pandas.core.window.ewm.ExponentialMovingWindow.mean": ["Calculate the ewm (exponential weighted moment) mean."], "ExponentialMovingWindow.sum": ["Calculate the ewm (exponential weighted moment) sum."], "ewm.ExponentialMovingWindow.sum": ["Calculate the ewm (exponential weighted moment) sum."], "window.ewm.ExponentialMovingWindow.sum": ["Calculate the ewm (exponential weighted moment) sum."], "core.window.ewm.ExponentialMovingWindow.sum": ["Calculate the ewm (exponential weighted moment) sum."], "pandas.core.window.ewm.ExponentialMovingWindow.sum": ["Calculate the ewm (exponential weighted moment) sum."], "ExponentialMovingWindow.std": ["Calculate the ewm (exponential weighted moment) standard deviation."], "ewm.ExponentialMovingWindow.std": ["Calculate the ewm (exponential weighted moment) standard deviation."], "window.ewm.ExponentialMovingWindow.std": ["Calculate the ewm (exponential weighted moment) standard deviation."], "core.window.ewm.ExponentialMovingWindow.std": ["Calculate the ewm (exponential weighted moment) standard deviation."], "pandas.core.window.ewm.ExponentialMovingWindow.std": ["Calculate the ewm (exponential weighted moment) standard deviation."], "ExponentialMovingWindow.var": ["Calculate the ewm (exponential weighted moment) variance."], "ewm.ExponentialMovingWindow.var": ["Calculate the ewm (exponential weighted moment) variance."], "window.ewm.ExponentialMovingWindow.var": ["Calculate the ewm (exponential weighted moment) variance."], "core.window.ewm.ExponentialMovingWindow.var": ["Calculate the ewm (exponential weighted moment) variance."], "pandas.core.window.ewm.ExponentialMovingWindow.var": ["Calculate the ewm (exponential weighted moment) variance."], "ExponentialMovingWindow.corr": ["Calculate the ewm (exponential weighted moment) sample correlation."], "ewm.ExponentialMovingWindow.corr": ["Calculate the ewm (exponential weighted moment) sample correlation."], "window.ewm.ExponentialMovingWindow.corr": ["Calculate the ewm (exponential weighted moment) sample correlation."], "core.window.ewm.ExponentialMovingWindow.corr": ["Calculate the ewm (exponential weighted moment) sample correlation."], "pandas.core.window.ewm.ExponentialMovingWindow.corr": ["Calculate the ewm (exponential weighted moment) sample correlation."], "ExponentialMovingWindow.cov": ["Calculate the ewm (exponential weighted moment) sample covariance."], "ewm.ExponentialMovingWindow.cov": ["Calculate the ewm (exponential weighted moment) sample covariance."], "window.ewm.ExponentialMovingWindow.cov": ["Calculate the ewm (exponential weighted moment) sample covariance."], "core.window.ewm.ExponentialMovingWindow.cov": ["Calculate the ewm (exponential weighted moment) sample covariance."], "pandas.core.window.ewm.ExponentialMovingWindow.cov": ["Calculate the ewm (exponential weighted moment) sample covariance."], "BaseIndexer": ["Base class for window bounds calculations."], "indexers.BaseIndexer": ["Base class for window bounds calculations."], "api.indexers.BaseIndexer": ["Base class for window bounds calculations."], "pandas.api.indexers.BaseIndexer": ["Base class for window bounds calculations."], "FixedForwardWindowIndexer": ["Creates window boundaries for fixed-length windows that include the current row."], "indexers.FixedForwardWindowIndexer": ["Creates window boundaries for fixed-length windows that include the current row."], "api.indexers.FixedForwardWindowIndexer": ["Creates window boundaries for fixed-length windows that include the current row."], "pandas.api.indexers.FixedForwardWindowIndexer": ["Creates window boundaries for fixed-length windows that include the current row."], "VariableOffsetWindowIndexer": ["Calculate window boundaries based on a non-fixed offset such as a BusinessDay."], "indexers.VariableOffsetWindowIndexer": ["Calculate window boundaries based on a non-fixed offset such as a BusinessDay."], "api.indexers.VariableOffsetWindowIndexer": ["Calculate window boundaries based on a non-fixed offset such as a BusinessDay."], "pandas.api.indexers.VariableOffsetWindowIndexer": ["Calculate window boundaries based on a non-fixed offset such as a BusinessDay."], "GroupBy.__iter__": ["Groupby iterator."], "groupby.GroupBy.__iter__": ["Groupby iterator."], "core.groupby.GroupBy.__iter__": ["Groupby iterator."], "pandas.core.groupby.GroupBy.__iter__": ["Groupby iterator."], "GroupBy.groups": ["Dict {group name -&gt; group labels}."], "groupby.GroupBy.groups": ["Dict {group name -&gt; group labels}."], "core.groupby.GroupBy.groups": ["Dict {group name -&gt; group labels}."], "pandas.core.groupby.GroupBy.groups": ["Dict {group name -&gt; group labels}."], "indices": ["Dict {group name -&gt; group indices}."], "GroupBy.indices": ["Dict {group name -&gt; group indices}."], "groupby.GroupBy.indices": ["Dict {group name -&gt; group indices}."], "core.groupby.GroupBy.indices": ["Dict {group name -&gt; group indices}."], "pandas.core.groupby.GroupBy.indices": ["Dict {group name -&gt; group indices}."], "get_group": ["Construct DataFrame from group with provided name."], "GroupBy.get_group": ["Construct DataFrame from group with provided name."], "groupby.GroupBy.get_group": ["Construct DataFrame from group with provided name."], "core.groupby.GroupBy.get_group": ["Construct DataFrame from group with provided name."], "pandas.core.groupby.GroupBy.get_group": ["Construct DataFrame from group with provided name."], "Grouper": ["A Grouper allows the user to specify a groupby instruction for an object."], "pandas.Grouper": ["A Grouper allows the user to specify a groupby instruction for an object."], "GroupBy.apply": ["Apply function <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> group-wise and combine the results together."], "groupby.GroupBy.apply": ["Apply function <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> group-wise and combine the results together."], "core.groupby.GroupBy.apply": ["Apply function <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> group-wise and combine the results together."], "pandas.core.groupby.GroupBy.apply": ["Apply function <code class=\"docutils literal notranslate\"><span class=\"pre\">func</span></code> group-wise and combine the results together."], "GroupBy.agg": [""], "groupby.GroupBy.agg": [""], "core.groupby.GroupBy.agg": [""], "pandas.core.groupby.GroupBy.agg": [""], "SeriesGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "groupby.SeriesGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "core.groupby.SeriesGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.core.groupby.SeriesGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "DataFrameGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "groupby.DataFrameGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "core.groupby.DataFrameGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.core.groupby.DataFrameGroupBy.aggregate": ["Aggregate using one or more operations over the specified axis."], "SeriesGroupBy.transform": ["Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values."], "groupby.SeriesGroupBy.transform": ["Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values."], "core.groupby.SeriesGroupBy.transform": ["Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values."], "pandas.core.groupby.SeriesGroupBy.transform": ["Call function producing a like-indexed Series on each group and return a Series having the same indexes as the original object filled with the transformed values."], "DataFrameGroupBy.transform": ["Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values."], "groupby.DataFrameGroupBy.transform": ["Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values."], "core.groupby.DataFrameGroupBy.transform": ["Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values."], "pandas.core.groupby.DataFrameGroupBy.transform": ["Call function producing a like-indexed DataFrame on each group and return a DataFrame having the same indexes as the original object filled with the transformed values."], "GroupBy.pipe": ["Apply a function <cite>func</cite> with arguments to this GroupBy object and return the function's result."], "groupby.GroupBy.pipe": ["Apply a function <cite>func</cite> with arguments to this GroupBy object and return the function's result."], "core.groupby.GroupBy.pipe": ["Apply a function <cite>func</cite> with arguments to this GroupBy object and return the function's result."], "pandas.core.groupby.GroupBy.pipe": ["Apply a function <cite>func</cite> with arguments to this GroupBy object and return the function's result."], "GroupBy.all": ["Return True if all values in the group are truthful, else False."], "groupby.GroupBy.all": ["Return True if all values in the group are truthful, else False."], "core.groupby.GroupBy.all": ["Return True if all values in the group are truthful, else False."], "pandas.core.groupby.GroupBy.all": ["Return True if all values in the group are truthful, else False."], "GroupBy.any": ["Return True if any value in the group is truthful, else False."], "groupby.GroupBy.any": ["Return True if any value in the group is truthful, else False."], "core.groupby.GroupBy.any": ["Return True if any value in the group is truthful, else False."], "pandas.core.groupby.GroupBy.any": ["Return True if any value in the group is truthful, else False."], "GroupBy.bfill": ["Backward fill the values."], "groupby.GroupBy.bfill": ["Backward fill the values."], "core.groupby.GroupBy.bfill": ["Backward fill the values."], "pandas.core.groupby.GroupBy.bfill": ["Backward fill the values."], "GroupBy.backfill": ["Backward fill the values."], "groupby.GroupBy.backfill": ["Backward fill the values."], "core.groupby.GroupBy.backfill": ["Backward fill the values."], "pandas.core.groupby.GroupBy.backfill": ["Backward fill the values."], "GroupBy.count": ["Compute count of group, excluding missing values."], "groupby.GroupBy.count": ["Compute count of group, excluding missing values."], "core.groupby.GroupBy.count": ["Compute count of group, excluding missing values."], "pandas.core.groupby.GroupBy.count": ["Compute count of group, excluding missing values."], "cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "GroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "groupby.GroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "core.groupby.GroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "pandas.core.groupby.GroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "GroupBy.cummax": ["Cumulative max for each group."], "groupby.GroupBy.cummax": ["Cumulative max for each group."], "core.groupby.GroupBy.cummax": ["Cumulative max for each group."], "pandas.core.groupby.GroupBy.cummax": ["Cumulative max for each group."], "GroupBy.cummin": ["Cumulative min for each group."], "groupby.GroupBy.cummin": ["Cumulative min for each group."], "core.groupby.GroupBy.cummin": ["Cumulative min for each group."], "pandas.core.groupby.GroupBy.cummin": ["Cumulative min for each group."], "GroupBy.cumprod": ["Cumulative product for each group."], "groupby.GroupBy.cumprod": ["Cumulative product for each group."], "core.groupby.GroupBy.cumprod": ["Cumulative product for each group."], "pandas.core.groupby.GroupBy.cumprod": ["Cumulative product for each group."], "GroupBy.cumsum": ["Cumulative sum for each group."], "groupby.GroupBy.cumsum": ["Cumulative sum for each group."], "core.groupby.GroupBy.cumsum": ["Cumulative sum for each group."], "pandas.core.groupby.GroupBy.cumsum": ["Cumulative sum for each group."], "GroupBy.ffill": ["Forward fill the values."], "groupby.GroupBy.ffill": ["Forward fill the values."], "core.groupby.GroupBy.ffill": ["Forward fill the values."], "pandas.core.groupby.GroupBy.ffill": ["Forward fill the values."], "GroupBy.first": ["Compute first of group values."], "groupby.GroupBy.first": ["Compute first of group values."], "core.groupby.GroupBy.first": ["Compute first of group values."], "pandas.core.groupby.GroupBy.first": ["Compute first of group values."], "GroupBy.head": ["Return first n rows of each group."], "groupby.GroupBy.head": ["Return first n rows of each group."], "core.groupby.GroupBy.head": ["Return first n rows of each group."], "pandas.core.groupby.GroupBy.head": ["Return first n rows of each group."], "GroupBy.last": ["Compute last of group values."], "groupby.GroupBy.last": ["Compute last of group values."], "core.groupby.GroupBy.last": ["Compute last of group values."], "pandas.core.groupby.GroupBy.last": ["Compute last of group values."], "GroupBy.max": ["Compute max of group values."], "groupby.GroupBy.max": ["Compute max of group values."], "core.groupby.GroupBy.max": ["Compute max of group values."], "pandas.core.groupby.GroupBy.max": ["Compute max of group values."], "GroupBy.mean": ["Compute mean of groups, excluding missing values."], "groupby.GroupBy.mean": ["Compute mean of groups, excluding missing values."], "core.groupby.GroupBy.mean": ["Compute mean of groups, excluding missing values."], "pandas.core.groupby.GroupBy.mean": ["Compute mean of groups, excluding missing values."], "GroupBy.median": ["Compute median of groups, excluding missing values."], "groupby.GroupBy.median": ["Compute median of groups, excluding missing values."], "core.groupby.GroupBy.median": ["Compute median of groups, excluding missing values."], "pandas.core.groupby.GroupBy.median": ["Compute median of groups, excluding missing values."], "GroupBy.min": ["Compute min of group values."], "groupby.GroupBy.min": ["Compute min of group values."], "core.groupby.GroupBy.min": ["Compute min of group values."], "pandas.core.groupby.GroupBy.min": ["Compute min of group values."], "ngroup": ["Number each group from 0 to the number of groups - 1."], "GroupBy.ngroup": ["Number each group from 0 to the number of groups - 1."], "groupby.GroupBy.ngroup": ["Number each group from 0 to the number of groups - 1."], "core.groupby.GroupBy.ngroup": ["Number each group from 0 to the number of groups - 1."], "pandas.core.groupby.GroupBy.ngroup": ["Number each group from 0 to the number of groups - 1."], "nth": ["Take the nth row from each group if n is an int, otherwise a subset of rows."], "GroupBy.nth": ["Take the nth row from each group if n is an int, otherwise a subset of rows."], "groupby.GroupBy.nth": ["Take the nth row from each group if n is an int, otherwise a subset of rows."], "core.groupby.GroupBy.nth": ["Take the nth row from each group if n is an int, otherwise a subset of rows."], "pandas.core.groupby.GroupBy.nth": ["Take the nth row from each group if n is an int, otherwise a subset of rows."], "ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "GroupBy.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "groupby.GroupBy.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "core.groupby.GroupBy.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "pandas.core.groupby.GroupBy.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "GroupBy.pad": ["Forward fill the values."], "groupby.GroupBy.pad": ["Forward fill the values."], "core.groupby.GroupBy.pad": ["Forward fill the values."], "pandas.core.groupby.GroupBy.pad": ["Forward fill the values."], "GroupBy.prod": ["Compute prod of group values."], "groupby.GroupBy.prod": ["Compute prod of group values."], "core.groupby.GroupBy.prod": ["Compute prod of group values."], "pandas.core.groupby.GroupBy.prod": ["Compute prod of group values."], "GroupBy.rank": ["Provide the rank of values within each group."], "groupby.GroupBy.rank": ["Provide the rank of values within each group."], "core.groupby.GroupBy.rank": ["Provide the rank of values within each group."], "pandas.core.groupby.GroupBy.rank": ["Provide the rank of values within each group."], "GroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "groupby.GroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "core.groupby.GroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "pandas.core.groupby.GroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "GroupBy.size": ["Compute group sizes."], "groupby.GroupBy.size": ["Compute group sizes."], "core.groupby.GroupBy.size": ["Compute group sizes."], "pandas.core.groupby.GroupBy.size": ["Compute group sizes."], "GroupBy.sem": ["Compute standard error of the mean of groups, excluding missing values."], "groupby.GroupBy.sem": ["Compute standard error of the mean of groups, excluding missing values."], "core.groupby.GroupBy.sem": ["Compute standard error of the mean of groups, excluding missing values."], "pandas.core.groupby.GroupBy.sem": ["Compute standard error of the mean of groups, excluding missing values."], "GroupBy.std": ["Compute standard deviation of groups, excluding missing values."], "groupby.GroupBy.std": ["Compute standard deviation of groups, excluding missing values."], "core.groupby.GroupBy.std": ["Compute standard deviation of groups, excluding missing values."], "pandas.core.groupby.GroupBy.std": ["Compute standard deviation of groups, excluding missing values."], "GroupBy.sum": ["Compute sum of group values."], "groupby.GroupBy.sum": ["Compute sum of group values."], "core.groupby.GroupBy.sum": ["Compute sum of group values."], "pandas.core.groupby.GroupBy.sum": ["Compute sum of group values."], "GroupBy.var": ["Compute variance of groups, excluding missing values."], "groupby.GroupBy.var": ["Compute variance of groups, excluding missing values."], "core.groupby.GroupBy.var": ["Compute variance of groups, excluding missing values."], "pandas.core.groupby.GroupBy.var": ["Compute variance of groups, excluding missing values."], "GroupBy.tail": ["Return last n rows of each group."], "groupby.GroupBy.tail": ["Return last n rows of each group."], "core.groupby.GroupBy.tail": ["Return last n rows of each group."], "pandas.core.groupby.GroupBy.tail": ["Return last n rows of each group."], "DataFrameGroupBy.all": ["Return True if all values in the group are truthful, else False."], "groupby.DataFrameGroupBy.all": ["Return True if all values in the group are truthful, else False."], "core.groupby.DataFrameGroupBy.all": ["Return True if all values in the group are truthful, else False."], "pandas.core.groupby.DataFrameGroupBy.all": ["Return True if all values in the group are truthful, else False."], "DataFrameGroupBy.any": ["Return True if any value in the group is truthful, else False."], "groupby.DataFrameGroupBy.any": ["Return True if any value in the group is truthful, else False."], "core.groupby.DataFrameGroupBy.any": ["Return True if any value in the group is truthful, else False."], "pandas.core.groupby.DataFrameGroupBy.any": ["Return True if any value in the group is truthful, else False."], "DataFrameGroupBy.backfill": ["Backward fill the values."], "groupby.DataFrameGroupBy.backfill": ["Backward fill the values."], "core.groupby.DataFrameGroupBy.backfill": ["Backward fill the values."], "pandas.core.groupby.DataFrameGroupBy.backfill": ["Backward fill the values."], "DataFrameGroupBy.bfill": ["Backward fill the values."], "groupby.DataFrameGroupBy.bfill": ["Backward fill the values."], "core.groupby.DataFrameGroupBy.bfill": ["Backward fill the values."], "pandas.core.groupby.DataFrameGroupBy.bfill": ["Backward fill the values."], "DataFrameGroupBy.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "groupby.DataFrameGroupBy.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "core.groupby.DataFrameGroupBy.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "pandas.core.groupby.DataFrameGroupBy.corr": ["Compute pairwise correlation of columns, excluding NA/null values."], "DataFrameGroupBy.count": ["Compute count of group, excluding missing values."], "groupby.DataFrameGroupBy.count": ["Compute count of group, excluding missing values."], "core.groupby.DataFrameGroupBy.count": ["Compute count of group, excluding missing values."], "pandas.core.groupby.DataFrameGroupBy.count": ["Compute count of group, excluding missing values."], "DataFrameGroupBy.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "groupby.DataFrameGroupBy.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "core.groupby.DataFrameGroupBy.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "pandas.core.groupby.DataFrameGroupBy.cov": ["Compute pairwise covariance of columns, excluding NA/null values."], "DataFrameGroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "groupby.DataFrameGroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "core.groupby.DataFrameGroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "pandas.core.groupby.DataFrameGroupBy.cumcount": ["Number each item in each group from 0 to the length of that group - 1."], "DataFrameGroupBy.cummax": ["Cumulative max for each group."], "groupby.DataFrameGroupBy.cummax": ["Cumulative max for each group."], "core.groupby.DataFrameGroupBy.cummax": ["Cumulative max for each group."], "pandas.core.groupby.DataFrameGroupBy.cummax": ["Cumulative max for each group."], "DataFrameGroupBy.cummin": ["Cumulative min for each group."], "groupby.DataFrameGroupBy.cummin": ["Cumulative min for each group."], "core.groupby.DataFrameGroupBy.cummin": ["Cumulative min for each group."], "pandas.core.groupby.DataFrameGroupBy.cummin": ["Cumulative min for each group."], "DataFrameGroupBy.cumprod": ["Cumulative product for each group."], "groupby.DataFrameGroupBy.cumprod": ["Cumulative product for each group."], "core.groupby.DataFrameGroupBy.cumprod": ["Cumulative product for each group."], "pandas.core.groupby.DataFrameGroupBy.cumprod": ["Cumulative product for each group."], "DataFrameGroupBy.cumsum": ["Cumulative sum for each group."], "groupby.DataFrameGroupBy.cumsum": ["Cumulative sum for each group."], "core.groupby.DataFrameGroupBy.cumsum": ["Cumulative sum for each group."], "pandas.core.groupby.DataFrameGroupBy.cumsum": ["Cumulative sum for each group."], "DataFrameGroupBy.describe": ["Generate descriptive statistics."], "groupby.DataFrameGroupBy.describe": ["Generate descriptive statistics."], "core.groupby.DataFrameGroupBy.describe": ["Generate descriptive statistics."], "pandas.core.groupby.DataFrameGroupBy.describe": ["Generate descriptive statistics."], "DataFrameGroupBy.diff": ["First discrete difference of element."], "groupby.DataFrameGroupBy.diff": ["First discrete difference of element."], "core.groupby.DataFrameGroupBy.diff": ["First discrete difference of element."], "pandas.core.groupby.DataFrameGroupBy.diff": ["First discrete difference of element."], "DataFrameGroupBy.ffill": ["Forward fill the values."], "groupby.DataFrameGroupBy.ffill": ["Forward fill the values."], "core.groupby.DataFrameGroupBy.ffill": ["Forward fill the values."], "pandas.core.groupby.DataFrameGroupBy.ffill": ["Forward fill the values."], "DataFrameGroupBy.fillna": ["Fill NA/NaN values using the specified method."], "groupby.DataFrameGroupBy.fillna": ["Fill NA/NaN values using the specified method."], "core.groupby.DataFrameGroupBy.fillna": ["Fill NA/NaN values using the specified method."], "pandas.core.groupby.DataFrameGroupBy.fillna": ["Fill NA/NaN values using the specified method."], "DataFrameGroupBy.filter": ["Return a copy of a DataFrame excluding filtered elements."], "groupby.DataFrameGroupBy.filter": ["Return a copy of a DataFrame excluding filtered elements."], "core.groupby.DataFrameGroupBy.filter": ["Return a copy of a DataFrame excluding filtered elements."], "pandas.core.groupby.DataFrameGroupBy.filter": ["Return a copy of a DataFrame excluding filtered elements."], "DataFrameGroupBy.hist": ["Make a histogram of the DataFrame's columns."], "groupby.DataFrameGroupBy.hist": ["Make a histogram of the DataFrame's columns."], "core.groupby.DataFrameGroupBy.hist": ["Make a histogram of the DataFrame's columns."], "pandas.core.groupby.DataFrameGroupBy.hist": ["Make a histogram of the DataFrame's columns."], "DataFrameGroupBy.idxmax": ["Return index of first occurrence of maximum over requested axis."], "groupby.DataFrameGroupBy.idxmax": ["Return index of first occurrence of maximum over requested axis."], "core.groupby.DataFrameGroupBy.idxmax": ["Return index of first occurrence of maximum over requested axis."], "pandas.core.groupby.DataFrameGroupBy.idxmax": ["Return index of first occurrence of maximum over requested axis."], "DataFrameGroupBy.idxmin": ["Return index of first occurrence of minimum over requested axis."], "groupby.DataFrameGroupBy.idxmin": ["Return index of first occurrence of minimum over requested axis."], "core.groupby.DataFrameGroupBy.idxmin": ["Return index of first occurrence of minimum over requested axis."], "pandas.core.groupby.DataFrameGroupBy.idxmin": ["Return index of first occurrence of minimum over requested axis."], "DataFrameGroupBy.mad": ["Return the mean absolute deviation of the values over the requested axis."], "groupby.DataFrameGroupBy.mad": ["Return the mean absolute deviation of the values over the requested axis."], "core.groupby.DataFrameGroupBy.mad": ["Return the mean absolute deviation of the values over the requested axis."], "pandas.core.groupby.DataFrameGroupBy.mad": ["Return the mean absolute deviation of the values over the requested axis."], "DataFrameGroupBy.nunique": ["Return DataFrame with counts of unique elements in each position."], "groupby.DataFrameGroupBy.nunique": ["Return DataFrame with counts of unique elements in each position."], "core.groupby.DataFrameGroupBy.nunique": ["Return DataFrame with counts of unique elements in each position."], "pandas.core.groupby.DataFrameGroupBy.nunique": ["Return DataFrame with counts of unique elements in each position."], "DataFrameGroupBy.pad": ["Forward fill the values."], "groupby.DataFrameGroupBy.pad": ["Forward fill the values."], "core.groupby.DataFrameGroupBy.pad": ["Forward fill the values."], "pandas.core.groupby.DataFrameGroupBy.pad": ["Forward fill the values."], "DataFrameGroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "groupby.DataFrameGroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "core.groupby.DataFrameGroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "pandas.core.groupby.DataFrameGroupBy.pct_change": ["Calculate pct_change of each value to previous entry in group."], "DataFrameGroupBy.plot": ["Class implementing the .plot attribute for groupby objects."], "groupby.DataFrameGroupBy.plot": ["Class implementing the .plot attribute for groupby objects."], "core.groupby.DataFrameGroupBy.plot": ["Class implementing the .plot attribute for groupby objects."], "pandas.core.groupby.DataFrameGroupBy.plot": ["Class implementing the .plot attribute for groupby objects."], "DataFrameGroupBy.quantile": ["Return group values at the given quantile, a la numpy.percentile."], "groupby.DataFrameGroupBy.quantile": ["Return group values at the given quantile, a la numpy.percentile."], "core.groupby.DataFrameGroupBy.quantile": ["Return group values at the given quantile, a la numpy.percentile."], "pandas.core.groupby.DataFrameGroupBy.quantile": ["Return group values at the given quantile, a la numpy.percentile."], "DataFrameGroupBy.rank": ["Provide the rank of values within each group."], "groupby.DataFrameGroupBy.rank": ["Provide the rank of values within each group."], "core.groupby.DataFrameGroupBy.rank": ["Provide the rank of values within each group."], "pandas.core.groupby.DataFrameGroupBy.rank": ["Provide the rank of values within each group."], "DataFrameGroupBy.resample": ["Provide resampling when using a TimeGrouper."], "groupby.DataFrameGroupBy.resample": ["Provide resampling when using a TimeGrouper."], "core.groupby.DataFrameGroupBy.resample": ["Provide resampling when using a TimeGrouper."], "pandas.core.groupby.DataFrameGroupBy.resample": ["Provide resampling when using a TimeGrouper."], "DataFrameGroupBy.sample": ["Return a random sample of items from each group."], "groupby.DataFrameGroupBy.sample": ["Return a random sample of items from each group."], "core.groupby.DataFrameGroupBy.sample": ["Return a random sample of items from each group."], "pandas.core.groupby.DataFrameGroupBy.sample": ["Return a random sample of items from each group."], "DataFrameGroupBy.shift": ["Shift each group by periods observations."], "groupby.DataFrameGroupBy.shift": ["Shift each group by periods observations."], "core.groupby.DataFrameGroupBy.shift": ["Shift each group by periods observations."], "pandas.core.groupby.DataFrameGroupBy.shift": ["Shift each group by periods observations."], "DataFrameGroupBy.size": ["Compute group sizes."], "groupby.DataFrameGroupBy.size": ["Compute group sizes."], "core.groupby.DataFrameGroupBy.size": ["Compute group sizes."], "pandas.core.groupby.DataFrameGroupBy.size": ["Compute group sizes."], "DataFrameGroupBy.skew": ["Return unbiased skew over requested axis."], "groupby.DataFrameGroupBy.skew": ["Return unbiased skew over requested axis."], "core.groupby.DataFrameGroupBy.skew": ["Return unbiased skew over requested axis."], "pandas.core.groupby.DataFrameGroupBy.skew": ["Return unbiased skew over requested axis."], "DataFrameGroupBy.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "groupby.DataFrameGroupBy.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "core.groupby.DataFrameGroupBy.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "pandas.core.groupby.DataFrameGroupBy.take": ["Return the elements in the given <em>positional</em> indices along an axis."], "DataFrameGroupBy.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "groupby.DataFrameGroupBy.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "core.groupby.DataFrameGroupBy.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "pandas.core.groupby.DataFrameGroupBy.tshift": ["(DEPRECATED) Shift the time index, using the index's frequency if available."], "DataFrameGroupBy.value_counts": ["Return a Series or DataFrame containing counts of unique rows."], "groupby.DataFrameGroupBy.value_counts": ["Return a Series or DataFrame containing counts of unique rows."], "core.groupby.DataFrameGroupBy.value_counts": ["Return a Series or DataFrame containing counts of unique rows."], "pandas.core.groupby.DataFrameGroupBy.value_counts": ["Return a Series or DataFrame containing counts of unique rows."], "SeriesGroupBy.hist": ["Draw histogram of the input series using matplotlib."], "groupby.SeriesGroupBy.hist": ["Draw histogram of the input series using matplotlib."], "core.groupby.SeriesGroupBy.hist": ["Draw histogram of the input series using matplotlib."], "pandas.core.groupby.SeriesGroupBy.hist": ["Draw histogram of the input series using matplotlib."], "SeriesGroupBy.nlargest": ["Return the largest <cite>n</cite> elements."], "groupby.SeriesGroupBy.nlargest": ["Return the largest <cite>n</cite> elements."], "core.groupby.SeriesGroupBy.nlargest": ["Return the largest <cite>n</cite> elements."], "pandas.core.groupby.SeriesGroupBy.nlargest": ["Return the largest <cite>n</cite> elements."], "SeriesGroupBy.nsmallest": ["Return the smallest <cite>n</cite> elements."], "groupby.SeriesGroupBy.nsmallest": ["Return the smallest <cite>n</cite> elements."], "core.groupby.SeriesGroupBy.nsmallest": ["Return the smallest <cite>n</cite> elements."], "pandas.core.groupby.SeriesGroupBy.nsmallest": ["Return the smallest <cite>n</cite> elements."], "SeriesGroupBy.nunique": ["Return number of unique elements in the group."], "groupby.SeriesGroupBy.nunique": ["Return number of unique elements in the group."], "core.groupby.SeriesGroupBy.nunique": ["Return number of unique elements in the group."], "pandas.core.groupby.SeriesGroupBy.nunique": ["Return number of unique elements in the group."], "SeriesGroupBy.unique": ["Return unique values of Series object."], "groupby.SeriesGroupBy.unique": ["Return unique values of Series object."], "core.groupby.SeriesGroupBy.unique": ["Return unique values of Series object."], "pandas.core.groupby.SeriesGroupBy.unique": ["Return unique values of Series object."], "SeriesGroupBy.value_counts": [""], "groupby.SeriesGroupBy.value_counts": [""], "core.groupby.SeriesGroupBy.value_counts": [""], "pandas.core.groupby.SeriesGroupBy.value_counts": [""], "SeriesGroupBy.is_monotonic_increasing": ["Alias for is_monotonic."], "groupby.SeriesGroupBy.is_monotonic_increasing": ["Alias for is_monotonic."], "core.groupby.SeriesGroupBy.is_monotonic_increasing": ["Alias for is_monotonic."], "pandas.core.groupby.SeriesGroupBy.is_monotonic_increasing": ["Alias for is_monotonic."], "SeriesGroupBy.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "groupby.SeriesGroupBy.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "core.groupby.SeriesGroupBy.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "pandas.core.groupby.SeriesGroupBy.is_monotonic_decreasing": ["Return boolean if values in the object are monotonic_decreasing."], "DataFrameGroupBy.corrwith": ["Compute pairwise correlation."], "groupby.DataFrameGroupBy.corrwith": ["Compute pairwise correlation."], "core.groupby.DataFrameGroupBy.corrwith": ["Compute pairwise correlation."], "pandas.core.groupby.DataFrameGroupBy.corrwith": ["Compute pairwise correlation."], "DataFrameGroupBy.boxplot": ["Make box plots from DataFrameGroupBy data."], "groupby.DataFrameGroupBy.boxplot": ["Make box plots from DataFrameGroupBy data."], "core.groupby.DataFrameGroupBy.boxplot": ["Make box plots from DataFrameGroupBy data."], "pandas.core.groupby.DataFrameGroupBy.boxplot": ["Make box plots from DataFrameGroupBy data."], "Resampler.__iter__": ["Groupby iterator."], "resample.Resampler.__iter__": ["Groupby iterator."], "core.resample.Resampler.__iter__": ["Groupby iterator."], "pandas.core.resample.Resampler.__iter__": ["Groupby iterator."], "Resampler.groups": ["Dict {group name -&gt; group labels}."], "resample.Resampler.groups": ["Dict {group name -&gt; group labels}."], "core.resample.Resampler.groups": ["Dict {group name -&gt; group labels}."], "pandas.core.resample.Resampler.groups": ["Dict {group name -&gt; group labels}."], "Resampler.indices": ["Dict {group name -&gt; group indices}."], "resample.Resampler.indices": ["Dict {group name -&gt; group indices}."], "core.resample.Resampler.indices": ["Dict {group name -&gt; group indices}."], "pandas.core.resample.Resampler.indices": ["Dict {group name -&gt; group indices}."], "Resampler.get_group": ["Construct DataFrame from group with provided name."], "resample.Resampler.get_group": ["Construct DataFrame from group with provided name."], "core.resample.Resampler.get_group": ["Construct DataFrame from group with provided name."], "pandas.core.resample.Resampler.get_group": ["Construct DataFrame from group with provided name."], "Resampler.apply": ["Aggregate using one or more operations over the specified axis."], "resample.Resampler.apply": ["Aggregate using one or more operations over the specified axis."], "core.resample.Resampler.apply": ["Aggregate using one or more operations over the specified axis."], "pandas.core.resample.Resampler.apply": ["Aggregate using one or more operations over the specified axis."], "Resampler.aggregate": ["Aggregate using one or more operations over the specified axis."], "resample.Resampler.aggregate": ["Aggregate using one or more operations over the specified axis."], "core.resample.Resampler.aggregate": ["Aggregate using one or more operations over the specified axis."], "pandas.core.resample.Resampler.aggregate": ["Aggregate using one or more operations over the specified axis."], "Resampler.transform": ["Call function producing a like-indexed Series on each group and return a Series with the transformed values."], "resample.Resampler.transform": ["Call function producing a like-indexed Series on each group and return a Series with the transformed values."], "core.resample.Resampler.transform": ["Call function producing a like-indexed Series on each group and return a Series with the transformed values."], "pandas.core.resample.Resampler.transform": ["Call function producing a like-indexed Series on each group and return a Series with the transformed values."], "Resampler.pipe": ["Apply a function <cite>func</cite> with arguments to this Resampler object and return the function's result."], "resample.Resampler.pipe": ["Apply a function <cite>func</cite> with arguments to this Resampler object and return the function's result."], "core.resample.Resampler.pipe": ["Apply a function <cite>func</cite> with arguments to this Resampler object and return the function's result."], "pandas.core.resample.Resampler.pipe": ["Apply a function <cite>func</cite> with arguments to this Resampler object and return the function's result."], "Resampler.ffill": ["Forward fill the values."], "resample.Resampler.ffill": ["Forward fill the values."], "core.resample.Resampler.ffill": ["Forward fill the values."], "pandas.core.resample.Resampler.ffill": ["Forward fill the values."], "Resampler.backfill": ["Backward fill the new missing values in the resampled data."], "resample.Resampler.backfill": ["Backward fill the new missing values in the resampled data."], "core.resample.Resampler.backfill": ["Backward fill the new missing values in the resampled data."], "pandas.core.resample.Resampler.backfill": ["Backward fill the new missing values in the resampled data."], "Resampler.bfill": ["Backward fill the new missing values in the resampled data."], "resample.Resampler.bfill": ["Backward fill the new missing values in the resampled data."], "core.resample.Resampler.bfill": ["Backward fill the new missing values in the resampled data."], "pandas.core.resample.Resampler.bfill": ["Backward fill the new missing values in the resampled data."], "Resampler.pad": ["Forward fill the values."], "resample.Resampler.pad": ["Forward fill the values."], "core.resample.Resampler.pad": ["Forward fill the values."], "pandas.core.resample.Resampler.pad": ["Forward fill the values."], "nearest": ["Resample by using the nearest value."], "Resampler.nearest": ["Resample by using the nearest value."], "resample.Resampler.nearest": ["Resample by using the nearest value."], "core.resample.Resampler.nearest": ["Resample by using the nearest value."], "pandas.core.resample.Resampler.nearest": ["Resample by using the nearest value."], "Resampler.fillna": ["Fill missing values introduced by upsampling."], "resample.Resampler.fillna": ["Fill missing values introduced by upsampling."], "core.resample.Resampler.fillna": ["Fill missing values introduced by upsampling."], "pandas.core.resample.Resampler.fillna": ["Fill missing values introduced by upsampling."], "Resampler.asfreq": ["Return the values at the new freq, essentially a reindex."], "resample.Resampler.asfreq": ["Return the values at the new freq, essentially a reindex."], "core.resample.Resampler.asfreq": ["Return the values at the new freq, essentially a reindex."], "pandas.core.resample.Resampler.asfreq": ["Return the values at the new freq, essentially a reindex."], "Resampler.interpolate": ["Interpolate values according to different methods."], "resample.Resampler.interpolate": ["Interpolate values according to different methods."], "core.resample.Resampler.interpolate": ["Interpolate values according to different methods."], "pandas.core.resample.Resampler.interpolate": ["Interpolate values according to different methods."], "Resampler.count": ["Compute count of group, excluding missing values."], "resample.Resampler.count": ["Compute count of group, excluding missing values."], "core.resample.Resampler.count": ["Compute count of group, excluding missing values."], "pandas.core.resample.Resampler.count": ["Compute count of group, excluding missing values."], "Resampler.nunique": ["Return number of unique elements in the group."], "resample.Resampler.nunique": ["Return number of unique elements in the group."], "core.resample.Resampler.nunique": ["Return number of unique elements in the group."], "pandas.core.resample.Resampler.nunique": ["Return number of unique elements in the group."], "Resampler.first": ["Compute first of group values."], "resample.Resampler.first": ["Compute first of group values."], "core.resample.Resampler.first": ["Compute first of group values."], "pandas.core.resample.Resampler.first": ["Compute first of group values."], "Resampler.last": ["Compute last of group values."], "resample.Resampler.last": ["Compute last of group values."], "core.resample.Resampler.last": ["Compute last of group values."], "pandas.core.resample.Resampler.last": ["Compute last of group values."], "Resampler.max": ["Compute max of group values."], "resample.Resampler.max": ["Compute max of group values."], "core.resample.Resampler.max": ["Compute max of group values."], "pandas.core.resample.Resampler.max": ["Compute max of group values."], "Resampler.mean": ["Compute mean of groups, excluding missing values."], "resample.Resampler.mean": ["Compute mean of groups, excluding missing values."], "core.resample.Resampler.mean": ["Compute mean of groups, excluding missing values."], "pandas.core.resample.Resampler.mean": ["Compute mean of groups, excluding missing values."], "Resampler.median": ["Compute median of groups, excluding missing values."], "resample.Resampler.median": ["Compute median of groups, excluding missing values."], "core.resample.Resampler.median": ["Compute median of groups, excluding missing values."], "pandas.core.resample.Resampler.median": ["Compute median of groups, excluding missing values."], "Resampler.min": ["Compute min of group values."], "resample.Resampler.min": ["Compute min of group values."], "core.resample.Resampler.min": ["Compute min of group values."], "pandas.core.resample.Resampler.min": ["Compute min of group values."], "Resampler.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "resample.Resampler.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "core.resample.Resampler.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "pandas.core.resample.Resampler.ohlc": ["Compute open, high, low and close values of a group, excluding missing values."], "Resampler.prod": ["Compute prod of group values."], "resample.Resampler.prod": ["Compute prod of group values."], "core.resample.Resampler.prod": ["Compute prod of group values."], "pandas.core.resample.Resampler.prod": ["Compute prod of group values."], "Resampler.size": ["Compute group sizes."], "resample.Resampler.size": ["Compute group sizes."], "core.resample.Resampler.size": ["Compute group sizes."], "pandas.core.resample.Resampler.size": ["Compute group sizes."], "Resampler.sem": ["Compute standard error of the mean of groups, excluding missing values."], "resample.Resampler.sem": ["Compute standard error of the mean of groups, excluding missing values."], "core.resample.Resampler.sem": ["Compute standard error of the mean of groups, excluding missing values."], "pandas.core.resample.Resampler.sem": ["Compute standard error of the mean of groups, excluding missing values."], "Resampler.std": ["Compute standard deviation of groups, excluding missing values."], "resample.Resampler.std": ["Compute standard deviation of groups, excluding missing values."], "core.resample.Resampler.std": ["Compute standard deviation of groups, excluding missing values."], "pandas.core.resample.Resampler.std": ["Compute standard deviation of groups, excluding missing values."], "Resampler.sum": ["Compute sum of group values."], "resample.Resampler.sum": ["Compute sum of group values."], "core.resample.Resampler.sum": ["Compute sum of group values."], "pandas.core.resample.Resampler.sum": ["Compute sum of group values."], "Resampler.var": ["Compute variance of groups, excluding missing values."], "resample.Resampler.var": ["Compute variance of groups, excluding missing values."], "core.resample.Resampler.var": ["Compute variance of groups, excluding missing values."], "pandas.core.resample.Resampler.var": ["Compute variance of groups, excluding missing values."], "Resampler.quantile": ["Return value at the given quantile."], "resample.Resampler.quantile": ["Return value at the given quantile."], "core.resample.Resampler.quantile": ["Return value at the given quantile."], "pandas.core.resample.Resampler.quantile": ["Return value at the given quantile."], "Styler": ["Helps style a DataFrame or Series according to the data with HTML and CSS."], "style.Styler": ["Helps style a DataFrame or Series according to the data with HTML and CSS."], "formats.style.Styler": ["Helps style a DataFrame or Series according to the data with HTML and CSS."], "io.formats.style.Styler": ["Helps style a DataFrame or Series according to the data with HTML and CSS."], "pandas.io.formats.style.Styler": ["Helps style a DataFrame or Series according to the data with HTML and CSS."], "from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "Styler.from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "style.Styler.from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "formats.style.Styler.from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "io.formats.style.Styler.from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "pandas.io.formats.style.Styler.from_custom_template": ["Factory function for creating a subclass of <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>."], "env": [""], "Styler.env": [""], "style.Styler.env": [""], "formats.style.Styler.env": [""], "io.formats.style.Styler.env": [""], "pandas.io.formats.style.Styler.env": [""], "template_html": [""], "Styler.template_html": [""], "style.Styler.template_html": [""], "formats.style.Styler.template_html": [""], "io.formats.style.Styler.template_html": [""], "pandas.io.formats.style.Styler.template_html": [""], "template_html_style": [""], "Styler.template_html_style": [""], "style.Styler.template_html_style": [""], "formats.style.Styler.template_html_style": [""], "io.formats.style.Styler.template_html_style": [""], "pandas.io.formats.style.Styler.template_html_style": [""], "template_html_table": [""], "Styler.template_html_table": [""], "style.Styler.template_html_table": [""], "formats.style.Styler.template_html_table": [""], "io.formats.style.Styler.template_html_table": [""], "pandas.io.formats.style.Styler.template_html_table": [""], "template_latex": [""], "Styler.template_latex": [""], "style.Styler.template_latex": [""], "formats.style.Styler.template_latex": [""], "io.formats.style.Styler.template_latex": [""], "pandas.io.formats.style.Styler.template_latex": [""], "loader": [""], "Styler.loader": [""], "style.Styler.loader": [""], "formats.style.Styler.loader": [""], "io.formats.style.Styler.loader": [""], "pandas.io.formats.style.Styler.loader": [""], "Styler.apply": ["Apply a CSS-styling function column-wise, row-wise, or table-wise."], "style.Styler.apply": ["Apply a CSS-styling function column-wise, row-wise, or table-wise."], "formats.style.Styler.apply": ["Apply a CSS-styling function column-wise, row-wise, or table-wise."], "io.formats.style.Styler.apply": ["Apply a CSS-styling function column-wise, row-wise, or table-wise."], "pandas.io.formats.style.Styler.apply": ["Apply a CSS-styling function column-wise, row-wise, or table-wise."], "Styler.applymap": ["Apply a CSS-styling function elementwise."], "style.Styler.applymap": ["Apply a CSS-styling function elementwise."], "formats.style.Styler.applymap": ["Apply a CSS-styling function elementwise."], "io.formats.style.Styler.applymap": ["Apply a CSS-styling function elementwise."], "pandas.io.formats.style.Styler.applymap": ["Apply a CSS-styling function elementwise."], "Styler.apply_index": ["Apply a CSS-styling function to the index or column headers, level-wise."], "style.Styler.apply_index": ["Apply a CSS-styling function to the index or column headers, level-wise."], "formats.style.Styler.apply_index": ["Apply a CSS-styling function to the index or column headers, level-wise."], "io.formats.style.Styler.apply_index": ["Apply a CSS-styling function to the index or column headers, level-wise."], "pandas.io.formats.style.Styler.apply_index": ["Apply a CSS-styling function to the index or column headers, level-wise."], "applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "Styler.applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "style.Styler.applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "formats.style.Styler.applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "io.formats.style.Styler.applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "pandas.io.formats.style.Styler.applymap_index": ["Apply a CSS-styling function to the index or column headers, elementwise."], "format": ["Format the text display value of cells.", "Binary serialization"], "Styler.format": ["Format the text display value of cells."], "style.Styler.format": ["Format the text display value of cells."], "formats.style.Styler.format": ["Format the text display value of cells."], "io.formats.style.Styler.format": ["Format the text display value of cells."], "pandas.io.formats.style.Styler.format": ["Format the text display value of cells."], "format_index": ["Format the text display value of index labels or column headers."], "Styler.format_index": ["Format the text display value of index labels or column headers."], "style.Styler.format_index": ["Format the text display value of index labels or column headers."], "formats.style.Styler.format_index": ["Format the text display value of index labels or column headers."], "io.formats.style.Styler.format_index": ["Format the text display value of index labels or column headers."], "pandas.io.formats.style.Styler.format_index": ["Format the text display value of index labels or column headers."], "hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "Styler.hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "style.Styler.hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "formats.style.Styler.hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "io.formats.style.Styler.hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "pandas.io.formats.style.Styler.hide": ["Hide the entire index / column headers, or specific rows / columns from display."], "set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "Styler.set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "style.Styler.set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "formats.style.Styler.set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "io.formats.style.Styler.set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "pandas.io.formats.style.Styler.set_td_classes": ["Set the DataFrame of strings added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">class</span></code> attribute of <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML elements."], "set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "Styler.set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "style.Styler.set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "formats.style.Styler.set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "io.formats.style.Styler.set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "pandas.io.formats.style.Styler.set_table_styles": ["Set the table styles included within the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;style&gt;</span></code> HTML element."], "set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "Styler.set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "style.Styler.set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "formats.style.Styler.set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "io.formats.style.Styler.set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "pandas.io.formats.style.Styler.set_table_attributes": ["Set the table attributes added to the <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;table&gt;</span></code> HTML element."], "set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "Styler.set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "style.Styler.set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "formats.style.Styler.set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "io.formats.style.Styler.set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "pandas.io.formats.style.Styler.set_tooltips": ["Set the DataFrame of strings on <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code> generating <code class=\"docutils literal notranslate\"><span class=\"pre\">:hover</span></code> tooltips."], "set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "Styler.set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "style.Styler.set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "formats.style.Styler.set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "io.formats.style.Styler.set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "pandas.io.formats.style.Styler.set_caption": ["Set the text added to a <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;caption&gt;</span></code> HTML element."], "set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "Styler.set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "style.Styler.set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "formats.style.Styler.set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "io.formats.style.Styler.set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "pandas.io.formats.style.Styler.set_sticky": ["Add CSS to permanently display the index or column headers in a scrolling frame."], "set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "Styler.set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "style.Styler.set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "formats.style.Styler.set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "io.formats.style.Styler.set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "pandas.io.formats.style.Styler.set_properties": ["Set defined CSS-properties to each <code class=\"docutils literal notranslate\"><span class=\"pre\">&lt;td&gt;</span></code> HTML element within the given subset."], "set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "Styler.set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "style.Styler.set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "formats.style.Styler.set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "io.formats.style.Styler.set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "pandas.io.formats.style.Styler.set_uuid": ["Set the uuid applied to <code class=\"docutils literal notranslate\"><span class=\"pre\">id</span></code> attributes of HTML elements."], "clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "Styler.clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "style.Styler.clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "formats.style.Styler.clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "io.formats.style.Styler.clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "pandas.io.formats.style.Styler.clear": ["Reset the <code class=\"docutils literal notranslate\"><span class=\"pre\">Styler</span></code>, removing any previously applied styles."], "Styler.pipe": ["Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "style.Styler.pipe": ["Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "formats.style.Styler.pipe": ["Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "io.formats.style.Styler.pipe": ["Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "pandas.io.formats.style.Styler.pipe": ["Apply <code class=\"docutils literal notranslate\"><span class=\"pre\">func(self,</span> <span class=\"pre\">*args,</span> <span class=\"pre\">**kwargs)</span></code>, and return the result."], "highlight_null": ["Highlight missing values with a style."], "Styler.highlight_null": ["Highlight missing values with a style."], "style.Styler.highlight_null": ["Highlight missing values with a style."], "formats.style.Styler.highlight_null": ["Highlight missing values with a style."], "io.formats.style.Styler.highlight_null": ["Highlight missing values with a style."], "pandas.io.formats.style.Styler.highlight_null": ["Highlight missing values with a style."], "highlight_max": ["Highlight the maximum with a style."], "Styler.highlight_max": ["Highlight the maximum with a style."], "style.Styler.highlight_max": ["Highlight the maximum with a style."], "formats.style.Styler.highlight_max": ["Highlight the maximum with a style."], "io.formats.style.Styler.highlight_max": ["Highlight the maximum with a style."], "pandas.io.formats.style.Styler.highlight_max": ["Highlight the maximum with a style."], "highlight_min": ["Highlight the minimum with a style."], "Styler.highlight_min": ["Highlight the minimum with a style."], "style.Styler.highlight_min": ["Highlight the minimum with a style."], "formats.style.Styler.highlight_min": ["Highlight the minimum with a style."], "io.formats.style.Styler.highlight_min": ["Highlight the minimum with a style."], "pandas.io.formats.style.Styler.highlight_min": ["Highlight the minimum with a style."], "highlight_between": ["Highlight a defined range with a style."], "Styler.highlight_between": ["Highlight a defined range with a style."], "style.Styler.highlight_between": ["Highlight a defined range with a style."], "formats.style.Styler.highlight_between": ["Highlight a defined range with a style."], "io.formats.style.Styler.highlight_between": ["Highlight a defined range with a style."], "pandas.io.formats.style.Styler.highlight_between": ["Highlight a defined range with a style."], "highlight_quantile": ["Highlight values defined by a quantile with a style."], "Styler.highlight_quantile": ["Highlight values defined by a quantile with a style."], "style.Styler.highlight_quantile": ["Highlight values defined by a quantile with a style."], "formats.style.Styler.highlight_quantile": ["Highlight values defined by a quantile with a style."], "io.formats.style.Styler.highlight_quantile": ["Highlight values defined by a quantile with a style."], "pandas.io.formats.style.Styler.highlight_quantile": ["Highlight values defined by a quantile with a style."], "background_gradient": ["Color the background in a gradient style."], "Styler.background_gradient": ["Color the background in a gradient style."], "style.Styler.background_gradient": ["Color the background in a gradient style."], "formats.style.Styler.background_gradient": ["Color the background in a gradient style."], "io.formats.style.Styler.background_gradient": ["Color the background in a gradient style."], "pandas.io.formats.style.Styler.background_gradient": ["Color the background in a gradient style."], "text_gradient": ["Color the text in a gradient style."], "Styler.text_gradient": ["Color the text in a gradient style."], "style.Styler.text_gradient": ["Color the text in a gradient style."], "formats.style.Styler.text_gradient": ["Color the text in a gradient style."], "io.formats.style.Styler.text_gradient": ["Color the text in a gradient style."], "pandas.io.formats.style.Styler.text_gradient": ["Color the text in a gradient style."], "Styler.bar": ["Draw bar chart in the cell backgrounds."], "style.Styler.bar": ["Draw bar chart in the cell backgrounds."], "formats.style.Styler.bar": ["Draw bar chart in the cell backgrounds."], "io.formats.style.Styler.bar": ["Draw bar chart in the cell backgrounds."], "pandas.io.formats.style.Styler.bar": ["Draw bar chart in the cell backgrounds."], "export": ["Export the styles applied to the current Styler."], "Styler.export": ["Export the styles applied to the current Styler."], "style.Styler.export": ["Export the styles applied to the current Styler."], "formats.style.Styler.export": ["Export the styles applied to the current Styler."], "io.formats.style.Styler.export": ["Export the styles applied to the current Styler."], "pandas.io.formats.style.Styler.export": ["Export the styles applied to the current Styler."], "use": ["Set the styles on the current Styler."], "Styler.use": ["Set the styles on the current Styler."], "style.Styler.use": ["Set the styles on the current Styler."], "formats.style.Styler.use": ["Set the styles on the current Styler."], "io.formats.style.Styler.use": ["Set the styles on the current Styler."], "pandas.io.formats.style.Styler.use": ["Set the styles on the current Styler."], "andrews_curves": ["Generate a matplotlib plot of Andrews curves, for visualising clusters of multivariate data."], "plotting.andrews_curves": ["Generate a matplotlib plot of Andrews curves, for visualising clusters of multivariate data."], "pandas.plotting.andrews_curves": ["Generate a matplotlib plot of Andrews curves, for visualising clusters of multivariate data."], "autocorrelation_plot": ["Autocorrelation plot for time series."], "plotting.autocorrelation_plot": ["Autocorrelation plot for time series."], "pandas.plotting.autocorrelation_plot": ["Autocorrelation plot for time series."], "bootstrap_plot": ["Bootstrap plot on mean, median and mid-range statistics."], "plotting.bootstrap_plot": ["Bootstrap plot on mean, median and mid-range statistics."], "pandas.plotting.bootstrap_plot": ["Bootstrap plot on mean, median and mid-range statistics."], "plotting.boxplot": ["Make a box plot from DataFrame columns."], "pandas.plotting.boxplot": ["Make a box plot from DataFrame columns."], "deregister_matplotlib_converters": ["Remove pandas formatters and converters."], "plotting.deregister_matplotlib_converters": ["Remove pandas formatters and converters."], "pandas.plotting.deregister_matplotlib_converters": ["Remove pandas formatters and converters."], "lag_plot": ["Lag plot for time series."], "plotting.lag_plot": ["Lag plot for time series."], "pandas.plotting.lag_plot": ["Lag plot for time series."], "parallel_coordinates": ["Parallel coordinates plotting."], "plotting.parallel_coordinates": ["Parallel coordinates plotting."], "pandas.plotting.parallel_coordinates": ["Parallel coordinates plotting."], "plot_params": ["Stores pandas plotting options."], "plotting.plot_params": ["Stores pandas plotting options."], "pandas.plotting.plot_params": ["Stores pandas plotting options."], "radviz": ["Plot a multidimensional dataset in 2D."], "plotting.radviz": ["Plot a multidimensional dataset in 2D."], "pandas.plotting.radviz": ["Plot a multidimensional dataset in 2D."], "register_matplotlib_converters": ["Register pandas formatters and converters with matplotlib."], "plotting.register_matplotlib_converters": ["Register pandas formatters and converters with matplotlib."], "pandas.plotting.register_matplotlib_converters": ["Register pandas formatters and converters with matplotlib."], "scatter_matrix": ["Draw a matrix of scatter plots."], "plotting.scatter_matrix": ["Draw a matrix of scatter plots."], "pandas.plotting.scatter_matrix": ["Draw a matrix of scatter plots."], "table": ["Helper function to convert DataFrame and Series to matplotlib.table."], "plotting.table": ["Helper function to convert DataFrame and Series to matplotlib.table."], "pandas.plotting.table": ["Helper function to convert DataFrame and Series to matplotlib.table."], "describe_option": ["Prints the description for one or more registered options."], "pandas.describe_option": ["Prints the description for one or more registered options."], "reset_option": ["Reset one or more options to their default value."], "pandas.reset_option": ["Reset one or more options to their default value."], "get_option": ["Retrieves the value of the specified option."], "pandas.get_option": ["Retrieves the value of the specified option."], "set_option": ["Sets the value of the specified option."], "pandas.set_option": ["Sets the value of the specified option."], "option_context": ["Context manager to temporarily set options in the <cite>with</cite> statement context."], "pandas.option_context": ["Context manager to temporarily set options in the <cite>with</cite> statement context."], "assert_frame_equal": ["Check that left and right DataFrame are equal."], "testing.assert_frame_equal": ["Check that left and right DataFrame are equal."], "pandas.testing.assert_frame_equal": ["Check that left and right DataFrame are equal."], "assert_series_equal": ["Check that left and right Series are equal."], "testing.assert_series_equal": ["Check that left and right Series are equal."], "pandas.testing.assert_series_equal": ["Check that left and right Series are equal."], "assert_index_equal": ["Check that left and right Index are equal."], "testing.assert_index_equal": ["Check that left and right Index are equal."], "pandas.testing.assert_index_equal": ["Check that left and right Index are equal."], "assert_extension_array_equal": ["Check that left and right ExtensionArrays are equal."], "testing.assert_extension_array_equal": ["Check that left and right ExtensionArrays are equal."], "pandas.testing.assert_extension_array_equal": ["Check that left and right ExtensionArrays are equal."], "AbstractMethodError": ["Raise this error instead of NotImplementedError for abstract methods while keeping compatibility with Python 2 and Python 3."], "errors.AbstractMethodError": ["Raise this error instead of NotImplementedError for abstract methods while keeping compatibility with Python 2 and Python 3."], "pandas.errors.AbstractMethodError": ["Raise this error instead of NotImplementedError for abstract methods while keeping compatibility with Python 2 and Python 3."], "AccessorRegistrationWarning": ["Warning for attribute conflicts in accessor registration."], "errors.AccessorRegistrationWarning": ["Warning for attribute conflicts in accessor registration."], "pandas.errors.AccessorRegistrationWarning": ["Warning for attribute conflicts in accessor registration."], "DtypeWarning": ["Warning raised when reading different dtypes in a column from a file."], "errors.DtypeWarning": ["Warning raised when reading different dtypes in a column from a file."], "pandas.errors.DtypeWarning": ["Warning raised when reading different dtypes in a column from a file."], "DuplicateLabelError": ["Error raised when an operation would introduce duplicate labels."], "errors.DuplicateLabelError": ["Error raised when an operation would introduce duplicate labels."], "pandas.errors.DuplicateLabelError": ["Error raised when an operation would introduce duplicate labels."], "EmptyDataError": ["Exception that is thrown in <cite>pd.read_csv</cite> (by both the C and Python engines) when empty data or header is encountered."], "errors.EmptyDataError": ["Exception that is thrown in <cite>pd.read_csv</cite> (by both the C and Python engines) when empty data or header is encountered."], "pandas.errors.EmptyDataError": ["Exception that is thrown in <cite>pd.read_csv</cite> (by both the C and Python engines) when empty data or header is encountered."], "InvalidIndexError": ["Exception raised when attempting to use an invalid index key."], "errors.InvalidIndexError": ["Exception raised when attempting to use an invalid index key."], "pandas.errors.InvalidIndexError": ["Exception raised when attempting to use an invalid index key."], "IntCastingNaNError": ["Raised when attempting an astype operation on an array with NaN to an integer dtype."], "errors.IntCastingNaNError": ["Raised when attempting an astype operation on an array with NaN to an integer dtype."], "pandas.errors.IntCastingNaNError": ["Raised when attempting an astype operation on an array with NaN to an integer dtype."], "MergeError": ["Error raised when problems arise during merging due to problems with input data."], "errors.MergeError": ["Error raised when problems arise during merging due to problems with input data."], "pandas.errors.MergeError": ["Error raised when problems arise during merging due to problems with input data."], "NullFrequencyError": ["Error raised when a null <cite>freq</cite> attribute is used in an operation that needs a non-null frequency, particularly <cite>DatetimeIndex.shift</cite>, <cite>TimedeltaIndex.shift</cite>, <cite>PeriodIndex.shift</cite>."], "errors.NullFrequencyError": ["Error raised when a null <cite>freq</cite> attribute is used in an operation that needs a non-null frequency, particularly <cite>DatetimeIndex.shift</cite>, <cite>TimedeltaIndex.shift</cite>, <cite>PeriodIndex.shift</cite>."], "pandas.errors.NullFrequencyError": ["Error raised when a null <cite>freq</cite> attribute is used in an operation that needs a non-null frequency, particularly <cite>DatetimeIndex.shift</cite>, <cite>TimedeltaIndex.shift</cite>, <cite>PeriodIndex.shift</cite>."], "NumbaUtilError": ["Error raised for unsupported Numba engine routines."], "errors.NumbaUtilError": ["Error raised for unsupported Numba engine routines."], "pandas.errors.NumbaUtilError": ["Error raised for unsupported Numba engine routines."], "OptionError": ["Exception for pandas.options, backwards compatible with KeyError checks."], "errors.OptionError": ["Exception for pandas.options, backwards compatible with KeyError checks."], "pandas.errors.OptionError": ["Exception for pandas.options, backwards compatible with KeyError checks."], "OutOfBoundsDatetime": [""], "errors.OutOfBoundsDatetime": [""], "pandas.errors.OutOfBoundsDatetime": [""], "OutOfBoundsTimedelta": ["Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns]."], "errors.OutOfBoundsTimedelta": ["Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns]."], "pandas.errors.OutOfBoundsTimedelta": ["Raised when encountering a timedelta value that cannot be represented as a timedelta64[ns]."], "ParserError": ["Exception that is raised by an error encountered in parsing file contents."], "errors.ParserError": ["Exception that is raised by an error encountered in parsing file contents."], "pandas.errors.ParserError": ["Exception that is raised by an error encountered in parsing file contents."], "ParserWarning": ["Warning raised when reading a file that doesn't use the default 'c' parser."], "errors.ParserWarning": ["Warning raised when reading a file that doesn't use the default 'c' parser."], "pandas.errors.ParserWarning": ["Warning raised when reading a file that doesn't use the default 'c' parser."], "PerformanceWarning": ["Warning raised when there is a possible performance impact."], "errors.PerformanceWarning": ["Warning raised when there is a possible performance impact."], "pandas.errors.PerformanceWarning": ["Warning raised when there is a possible performance impact."], "UnsortedIndexError": ["Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted."], "errors.UnsortedIndexError": ["Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted."], "pandas.errors.UnsortedIndexError": ["Error raised when attempting to get a slice of a MultiIndex, and the index has not been lexsorted."], "UnsupportedFunctionCall": ["Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g."], "errors.UnsupportedFunctionCall": ["Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g."], "pandas.errors.UnsupportedFunctionCall": ["Exception raised when attempting to call a numpy function on a pandas object, but that function is not supported by the object e.g."], "union_categoricals": ["Combine list-like of Categorical-like, unioning categories."], "types.union_categoricals": ["Combine list-like of Categorical-like, unioning categories."], "api.types.union_categoricals": ["Combine list-like of Categorical-like, unioning categories."], "pandas.api.types.union_categoricals": ["Combine list-like of Categorical-like, unioning categories."], "infer_dtype": ["Efficiently infer the type of a passed val, or list-like array of values."], "types.infer_dtype": ["Efficiently infer the type of a passed val, or list-like array of values."], "api.types.infer_dtype": ["Efficiently infer the type of a passed val, or list-like array of values."], "pandas.api.types.infer_dtype": ["Efficiently infer the type of a passed val, or list-like array of values."], "pandas_dtype": ["Convert input into a pandas only dtype object or a numpy dtype object."], "types.pandas_dtype": ["Convert input into a pandas only dtype object or a numpy dtype object."], "api.types.pandas_dtype": ["Convert input into a pandas only dtype object or a numpy dtype object."], "pandas.api.types.pandas_dtype": ["Convert input into a pandas only dtype object or a numpy dtype object."], "is_bool_dtype": ["Check whether the provided array or dtype is of a boolean dtype."], "types.is_bool_dtype": ["Check whether the provided array or dtype is of a boolean dtype."], "api.types.is_bool_dtype": ["Check whether the provided array or dtype is of a boolean dtype."], "pandas.api.types.is_bool_dtype": ["Check whether the provided array or dtype is of a boolean dtype."], "is_categorical_dtype": ["Check whether an array-like or dtype is of the Categorical dtype."], "types.is_categorical_dtype": ["Check whether an array-like or dtype is of the Categorical dtype."], "api.types.is_categorical_dtype": ["Check whether an array-like or dtype is of the Categorical dtype."], "pandas.api.types.is_categorical_dtype": ["Check whether an array-like or dtype is of the Categorical dtype."], "is_complex_dtype": ["Check whether the provided array or dtype is of a complex dtype."], "types.is_complex_dtype": ["Check whether the provided array or dtype is of a complex dtype."], "api.types.is_complex_dtype": ["Check whether the provided array or dtype is of a complex dtype."], "pandas.api.types.is_complex_dtype": ["Check whether the provided array or dtype is of a complex dtype."], "is_datetime64_any_dtype": ["Check whether the provided array or dtype is of the datetime64 dtype."], "types.is_datetime64_any_dtype": ["Check whether the provided array or dtype is of the datetime64 dtype."], "api.types.is_datetime64_any_dtype": ["Check whether the provided array or dtype is of the datetime64 dtype."], "pandas.api.types.is_datetime64_any_dtype": ["Check whether the provided array or dtype is of the datetime64 dtype."], "is_datetime64_dtype": ["Check whether an array-like or dtype is of the datetime64 dtype."], "types.is_datetime64_dtype": ["Check whether an array-like or dtype is of the datetime64 dtype."], "api.types.is_datetime64_dtype": ["Check whether an array-like or dtype is of the datetime64 dtype."], "pandas.api.types.is_datetime64_dtype": ["Check whether an array-like or dtype is of the datetime64 dtype."], "is_datetime64_ns_dtype": ["Check whether the provided array or dtype is of the datetime64[ns] dtype."], "types.is_datetime64_ns_dtype": ["Check whether the provided array or dtype is of the datetime64[ns] dtype."], "api.types.is_datetime64_ns_dtype": ["Check whether the provided array or dtype is of the datetime64[ns] dtype."], "pandas.api.types.is_datetime64_ns_dtype": ["Check whether the provided array or dtype is of the datetime64[ns] dtype."], "is_datetime64tz_dtype": ["Check whether an array-like or dtype is of a DatetimeTZDtype dtype."], "types.is_datetime64tz_dtype": ["Check whether an array-like or dtype is of a DatetimeTZDtype dtype."], "api.types.is_datetime64tz_dtype": ["Check whether an array-like or dtype is of a DatetimeTZDtype dtype."], "pandas.api.types.is_datetime64tz_dtype": ["Check whether an array-like or dtype is of a DatetimeTZDtype dtype."], "is_extension_type": ["(DEPRECATED) Check whether an array-like is of a pandas extension class instance."], "types.is_extension_type": ["(DEPRECATED) Check whether an array-like is of a pandas extension class instance."], "api.types.is_extension_type": ["(DEPRECATED) Check whether an array-like is of a pandas extension class instance."], "pandas.api.types.is_extension_type": ["(DEPRECATED) Check whether an array-like is of a pandas extension class instance."], "is_extension_array_dtype": ["Check if an object is a pandas extension array type."], "types.is_extension_array_dtype": ["Check if an object is a pandas extension array type."], "api.types.is_extension_array_dtype": ["Check if an object is a pandas extension array type."], "pandas.api.types.is_extension_array_dtype": ["Check if an object is a pandas extension array type."], "is_float_dtype": ["Check whether the provided array or dtype is of a float dtype."], "types.is_float_dtype": ["Check whether the provided array or dtype is of a float dtype."], "api.types.is_float_dtype": ["Check whether the provided array or dtype is of a float dtype."], "pandas.api.types.is_float_dtype": ["Check whether the provided array or dtype is of a float dtype."], "is_int64_dtype": ["Check whether the provided array or dtype is of the int64 dtype."], "types.is_int64_dtype": ["Check whether the provided array or dtype is of the int64 dtype."], "api.types.is_int64_dtype": ["Check whether the provided array or dtype is of the int64 dtype."], "pandas.api.types.is_int64_dtype": ["Check whether the provided array or dtype is of the int64 dtype."], "is_integer_dtype": ["Check whether the provided array or dtype is of an integer dtype."], "types.is_integer_dtype": ["Check whether the provided array or dtype is of an integer dtype."], "api.types.is_integer_dtype": ["Check whether the provided array or dtype is of an integer dtype."], "pandas.api.types.is_integer_dtype": ["Check whether the provided array or dtype is of an integer dtype."], "is_interval_dtype": ["Check whether an array-like or dtype is of the Interval dtype."], "types.is_interval_dtype": ["Check whether an array-like or dtype is of the Interval dtype."], "api.types.is_interval_dtype": ["Check whether an array-like or dtype is of the Interval dtype."], "pandas.api.types.is_interval_dtype": ["Check whether an array-like or dtype is of the Interval dtype."], "is_numeric_dtype": ["Check whether the provided array or dtype is of a numeric dtype."], "types.is_numeric_dtype": ["Check whether the provided array or dtype is of a numeric dtype."], "api.types.is_numeric_dtype": ["Check whether the provided array or dtype is of a numeric dtype."], "pandas.api.types.is_numeric_dtype": ["Check whether the provided array or dtype is of a numeric dtype."], "is_object_dtype": ["Check whether an array-like or dtype is of the object dtype."], "types.is_object_dtype": ["Check whether an array-like or dtype is of the object dtype."], "api.types.is_object_dtype": ["Check whether an array-like or dtype is of the object dtype."], "pandas.api.types.is_object_dtype": ["Check whether an array-like or dtype is of the object dtype."], "is_period_dtype": ["Check whether an array-like or dtype is of the Period dtype."], "types.is_period_dtype": ["Check whether an array-like or dtype is of the Period dtype."], "api.types.is_period_dtype": ["Check whether an array-like or dtype is of the Period dtype."], "pandas.api.types.is_period_dtype": ["Check whether an array-like or dtype is of the Period dtype."], "is_signed_integer_dtype": ["Check whether the provided array or dtype is of a signed integer dtype."], "types.is_signed_integer_dtype": ["Check whether the provided array or dtype is of a signed integer dtype."], "api.types.is_signed_integer_dtype": ["Check whether the provided array or dtype is of a signed integer dtype."], "pandas.api.types.is_signed_integer_dtype": ["Check whether the provided array or dtype is of a signed integer dtype."], "is_string_dtype": ["Check whether the provided array or dtype is of the string dtype."], "types.is_string_dtype": ["Check whether the provided array or dtype is of the string dtype."], "api.types.is_string_dtype": ["Check whether the provided array or dtype is of the string dtype."], "pandas.api.types.is_string_dtype": ["Check whether the provided array or dtype is of the string dtype."], "is_timedelta64_dtype": ["Check whether an array-like or dtype is of the timedelta64 dtype."], "types.is_timedelta64_dtype": ["Check whether an array-like or dtype is of the timedelta64 dtype."], "api.types.is_timedelta64_dtype": ["Check whether an array-like or dtype is of the timedelta64 dtype."], "pandas.api.types.is_timedelta64_dtype": ["Check whether an array-like or dtype is of the timedelta64 dtype."], "is_timedelta64_ns_dtype": ["Check whether the provided array or dtype is of the timedelta64[ns] dtype."], "types.is_timedelta64_ns_dtype": ["Check whether the provided array or dtype is of the timedelta64[ns] dtype."], "api.types.is_timedelta64_ns_dtype": ["Check whether the provided array or dtype is of the timedelta64[ns] dtype."], "pandas.api.types.is_timedelta64_ns_dtype": ["Check whether the provided array or dtype is of the timedelta64[ns] dtype."], "is_unsigned_integer_dtype": ["Check whether the provided array or dtype is of an unsigned integer dtype."], "types.is_unsigned_integer_dtype": ["Check whether the provided array or dtype is of an unsigned integer dtype."], "api.types.is_unsigned_integer_dtype": ["Check whether the provided array or dtype is of an unsigned integer dtype."], "pandas.api.types.is_unsigned_integer_dtype": ["Check whether the provided array or dtype is of an unsigned integer dtype."], "is_sparse": ["Check whether an array-like is a 1-D pandas sparse array."], "types.is_sparse": ["Check whether an array-like is a 1-D pandas sparse array."], "api.types.is_sparse": ["Check whether an array-like is a 1-D pandas sparse array."], "pandas.api.types.is_sparse": ["Check whether an array-like is a 1-D pandas sparse array."], "is_dict_like": ["Check if the object is dict-like."], "types.is_dict_like": ["Check if the object is dict-like."], "api.types.is_dict_like": ["Check if the object is dict-like."], "pandas.api.types.is_dict_like": ["Check if the object is dict-like."], "is_file_like": ["Check if the object is a file-like object."], "types.is_file_like": ["Check if the object is a file-like object."], "api.types.is_file_like": ["Check if the object is a file-like object."], "pandas.api.types.is_file_like": ["Check if the object is a file-like object."], "is_list_like": ["Check if the object is list-like."], "types.is_list_like": ["Check if the object is list-like."], "api.types.is_list_like": ["Check if the object is list-like."], "pandas.api.types.is_list_like": ["Check if the object is list-like."], "is_named_tuple": ["Check if the object is a named tuple."], "types.is_named_tuple": ["Check if the object is a named tuple."], "api.types.is_named_tuple": ["Check if the object is a named tuple."], "pandas.api.types.is_named_tuple": ["Check if the object is a named tuple."], "is_iterator": ["Check if the object is an iterator."], "types.is_iterator": ["Check if the object is an iterator."], "api.types.is_iterator": ["Check if the object is an iterator."], "pandas.api.types.is_iterator": ["Check if the object is an iterator."], "is_bool": ["Return True if given object is boolean."], "types.is_bool": ["Return True if given object is boolean."], "api.types.is_bool": ["Return True if given object is boolean."], "pandas.api.types.is_bool": ["Return True if given object is boolean."], "types.is_categorical": ["Check whether an array-like is a Categorical instance."], "api.types.is_categorical": ["Check whether an array-like is a Categorical instance."], "pandas.api.types.is_categorical": ["Check whether an array-like is a Categorical instance."], "is_complex": ["Return True if given object is complex."], "types.is_complex": ["Return True if given object is complex."], "api.types.is_complex": ["Return True if given object is complex."], "pandas.api.types.is_complex": ["Return True if given object is complex."], "is_float": ["Return True if given object is float."], "types.is_float": ["Return True if given object is float."], "api.types.is_float": ["Return True if given object is float."], "pandas.api.types.is_float": ["Return True if given object is float."], "is_hashable": ["Return True if hash(obj) will succeed, False otherwise."], "types.is_hashable": ["Return True if hash(obj) will succeed, False otherwise."], "api.types.is_hashable": ["Return True if hash(obj) will succeed, False otherwise."], "pandas.api.types.is_hashable": ["Return True if hash(obj) will succeed, False otherwise."], "types.is_integer": ["Return True if given object is integer."], "api.types.is_integer": ["Return True if given object is integer."], "pandas.api.types.is_integer": ["Return True if given object is integer."], "types.is_interval": [""], "api.types.is_interval": [""], "pandas.api.types.is_interval": [""], "is_number": ["Check if the object is a number."], "types.is_number": ["Check if the object is a number."], "api.types.is_number": ["Check if the object is a number."], "pandas.api.types.is_number": ["Check if the object is a number."], "is_re": ["Check if the object is a regex pattern instance."], "types.is_re": ["Check if the object is a regex pattern instance."], "api.types.is_re": ["Check if the object is a regex pattern instance."], "pandas.api.types.is_re": ["Check if the object is a regex pattern instance."], "is_re_compilable": ["Check if the object can be compiled into a regex pattern instance."], "types.is_re_compilable": ["Check if the object can be compiled into a regex pattern instance."], "api.types.is_re_compilable": ["Check if the object can be compiled into a regex pattern instance."], "pandas.api.types.is_re_compilable": ["Check if the object can be compiled into a regex pattern instance."], "is_scalar": ["Return True if given object is scalar."], "types.is_scalar": ["Return True if given object is scalar."], "api.types.is_scalar": ["Return True if given object is scalar."], "pandas.api.types.is_scalar": ["Return True if given object is scalar."], "show_versions": ["Provide useful information, important for bug reports.", "Print useful debugging information\""], "pandas.show_versions": ["Provide useful information, important for bug reports."], "register_extension_dtype": ["Register an ExtensionType with pandas as class decorator."], "extensions.register_extension_dtype": ["Register an ExtensionType with pandas as class decorator."], "api.extensions.register_extension_dtype": ["Register an ExtensionType with pandas as class decorator."], "pandas.api.extensions.register_extension_dtype": ["Register an ExtensionType with pandas as class decorator."], "register_dataframe_accessor": ["Register a custom accessor on DataFrame objects."], "extensions.register_dataframe_accessor": ["Register a custom accessor on DataFrame objects."], "api.extensions.register_dataframe_accessor": ["Register a custom accessor on DataFrame objects."], "pandas.api.extensions.register_dataframe_accessor": ["Register a custom accessor on DataFrame objects."], "register_series_accessor": ["Register a custom accessor on Series objects."], "extensions.register_series_accessor": ["Register a custom accessor on Series objects."], "api.extensions.register_series_accessor": ["Register a custom accessor on Series objects."], "pandas.api.extensions.register_series_accessor": ["Register a custom accessor on Series objects."], "register_index_accessor": ["Register a custom accessor on Index objects."], "extensions.register_index_accessor": ["Register a custom accessor on Index objects."], "api.extensions.register_index_accessor": ["Register a custom accessor on Index objects."], "pandas.api.extensions.register_index_accessor": ["Register a custom accessor on Index objects."], "ExtensionDtype": ["A custom data type, to be paired with an ExtensionArray."], "extensions.ExtensionDtype": ["A custom data type, to be paired with an ExtensionArray."], "api.extensions.ExtensionDtype": ["A custom data type, to be paired with an ExtensionArray."], "pandas.api.extensions.ExtensionDtype": ["A custom data type, to be paired with an ExtensionArray."], "ExtensionArray": ["Abstract base class for custom 1-D array types."], "extensions.ExtensionArray": ["Abstract base class for custom 1-D array types."], "api.extensions.ExtensionArray": ["Abstract base class for custom 1-D array types."], "pandas.api.extensions.ExtensionArray": ["Abstract base class for custom 1-D array types."], "PandasArray": ["A pandas ExtensionArray for NumPy data."], "arrays.PandasArray": ["A pandas ExtensionArray for NumPy data."], "pandas.arrays.PandasArray": ["A pandas ExtensionArray for NumPy data."], "check_array_indexer": ["Check if <cite>indexer</cite> is a valid array indexer for <cite>array</cite>."], "indexers.check_array_indexer": ["Check if <cite>indexer</cite> is a valid array indexer for <cite>array</cite>."], "api.indexers.check_array_indexer": ["Check if <cite>indexer</cite> is a valid array indexer for <cite>array</cite>."], "pandas.api.indexers.check_array_indexer": ["Check if <cite>indexer</cite> is a valid array indexer for <cite>array</cite>."], "ndarray.any": ["Returns True if any of the elements of <em class=\"xref py py-obj\">a</em> evaluate to True."], "numpy.ndarray.any": ["Returns True if any of the elements of <em class=\"xref py py-obj\">a</em> evaluate to True."], "ndarray.argmax": ["Return indices of the maximum values along the given axis."], "numpy.ndarray.argmax": ["Return indices of the maximum values along the given axis."], "ndarray.argmin": ["Return indices of the minimum values along the given axis."], "numpy.ndarray.argmin": ["Return indices of the minimum values along the given axis."], "argpartition": ["Returns the indices that would partition this array."], "ndarray.argpartition": ["Returns the indices that would partition this array."], "numpy.ndarray.argpartition": ["Returns the indices that would partition this array."], "ndarray.argsort": ["Returns the indices that would sort this array."], "numpy.ndarray.argsort": ["Returns the indices that would sort this array."], "ndarray.astype": ["Copy of the array, cast to a specified type."], "numpy.ndarray.astype": ["Copy of the array, cast to a specified type."], "byteswap": ["Swap the bytes of the array elements", "Scalar method identical to the corresponding array attribute."], "ndarray.byteswap": ["Swap the bytes of the array elements"], "numpy.ndarray.byteswap": ["Swap the bytes of the array elements"], "choose": ["Use an index array to construct a new array from a set of choices."], "ndarray.choose": ["Use an index array to construct a new array from a set of choices."], "numpy.ndarray.choose": ["Use an index array to construct a new array from a set of choices."], "compress": ["Return selected slices of this array along given axis."], "ndarray.compress": ["Return selected slices of this array along given axis."], "numpy.ndarray.compress": ["Return selected slices of this array along given axis."], "conj": ["Complex-conjugate all elements."], "ndarray.conj": ["Complex-conjugate all elements."], "numpy.ndarray.conj": ["Complex-conjugate all elements."], "conjugate": ["Return the complex conjugate, element-wise."], "ndarray.conjugate": ["Return the complex conjugate, element-wise."], "numpy.ndarray.conjugate": ["Return the complex conjugate, element-wise."], "ndarray.copy": ["Return a copy of the array."], "numpy.ndarray.copy": ["Return a copy of the array."], "ndarray.cumprod": ["Return the cumulative product of the elements along the given axis."], "numpy.ndarray.cumprod": ["Return the cumulative product of the elements along the given axis."], "ndarray.cumsum": ["Return the cumulative sum of the elements along the given axis."], "numpy.ndarray.cumsum": ["Return the cumulative sum of the elements along the given axis."], "fill": ["Fill the array with a scalar value."], "ndarray.fill": ["Fill the array with a scalar value."], "numpy.ndarray.fill": ["Fill the array with a scalar value."], "flatten": ["method"], "ndarray.flatten": ["method"], "numpy.ndarray.flatten": ["method"], "getfield": ["Returns a field of the given array as a certain type."], "ndarray.getfield": ["Returns a field of the given array as a certain type."], "numpy.ndarray.getfield": ["Returns a field of the given array as a certain type."], "ndarray.item": ["Copy an element of an array to a standard Python scalar and return it."], "numpy.ndarray.item": ["Copy an element of an array to a standard Python scalar and return it."], "itemset": ["Insert scalar into an array (scalar is cast to array\u2019s dtype, if possible)"], "ndarray.itemset": ["Insert scalar into an array (scalar is cast to array\u2019s dtype, if possible)"], "numpy.ndarray.itemset": ["Insert scalar into an array (scalar is cast to array\u2019s dtype, if possible)"], "ndarray.max": ["Return the maximum along a given axis."], "numpy.ndarray.max": ["Return the maximum along a given axis."], "ndarray.mean": ["Returns the average of the array elements along given axis."], "numpy.ndarray.mean": ["Returns the average of the array elements along given axis."], "ndarray.min": ["Return the minimum along a given axis."], "numpy.ndarray.min": ["Return the minimum along a given axis."], "newbyteorder": ["Return the array with the same data viewed with a different byte order.", "Return a new dtype with a different byte order."], "ndarray.newbyteorder": ["Return the array with the same data viewed with a different byte order."], "numpy.ndarray.newbyteorder": ["Return the array with the same data viewed with a different byte order."], "nonzero": ["Return the indices of the elements that are non-zero."], "ndarray.nonzero": ["Return the indices of the elements that are non-zero."], "numpy.ndarray.nonzero": ["Return the indices of the elements that are non-zero."], "ndarray.prod": ["Return the product of the array elements over the given axis"], "numpy.ndarray.prod": ["Return the product of the array elements over the given axis"], "ptp": ["Peak to peak (maximum - minimum) value along a given axis."], "ndarray.ptp": ["Peak to peak (maximum - minimum) value along a given axis."], "numpy.ndarray.ptp": ["Peak to peak (maximum - minimum) value along a given axis."], "ndarray.put": ["Set <code class=\"docutils literal notranslate\"><span class=\"pre\">a.flat[n]</span> <span class=\"pre\">=</span> <span class=\"pre\">values[n]</span></code> for all <em class=\"xref py py-obj\">n</em> in indices."], "numpy.ndarray.put": ["Set <code class=\"docutils literal notranslate\"><span class=\"pre\">a.flat[n]</span> <span class=\"pre\">=</span> <span class=\"pre\">values[n]</span></code> for all <em class=\"xref py py-obj\">n</em> in indices."], "ndarray.ravel": ["Return a flattened array."], "numpy.ndarray.ravel": ["Return a flattened array."], "ndarray.repeat": ["Repeat elements of an array."], "numpy.ndarray.repeat": ["Repeat elements of an array."], "reshape": ["Returns an array containing the same data with a new shape.", "Gives a new shape to an array without changing its data."], "ndarray.reshape": ["Returns an array containing the same data with a new shape."], "numpy.ndarray.reshape": ["Returns an array containing the same data with a new shape."], "resize": ["Change shape and size of array in-place.", "Return a new array with the specified shape."], "ndarray.resize": ["Change shape and size of array in-place."], "numpy.ndarray.resize": ["Change shape and size of array in-place."], "ndarray.round": ["Return <em class=\"xref py py-obj\">a</em> with each element rounded to the given number of decimals."], "numpy.ndarray.round": ["Return <em class=\"xref py py-obj\">a</em> with each element rounded to the given number of decimals."], "ndarray.searchsorted": ["Find indices where elements of v should be inserted in a to maintain order."], "numpy.ndarray.searchsorted": ["Find indices where elements of v should be inserted in a to maintain order."], "setfield": ["Put a value into a specified place in a field defined by a data-type."], "ndarray.setfield": ["Put a value into a specified place in a field defined by a data-type."], "numpy.ndarray.setfield": ["Put a value into a specified place in a field defined by a data-type."], "sort": ["Sort an array in-place. Refer to <a class=\"reference internal\" href=\"numpy.sort.html#numpy.sort\" title=\"numpy.sort\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">numpy.sort</span></code></a> for full documentation."], "ndarray.sort": ["Sort an array in-place. Refer to <a class=\"reference internal\" href=\"numpy.sort.html#numpy.sort\" title=\"numpy.sort\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">numpy.sort</span></code></a> for full documentation."], "numpy.ndarray.sort": ["Sort an array in-place. Refer to <a class=\"reference internal\" href=\"numpy.sort.html#numpy.sort\" title=\"numpy.sort\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">numpy.sort</span></code></a> for full documentation."], "ndarray.squeeze": ["Remove axes of length one from <em class=\"xref py py-obj\">a</em>."], "numpy.ndarray.squeeze": ["Remove axes of length one from <em class=\"xref py py-obj\">a</em>."], "ndarray.std": ["Returns the standard deviation of the array elements along given axis."], "numpy.ndarray.std": ["Returns the standard deviation of the array elements along given axis."], "ndarray.sum": ["Return the sum of the array elements over the given axis."], "numpy.ndarray.sum": ["Return the sum of the array elements over the given axis."], "ndarray.swapaxes": ["Return a view of the array with <em class=\"xref py py-obj\">axis1</em> and <em class=\"xref py py-obj\">axis2</em> interchanged."], "numpy.ndarray.swapaxes": ["Return a view of the array with <em class=\"xref py py-obj\">axis1</em> and <em class=\"xref py py-obj\">axis2</em> interchanged."], "ndarray.take": ["Return an array formed from the elements of <em class=\"xref py py-obj\">a</em> at the given indices."], "numpy.ndarray.take": ["Return an array formed from the elements of <em class=\"xref py py-obj\">a</em> at the given indices."], "tobytes": ["Construct Python bytes containing the raw data bytes in the array."], "ndarray.tobytes": ["Construct Python bytes containing the raw data bytes in the array."], "numpy.ndarray.tobytes": ["Construct Python bytes containing the raw data bytes in the array."], "tofile": ["method"], "ndarray.tofile": ["method"], "numpy.ndarray.tofile": ["method"], "tolist": ["method"], "ndarray.tolist": ["method"], "numpy.ndarray.tolist": ["method"], "tostring": ["A compatibility alias for <a class=\"reference internal\" href=\"numpy.ndarray.tobytes.html#numpy.ndarray.tobytes\" title=\"numpy.ndarray.tobytes\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">tobytes</span></code></a>, with exactly the same behavior."], "ndarray.tostring": ["A compatibility alias for <a class=\"reference internal\" href=\"numpy.ndarray.tobytes.html#numpy.ndarray.tobytes\" title=\"numpy.ndarray.tobytes\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">tobytes</span></code></a>, with exactly the same behavior."], "numpy.ndarray.tostring": ["A compatibility alias for <a class=\"reference internal\" href=\"numpy.ndarray.tobytes.html#numpy.ndarray.tobytes\" title=\"numpy.ndarray.tobytes\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">tobytes</span></code></a>, with exactly the same behavior."], "trace": ["Return the sum along diagonals of the array."], "ndarray.trace": ["Return the sum along diagonals of the array."], "numpy.ndarray.trace": ["Return the sum along diagonals of the array."], "ndarray.transpose": ["Returns a view of the array with axes transposed."], "numpy.ndarray.transpose": ["Returns a view of the array with axes transposed."], "ndarray.var": ["Returns the variance of the array elements, along given axis."], "numpy.ndarray.var": ["Returns the variance of the array elements, along given axis."], "ndarray.view": ["New view of array with the same data."], "numpy.ndarray.view": ["New view of array with the same data."], "ndarray.flags": ["Information about the memory layout of the array."], "numpy.ndarray.flags": ["Information about the memory layout of the array."], "ndarray.shape": ["Tuple of array dimensions."], "numpy.ndarray.shape": ["Tuple of array dimensions."], "strides": ["Tuple of bytes to step in each dimension when traversing an array.", "Tuple of bytes steps in each dimension."], "ndarray.strides": ["Tuple of bytes to step in each dimension when traversing an array."], "numpy.ndarray.strides": ["Tuple of bytes to step in each dimension when traversing an array."], "ndarray.ndim": ["Number of array dimensions."], "numpy.ndarray.ndim": ["Number of array dimensions."], "data": ["Python buffer object pointing to the start of the array\u2019s data.", "Pointer to start of data."], "ndarray.data": ["Python buffer object pointing to the start of the array\u2019s data."], "numpy.ndarray.data": ["Python buffer object pointing to the start of the array\u2019s data."], "ndarray.size": ["Number of elements in the array."], "numpy.ndarray.size": ["Number of elements in the array."], "itemsize": ["Length of one array element in bytes.", "The length of one element in bytes.", "The element size of this data-type object."], "ndarray.itemsize": ["Length of one array element in bytes."], "numpy.ndarray.itemsize": ["Length of one array element in bytes."], "ndarray.nbytes": ["Total bytes consumed by the elements of the array."], "numpy.ndarray.nbytes": ["Total bytes consumed by the elements of the array."], "base": ["Base object if memory is from some other object.", "Scalar attribute identical to the corresponding array attribute."], "ndarray.base": ["Base object if memory is from some other object."], "numpy.ndarray.base": ["Base object if memory is from some other object."], "ndarray.dtype": ["Data-type of the array\u2019s elements."], "numpy.ndarray.dtype": ["Data-type of the array\u2019s elements."], "ndarray.T": ["attribute"], "numpy.ndarray.T": ["attribute"], "real": ["The real part of the array.", "The real part of the scalar."], "ndarray.real": ["The real part of the array."], "numpy.ndarray.real": ["The real part of the array."], "imag": ["The imaginary part of the array.", "The imaginary part of the scalar."], "ndarray.imag": ["The imaginary part of the array."], "numpy.ndarray.imag": ["The imaginary part of the array."], "flat": ["attribute", "A 1-D view of the scalar."], "ndarray.flat": ["attribute"], "numpy.ndarray.flat": ["attribute"], "__lt__": ["Return self&lt;value."], "ndarray.__lt__": ["Return self&lt;value."], "numpy.ndarray.__lt__": ["Return self&lt;value."], "__le__": ["Return self&lt;=value."], "ndarray.__le__": ["Return self&lt;=value."], "numpy.ndarray.__le__": ["Return self&lt;=value."], "__gt__": ["Return self&gt;value."], "ndarray.__gt__": ["Return self&gt;value."], "numpy.ndarray.__gt__": ["Return self&gt;value."], "__ge__": ["Return self&gt;=value."], "ndarray.__ge__": ["Return self&gt;=value."], "numpy.ndarray.__ge__": ["Return self&gt;=value."], "__eq__": ["Return self==value."], "ndarray.__eq__": ["Return self==value."], "numpy.ndarray.__eq__": ["Return self==value."], "__ne__": ["Return self!=value."], "ndarray.__ne__": ["Return self!=value."], "numpy.ndarray.__ne__": ["Return self!=value."], "__bool__": ["self != 0"], "ndarray.__bool__": ["self != 0"], "numpy.ndarray.__bool__": ["self != 0"], "__neg__": ["-self"], "ndarray.__neg__": ["-self"], "numpy.ndarray.__neg__": ["-self"], "__pos__": ["+self"], "ndarray.__pos__": ["+self"], "numpy.ndarray.__pos__": ["+self"], "__invert__": ["~self"], "ndarray.__invert__": ["~self"], "numpy.ndarray.__invert__": ["~self"], "__add__": ["Return self+value."], "ndarray.__add__": ["Return self+value."], "numpy.ndarray.__add__": ["Return self+value."], "__sub__": ["Return self-value."], "ndarray.__sub__": ["Return self-value."], "numpy.ndarray.__sub__": ["Return self-value."], "__mul__": ["Return self*value."], "ndarray.__mul__": ["Return self*value."], "numpy.ndarray.__mul__": ["Return self*value."], "__truediv__": ["Return self/value."], "ndarray.__truediv__": ["Return self/value."], "numpy.ndarray.__truediv__": ["Return self/value."], "__floordiv__": ["Return self//value."], "ndarray.__floordiv__": ["Return self//value."], "numpy.ndarray.__floordiv__": ["Return self//value."], "__mod__": ["Return self%value."], "ndarray.__mod__": ["Return self%value."], "numpy.ndarray.__mod__": ["Return self%value."], "__divmod__": ["Return divmod(self, value)."], "ndarray.__divmod__": ["Return divmod(self, value)."], "numpy.ndarray.__divmod__": ["Return divmod(self, value)."], "__pow__": ["Return pow(self, value, mod)."], "ndarray.__pow__": ["Return pow(self, value, mod)."], "numpy.ndarray.__pow__": ["Return pow(self, value, mod)."], "__lshift__": ["Return self&lt;&lt;value."], "ndarray.__lshift__": ["Return self&lt;&lt;value."], "numpy.ndarray.__lshift__": ["Return self&lt;&lt;value."], "__rshift__": ["Return self&gt;&gt;value."], "ndarray.__rshift__": ["Return self&gt;&gt;value."], "numpy.ndarray.__rshift__": ["Return self&gt;&gt;value."], "__and__": ["Return self&amp;value."], "ndarray.__and__": ["Return self&amp;value."], "numpy.ndarray.__and__": ["Return self&amp;value."], "__or__": ["Return self|value."], "ndarray.__or__": ["Return self|value."], "numpy.ndarray.__or__": ["Return self|value."], "__xor__": ["Return self^value."], "ndarray.__xor__": ["Return self^value."], "numpy.ndarray.__xor__": ["Return self^value."], "__iadd__": ["Return self+=value."], "ndarray.__iadd__": ["Return self+=value."], "numpy.ndarray.__iadd__": ["Return self+=value."], "__isub__": ["Return self-=value."], "ndarray.__isub__": ["Return self-=value."], "numpy.ndarray.__isub__": ["Return self-=value."], "__imul__": ["Return self*=value."], "ndarray.__imul__": ["Return self*=value."], "numpy.ndarray.__imul__": ["Return self*=value."], "__itruediv__": ["Return self/=value."], "ndarray.__itruediv__": ["Return self/=value."], "numpy.ndarray.__itruediv__": ["Return self/=value."], "__ifloordiv__": ["Return self//=value."], "ndarray.__ifloordiv__": ["Return self//=value."], "numpy.ndarray.__ifloordiv__": ["Return self//=value."], "__imod__": ["Return self%=value."], "ndarray.__imod__": ["Return self%=value."], "numpy.ndarray.__imod__": ["Return self%=value."], "__ipow__": ["Return self**=value."], "ndarray.__ipow__": ["Return self**=value."], "numpy.ndarray.__ipow__": ["Return self**=value."], "__ilshift__": ["Return self&lt;&lt;=value."], "ndarray.__ilshift__": ["Return self&lt;&lt;=value."], "numpy.ndarray.__ilshift__": ["Return self&lt;&lt;=value."], "__irshift__": ["Return self&gt;&gt;=value."], "ndarray.__irshift__": ["Return self&gt;&gt;=value."], "numpy.ndarray.__irshift__": ["Return self&gt;&gt;=value."], "__iand__": ["Return self&amp;=value."], "ndarray.__iand__": ["Return self&amp;=value."], "numpy.ndarray.__iand__": ["Return self&amp;=value."], "__ior__": ["Return self|=value."], "ndarray.__ior__": ["Return self|=value."], "numpy.ndarray.__ior__": ["Return self|=value."], "__ixor__": ["Return self^=value."], "ndarray.__ixor__": ["Return self^=value."], "numpy.ndarray.__ixor__": ["Return self^=value."], "__matmul__": ["Return <a class=\"reference external\" href=\"/cdn-cgi/l/email-protection#7407111812525747434f525741464f5257404c4f0215180111\">self<span>@</span>value</a>."], "ndarray.__matmul__": ["Return <a class=\"reference external\" href=\"/cdn-cgi/l/email-protection#7407111812525747434f525741464f5257404c4f0215180111\">self<span>@</span>value</a>."], "numpy.ndarray.__matmul__": ["Return <a class=\"reference external\" href=\"/cdn-cgi/l/email-protection#7407111812525747434f525741464f5257404c4f0215180111\">self<span>@</span>value</a>."], "__copy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.copy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.copy</span></code></a> is called on an array. Returns a copy of the array."], "ndarray.__copy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.copy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.copy</span></code></a> is called on an array. Returns a copy of the array."], "numpy.ndarray.__copy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.copy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.copy</span></code></a> is called on an array. Returns a copy of the array."], "__deepcopy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.deepcopy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.deepcopy</span></code></a> is called on an array."], "ndarray.__deepcopy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.deepcopy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.deepcopy</span></code></a> is called on an array."], "numpy.ndarray.__deepcopy__": ["Used if <a class=\"reference external\" href=\"https://docs.python.org/3/library/copy.html#copy.deepcopy\" title=\"(in Python v3.10)\"><code class=\"xref py py-func docutils literal notranslate\"><span class=\"pre\">copy.deepcopy</span></code></a> is called on an array."], "__reduce__": ["For pickling.", "Helper for pickle."], "ndarray.__reduce__": ["For pickling."], "numpy.ndarray.__reduce__": ["For pickling."], "__setstate__": ["For unpickling."], "ndarray.__setstate__": ["For unpickling."], "numpy.ndarray.__setstate__": ["For unpickling."], "__array_wrap__": ["Returns a view of <a class=\"reference internal\" href=\"numpy.array.html#numpy.array\" title=\"numpy.array\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">array</span></code></a> with the same type as self.", "sc.__array_wrap__(obj) return scalar from array"], "ndarray.__array_wrap__": ["Returns a view of <a class=\"reference internal\" href=\"numpy.array.html#numpy.array\" title=\"numpy.array\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">array</span></code></a> with the same type as self."], "numpy.ndarray.__array_wrap__": ["Returns a view of <a class=\"reference internal\" href=\"numpy.array.html#numpy.array\" title=\"numpy.array\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">array</span></code></a> with the same type as self."], "__len__": ["Return len(self)."], "ndarray.__len__": ["Return len(self)."], "numpy.ndarray.__len__": ["Return len(self)."], "__getitem__": ["Return self[key]."], "ndarray.__getitem__": ["Return self[key]."], "numpy.ndarray.__getitem__": ["Return self[key]."], "__setitem__": ["Set self[key] to value."], "ndarray.__setitem__": ["Set self[key] to value."], "numpy.ndarray.__setitem__": ["Set self[key] to value."], "__contains__": ["Return key in self."], "ndarray.__contains__": ["Return key in self."], "numpy.ndarray.__contains__": ["Return key in self."], "__str__": ["Return str(self)."], "ndarray.__str__": ["Return str(self)."], "numpy.ndarray.__str__": ["Return str(self)."], "__repr__": ["Return repr(self)."], "ndarray.__repr__": ["Return repr(self)."], "numpy.ndarray.__repr__": ["Return repr(self)."], "__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.ndarray.html#numpy.ndarray\" title=\"numpy.ndarray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ndarray</span></code></a> type.", "Return a parametrized wrapper around the <a class=\"reference internal\" href=\"../arrays.scalars.html#numpy.number\" title=\"numpy.number\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">number</span></code></a> type.", "Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.dtype.html#numpy.dtype\" title=\"numpy.dtype\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></a> type."], "ndarray.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.ndarray.html#numpy.ndarray\" title=\"numpy.ndarray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ndarray</span></code></a> type."], "numpy.ndarray.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.ndarray.html#numpy.ndarray\" title=\"numpy.ndarray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ndarray</span></code></a> type."], "generic.strides": ["Tuple of bytes steps in each dimension."], "numpy.generic.strides": ["Tuple of bytes steps in each dimension."], "generic.ndim": ["The number of array dimensions."], "numpy.generic.ndim": ["The number of array dimensions."], "generic.data": ["Pointer to start of data."], "numpy.generic.data": ["Pointer to start of data."], "generic.size": ["The number of elements in the gentype."], "numpy.generic.size": ["The number of elements in the gentype."], "generic.itemsize": ["The length of one element in bytes."], "numpy.generic.itemsize": ["The length of one element in bytes."], "generic.base": ["Scalar attribute identical to the corresponding array attribute."], "numpy.generic.base": ["Scalar attribute identical to the corresponding array attribute."], "generic.dtype": ["Get array data-descriptor."], "numpy.generic.dtype": ["Get array data-descriptor."], "generic.real": ["The real part of the scalar."], "numpy.generic.real": ["The real part of the scalar."], "generic.imag": ["The imaginary part of the scalar."], "numpy.generic.imag": ["The imaginary part of the scalar."], "generic.flat": ["A 1-D view of the scalar."], "numpy.generic.flat": ["A 1-D view of the scalar."], "generic.T": ["Scalar attribute identical to the corresponding array attribute."], "numpy.generic.T": ["Scalar attribute identical to the corresponding array attribute."], "__array_interface__": ["Array protocol: Python side"], "generic.__array_interface__": ["Array protocol: Python side"], "numpy.generic.__array_interface__": ["Array protocol: Python side"], "__array_struct__": ["Array protocol: struct"], "generic.__array_struct__": ["Array protocol: struct"], "numpy.generic.__array_struct__": ["Array protocol: struct"], "__array_priority__": ["Array priority."], "generic.__array_priority__": ["Array priority."], "numpy.generic.__array_priority__": ["Array priority."], "generic.__array_wrap__": ["sc.__array_wrap__(obj) return scalar from array"], "numpy.generic.__array_wrap__": ["sc.__array_wrap__(obj) return scalar from array"], "generic.__array__": ["sc.__array__(dtype) return 0-dim array from scalar with specified dtype"], "numpy.generic.__array__": ["sc.__array__(dtype) return 0-dim array from scalar with specified dtype"], "generic.squeeze": ["Scalar method identical to the corresponding array attribute."], "numpy.generic.squeeze": ["Scalar method identical to the corresponding array attribute."], "generic.byteswap": ["Scalar method identical to the corresponding array attribute."], "numpy.generic.byteswap": ["Scalar method identical to the corresponding array attribute."], "generic.__reduce__": ["Helper for pickle."], "numpy.generic.__reduce__": ["Helper for pickle."], "setflags": ["Scalar method identical to the corresponding array attribute."], "generic.setflags": ["Scalar method identical to the corresponding array attribute."], "numpy.generic.setflags": ["Scalar method identical to the corresponding array attribute."], "number.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"../arrays.scalars.html#numpy.number\" title=\"numpy.number\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">number</span></code></a> type."], "numpy.number.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"../arrays.scalars.html#numpy.number\" title=\"numpy.number\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">number</span></code></a> type."], "kind": ["A character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data."], "dtype.kind": ["A character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data."], "numpy.dtype.kind": ["A character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data."], "char": ["A unique character code for each of the 21 different built-in types."], "dtype.char": ["A unique character code for each of the 21 different built-in types."], "numpy.dtype.char": ["A unique character code for each of the 21 different built-in types."], "num": ["A unique number for each of the 21 different built-in types."], "dtype.num": ["A unique number for each of the 21 different built-in types."], "numpy.dtype.num": ["A unique number for each of the 21 different built-in types."], "str": ["The array-protocol typestring of this data-type object."], "dtype.str": ["The array-protocol typestring of this data-type object."], "numpy.dtype.str": ["The array-protocol typestring of this data-type object."], "dtype.name": ["A bit-width name for this data-type."], "numpy.dtype.name": ["A bit-width name for this data-type."], "dtype.itemsize": ["The element size of this data-type object."], "numpy.dtype.itemsize": ["The element size of this data-type object."], "byteorder": ["A character indicating the byte-order of this data-type object."], "dtype.byteorder": ["A character indicating the byte-order of this data-type object."], "numpy.dtype.byteorder": ["A character indicating the byte-order of this data-type object."], "fields": ["Dictionary of named fields defined for this data type, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code>."], "dtype.fields": ["Dictionary of named fields defined for this data type, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code>."], "numpy.dtype.fields": ["Dictionary of named fields defined for this data type, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code>."], "dtype.names": ["Ordered list of field names, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> if there are no fields."], "numpy.dtype.names": ["Ordered list of field names, or <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> if there are no fields."], "dtype.flags": ["Bit-flags describing how this data type is to be interpreted."], "numpy.dtype.flags": ["Bit-flags describing how this data type is to be interpreted."], "isbuiltin": ["Integer indicating how this dtype relates to the built-in dtypes."], "dtype.isbuiltin": ["Integer indicating how this dtype relates to the built-in dtypes."], "numpy.dtype.isbuiltin": ["Integer indicating how this dtype relates to the built-in dtypes."], "descr": ["<em class=\"xref py py-obj\">__array_interface__</em> description of the data-type."], "dtype.descr": ["<em class=\"xref py py-obj\">__array_interface__</em> description of the data-type."], "numpy.dtype.descr": ["<em class=\"xref py py-obj\">__array_interface__</em> description of the data-type."], "alignment": ["The required alignment (bytes) of this data-type according to the compiler."], "dtype.alignment": ["The required alignment (bytes) of this data-type according to the compiler."], "numpy.dtype.alignment": ["The required alignment (bytes) of this data-type according to the compiler."], "metadata": ["Either <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> or a readonly dictionary of metadata (mappingproxy)."], "dtype.metadata": ["Either <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> or a readonly dictionary of metadata (mappingproxy)."], "numpy.dtype.metadata": ["Either <code class=\"docutils literal notranslate\"><span class=\"pre\">None</span></code> or a readonly dictionary of metadata (mappingproxy)."], "dtype.newbyteorder": ["Return a new dtype with a different byte order."], "numpy.dtype.newbyteorder": ["Return a new dtype with a different byte order."], "dtype.__reduce__": ["Helper for pickle."], "numpy.dtype.__reduce__": ["Helper for pickle."], "dtype.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.dtype.html#numpy.dtype\" title=\"numpy.dtype\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></a> type."], "numpy.dtype.__class_getitem__": ["Return a parametrized wrapper around the <a class=\"reference internal\" href=\"numpy.dtype.html#numpy.dtype\" title=\"numpy.dtype\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">dtype</span></code></a> type."], "dtype.__ge__": ["Return self&gt;=value."], "numpy.dtype.__ge__": ["Return self&gt;=value."], "dtype.__gt__": ["Return self&gt;value."], "numpy.dtype.__gt__": ["Return self&gt;value."], "dtype.__le__": ["Return self&lt;=value."], "numpy.dtype.__le__": ["Return self&lt;=value."], "dtype.__lt__": ["Return self&lt;value."], "numpy.dtype.__lt__": ["Return self&lt;value."], "eye": ["Return a 2-D array with ones on the diagonal and zeros elsewhere."], "numpy.eye": ["Return a 2-D array with ones on the diagonal and zeros elsewhere."], "identity": ["Return the identity array."], "numpy.identity": ["Return the identity array."], "ones": ["Return a new array of given shape and type, filled with ones."], "numpy.ones": ["Return a new array of given shape and type, filled with ones."], "ones_like": ["Return an array of ones with the same shape and type as a given array."], "numpy.ones_like": ["Return an array of ones with the same shape and type as a given array."], "zeros": ["Return a new array of given shape and type, filled with zeros."], "numpy.zeros": ["Return a new array of given shape and type, filled with zeros."], "zeros_like": ["Return an array of zeros with the same shape and type as a given array."], "numpy.zeros_like": ["Return an array of zeros with the same shape and type as a given array."], "full": ["Return a new array of given shape and type, filled with <em class=\"xref py py-obj\">fill_value</em>."], "numpy.full": ["Return a new array of given shape and type, filled with <em class=\"xref py py-obj\">fill_value</em>."], "full_like": ["Return a full array with the same shape and type as a given array."], "numpy.full_like": ["Return a full array with the same shape and type as a given array."], "numpy.array": ["Create an array."], "asarray": ["Convert the input to an array."], "numpy.asarray": ["Convert the input to an array."], "asanyarray": ["Convert the input to an ndarray, but pass ndarray subclasses through."], "numpy.asanyarray": ["Convert the input to an ndarray, but pass ndarray subclasses through."], "ascontiguousarray": ["Return a contiguous array (ndim &gt;= 1) in memory (C order)."], "numpy.ascontiguousarray": ["Return a contiguous array (ndim &gt;= 1) in memory (C order)."], "asmatrix": ["Interpret the input as a matrix."], "numpy.asmatrix": ["Interpret the input as a matrix."], "numpy.copy": ["Return an array copy of the given object."], "frombuffer": ["Interpret a buffer as a 1-dimensional array."], "numpy.frombuffer": ["Interpret a buffer as a 1-dimensional array."], "fromfile": ["Construct an array from data in a text or binary file.", "Create an array from binary file data"], "numpy.fromfile": ["Construct an array from data in a text or binary file."], "fromfunction": ["Construct an array by executing a function over each coordinate."], "numpy.fromfunction": ["Construct an array by executing a function over each coordinate."], "fromiter": ["Create a new 1-dimensional array from an iterable object."], "numpy.fromiter": ["Create a new 1-dimensional array from an iterable object."], "fromstring": ["A new 1-D array initialized from text data in a string.", "Create a record array from binary data"], "numpy.fromstring": ["A new 1-D array initialized from text data in a string."], "loadtxt": ["Load data from a text file."], "numpy.loadtxt": ["Load data from a text file."], "records.array": ["Construct a record array from a wide-variety of objects."], "core.records.array": ["Construct a record array from a wide-variety of objects."], "numpy.core.records.array": ["Construct a record array from a wide-variety of objects."], "fromarrays": ["Create a record array from a (flat) list of arrays"], "records.fromarrays": ["Create a record array from a (flat) list of arrays"], "core.records.fromarrays": ["Create a record array from a (flat) list of arrays"], "numpy.core.records.fromarrays": ["Create a record array from a (flat) list of arrays"], "fromrecords": ["Create a recarray from a list of records in text form."], "records.fromrecords": ["Create a recarray from a list of records in text form."], "core.records.fromrecords": ["Create a recarray from a list of records in text form."], "numpy.core.records.fromrecords": ["Create a recarray from a list of records in text form."], "records.fromstring": ["Create a record array from binary data"], "core.records.fromstring": ["Create a record array from binary data"], "numpy.core.records.fromstring": ["Create a record array from binary data"], "records.fromfile": ["Create an array from binary file data"], "core.records.fromfile": ["Create an array from binary file data"], "numpy.core.records.fromfile": ["Create an array from binary file data"], "defchararray.array": ["Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "core.defchararray.array": ["Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "numpy.core.defchararray.array": ["Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "arange": ["Return evenly spaced values within a given interval."], "numpy.arange": ["Return evenly spaced values within a given interval."], "linspace": ["Return evenly spaced numbers over a specified interval."], "numpy.linspace": ["Return evenly spaced numbers over a specified interval."], "logspace": ["Return numbers spaced evenly on a log scale."], "numpy.logspace": ["Return numbers spaced evenly on a log scale."], "geomspace": ["Return numbers spaced evenly on a log scale (a geometric progression)."], "numpy.geomspace": ["Return numbers spaced evenly on a log scale (a geometric progression)."], "meshgrid": ["Return coordinate matrices from coordinate vectors."], "numpy.meshgrid": ["Return coordinate matrices from coordinate vectors."], "mgrid": ["<em class=\"xref py py-obj\">nd_grid</em> instance which returns a dense multi-dimensional \u201cmeshgrid\u201d."], "numpy.mgrid": ["<em class=\"xref py py-obj\">nd_grid</em> instance which returns a dense multi-dimensional \u201cmeshgrid\u201d."], "ogrid": ["<em class=\"xref py py-obj\">nd_grid</em> instance which returns an open multi-dimensional \u201cmeshgrid\u201d."], "numpy.ogrid": ["<em class=\"xref py py-obj\">nd_grid</em> instance which returns an open multi-dimensional \u201cmeshgrid\u201d."], "diag": ["Extract a diagonal or construct a diagonal array."], "numpy.diag": ["Extract a diagonal or construct a diagonal array."], "diagflat": ["Create a two-dimensional array with the flattened input as a diagonal."], "numpy.diagflat": ["Create a two-dimensional array with the flattened input as a diagonal."], "tri": ["An array with ones at and below the given diagonal and zeros elsewhere."], "numpy.tri": ["An array with ones at and below the given diagonal and zeros elsewhere."], "tril": ["Lower triangle of an array."], "numpy.tril": ["Lower triangle of an array."], "triu": ["Upper triangle of an array."], "numpy.triu": ["Upper triangle of an array."], "vander": ["Generate a Vandermonde matrix."], "numpy.vander": ["Generate a Vandermonde matrix."], "mat": ["Interpret the input as a matrix."], "numpy.mat": ["Interpret the input as a matrix."], "bmat": ["Build a matrix object from a string, nested sequence, or array."], "numpy.bmat": ["Build a matrix object from a string, nested sequence, or array."], "numpy.reshape": ["Gives a new shape to an array without changing its data."], "numpy.ravel": ["Return a contiguous flattened array."], "moveaxis": ["Move axes of an array to new positions."], "numpy.moveaxis": ["Move axes of an array to new positions."], "rollaxis": ["Roll the specified axis backwards, until it lies in a given position."], "numpy.rollaxis": ["Roll the specified axis backwards, until it lies in a given position."], "numpy.swapaxes": ["Interchange two axes of an array."], "numpy.transpose": ["Reverse or permute the axes of an array; returns the modified array."], "atleast_1d": ["Convert inputs to arrays with at least one dimension."], "numpy.atleast_1d": ["Convert inputs to arrays with at least one dimension."], "atleast_2d": ["View inputs as arrays with at least two dimensions."], "numpy.atleast_2d": ["View inputs as arrays with at least two dimensions."], "atleast_3d": ["View inputs as arrays with at least three dimensions."], "numpy.atleast_3d": ["View inputs as arrays with at least three dimensions."], "broadcast": ["Produce an object that mimics broadcasting."], "numpy.broadcast": ["Produce an object that mimics broadcasting."], "broadcast_to": ["Broadcast an array to a new shape."], "numpy.broadcast_to": ["Broadcast an array to a new shape."], "broadcast_arrays": ["Broadcast any number of arrays against each other."], "numpy.broadcast_arrays": ["Broadcast any number of arrays against each other."], "expand_dims": ["Expand the shape of an array."], "numpy.expand_dims": ["Expand the shape of an array."], "numpy.squeeze": ["Remove axes of length one from <em class=\"xref py py-obj\">a</em>."], "asfarray": ["Return an array converted to a float type."], "numpy.asfarray": ["Return an array converted to a float type."], "asfortranarray": ["Return an array (ndim &gt;= 1) laid out in Fortran order in memory."], "numpy.asfortranarray": ["Return an array (ndim &gt;= 1) laid out in Fortran order in memory."], "asarray_chkfinite": ["Convert the input to an array, checking for NaNs or Infs."], "numpy.asarray_chkfinite": ["Convert the input to an array, checking for NaNs or Infs."], "require": ["Return an ndarray of the provided type that satisfies requirements."], "numpy.require": ["Return an ndarray of the provided type that satisfies requirements."], "concatenate": ["Join a sequence of arrays along an existing axis."], "numpy.concatenate": ["Join a sequence of arrays along an existing axis."], "numpy.stack": ["Join a sequence of arrays along a new axis."], "block": ["Assemble an nd-array from nested lists of blocks."], "numpy.block": ["Assemble an nd-array from nested lists of blocks."], "vstack": ["Stack arrays in sequence vertically (row wise)."], "numpy.vstack": ["Stack arrays in sequence vertically (row wise)."], "hstack": ["Stack arrays in sequence horizontally (column wise)."], "numpy.hstack": ["Stack arrays in sequence horizontally (column wise)."], "dstack": ["Stack arrays in sequence depth wise (along third axis)."], "numpy.dstack": ["Stack arrays in sequence depth wise (along third axis)."], "column_stack": ["Stack 1-D arrays as columns into a 2-D array."], "numpy.column_stack": ["Stack 1-D arrays as columns into a 2-D array."], "row_stack": ["Stack arrays in sequence vertically (row wise)."], "numpy.row_stack": ["Stack arrays in sequence vertically (row wise)."], "numpy.split": ["Split an array into multiple sub-arrays as views into <em class=\"xref py py-obj\">ary</em>."], "array_split": ["Split an array into multiple sub-arrays."], "numpy.array_split": ["Split an array into multiple sub-arrays."], "dsplit": ["Split array into multiple sub-arrays along the 3rd axis (depth)."], "numpy.dsplit": ["Split array into multiple sub-arrays along the 3rd axis (depth)."], "hsplit": ["Split an array into multiple sub-arrays horizontally (column-wise)."], "numpy.hsplit": ["Split an array into multiple sub-arrays horizontally (column-wise)."], "vsplit": ["Split an array into multiple sub-arrays vertically (row-wise)."], "numpy.vsplit": ["Split an array into multiple sub-arrays vertically (row-wise)."], "tile": ["Construct an array by repeating A the number of times given by reps."], "numpy.tile": ["Construct an array by repeating A the number of times given by reps."], "numpy.repeat": ["Repeat elements of an array."], "numpy.insert": ["Insert values along the given axis before the given indices."], "numpy.append": ["Append values to the end of an array."], "numpy.resize": ["Return a new array with the specified shape."], "trim_zeros": ["Trim the leading and/or trailing zeros from a 1-D array or sequence."], "numpy.trim_zeros": ["Trim the leading and/or trailing zeros from a 1-D array or sequence."], "numpy.unique": ["Find the unique elements of an array."], "flip": ["Reverse the order of elements in an array along the given axis."], "numpy.flip": ["Reverse the order of elements in an array along the given axis."], "fliplr": ["Reverse the order of elements along axis 1 (left/right)."], "numpy.fliplr": ["Reverse the order of elements along axis 1 (left/right)."], "flipud": ["Reverse the order of elements along axis 0 (up/down)."], "numpy.flipud": ["Reverse the order of elements along axis 0 (up/down)."], "roll": ["Roll array elements along a given axis."], "numpy.roll": ["Roll array elements along a given axis."], "rot90": ["Rotate an array by 90 degrees in the plane specified by axes."], "numpy.rot90": ["Rotate an array by 90 degrees in the plane specified by axes."], "bitwise_xor": ["Compute the bit-wise XOR of two arrays element-wise."], "numpy.bitwise_xor": ["Compute the bit-wise XOR of two arrays element-wise."], "invert": ["Compute bit-wise inversion, or bit-wise NOT, element-wise."], "numpy.invert": ["Compute bit-wise inversion, or bit-wise NOT, element-wise."], "left_shift": ["Shift the bits of an integer to the left."], "numpy.left_shift": ["Shift the bits of an integer to the left."], "right_shift": ["Shift the bits of an integer to the right."], "numpy.right_shift": ["Shift the bits of an integer to the right."], "packbits": ["Packs the elements of a binary-valued array into bits in a uint8 array."], "numpy.packbits": ["Packs the elements of a binary-valued array into bits in a uint8 array."], "unpackbits": ["Unpacks elements of a uint8 array into a binary-valued output array."], "numpy.unpackbits": ["Unpacks elements of a uint8 array into a binary-valued output array."], "binary_repr": ["Return the binary representation of the input number as a string."], "numpy.binary_repr": ["Return the binary representation of the input number as a string."], "char.decode": ["Calls <em class=\"xref py py-obj\">str.decode</em> element-wise."], "numpy.char.decode": ["Calls <em class=\"xref py py-obj\">str.decode</em> element-wise."], "char.encode": ["Calls <a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str.encode\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">str.encode</span></code></a> element-wise."], "numpy.char.encode": ["Calls <a class=\"reference external\" href=\"https://docs.python.org/3/library/stdtypes.html#str.encode\" title=\"(in Python v3.10)\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">str.encode</span></code></a> element-wise."], "char.lower": ["Return an array with the elements converted to lowercase."], "numpy.char.lower": ["Return an array with the elements converted to lowercase."], "char.partition": ["Partition each element in <em class=\"xref py py-obj\">a</em> around <em class=\"xref py py-obj\">sep</em>."], "numpy.char.partition": ["Partition each element in <em class=\"xref py py-obj\">a</em> around <em class=\"xref py py-obj\">sep</em>."], "char.rpartition": ["Partition (split) each element around the right-most separator."], "numpy.char.rpartition": ["Partition (split) each element around the right-most separator."], "char.title": ["Return element-wise title cased version of string or unicode."], "numpy.char.title": ["Return element-wise title cased version of string or unicode."], "char.upper": ["Return an array with the elements converted to uppercase."], "numpy.char.upper": ["Return an array with the elements converted to uppercase."], "char.zfill": ["Return the numeric string left-filled with zeros"], "numpy.char.zfill": ["Return the numeric string left-filled with zeros"], "equal": ["Return (x1 == x2) element-wise."], "char.equal": ["Return (x1 == x2) element-wise."], "numpy.char.equal": ["Return (x1 == x2) element-wise."], "not_equal": ["Return (x1 != x2) element-wise."], "char.not_equal": ["Return (x1 != x2) element-wise."], "numpy.char.not_equal": ["Return (x1 != x2) element-wise."], "greater_equal": ["Return (x1 &gt;= x2) element-wise."], "char.greater_equal": ["Return (x1 &gt;= x2) element-wise."], "numpy.char.greater_equal": ["Return (x1 &gt;= x2) element-wise."], "less_equal": ["Return (x1 &lt;= x2) element-wise."], "char.less_equal": ["Return (x1 &lt;= x2) element-wise."], "numpy.char.less_equal": ["Return (x1 &lt;= x2) element-wise."], "greater": ["Return (x1 &gt; x2) element-wise."], "char.greater": ["Return (x1 &gt; x2) element-wise."], "numpy.char.greater": ["Return (x1 &gt; x2) element-wise."], "less": ["Return (x1 &lt; x2) element-wise."], "char.less": ["Return (x1 &lt; x2) element-wise."], "numpy.char.less": ["Return (x1 &lt; x2) element-wise."], "char.index": ["Like <a class=\"reference internal\" href=\"numpy.char.find.html#numpy.char.find\" title=\"numpy.char.find\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">find</span></code></a>, but raises <em class=\"xref py py-obj\">ValueError</em> when the substring is not found."], "numpy.char.index": ["Like <a class=\"reference internal\" href=\"numpy.char.find.html#numpy.char.find\" title=\"numpy.char.find\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">find</span></code></a>, but raises <em class=\"xref py py-obj\">ValueError</em> when the substring is not found."], "str_len": ["Return len(a) element-wise."], "char.str_len": ["Return len(a) element-wise."], "numpy.char.str_len": ["Return len(a) element-wise."], "char.array": ["Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "numpy.char.array": ["Create a <a class=\"reference internal\" href=\"numpy.chararray.html#numpy.chararray\" title=\"numpy.chararray\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">chararray</span></code></a>."], "chararray": ["Provides a convenient view on arrays of string and unicode values."], "char.chararray": ["Provides a convenient view on arrays of string and unicode values."], "numpy.char.chararray": ["Provides a convenient view on arrays of string and unicode values."], "is_busday": ["Calculates which of the given dates are valid days, and which are not."], "numpy.is_busday": ["Calculates which of the given dates are valid days, and which are not."], "common_type": ["Return a scalar type which is common to the input arrays."], "numpy.common_type": ["Return a scalar type which is common to the input arrays."], "obj2sctype": ["Return the scalar dtype or NumPy equivalent of Python type of an object."], "numpy.obj2sctype": ["Return the scalar dtype or NumPy equivalent of Python type of an object."], "numpy.dtype": ["Create a data type object."], "format_parser": ["Class to convert formats, names, titles description to a dtype."], "numpy.format_parser": ["Class to convert formats, names, titles description to a dtype."], "finfo": ["Machine limits for floating point types."], "numpy.finfo": ["Machine limits for floating point types."], "iinfo": ["Machine limits for integer types."], "numpy.iinfo": ["Machine limits for integer types."], "MachAr": ["Diagnosing machine parameters."], "numpy.MachAr": ["Diagnosing machine parameters."], "issctype": ["Determines whether the given object represents a scalar data-type."], "numpy.issctype": ["Determines whether the given object represents a scalar data-type."], "issubdtype": ["Returns True if first argument is a typecode lower/equal in type hierarchy."], "numpy.issubdtype": ["Returns True if first argument is a typecode lower/equal in type hierarchy."], "issubsctype": ["Determine if the first argument is a subclass of the second argument."], "numpy.issubsctype": ["Determine if the first argument is a subclass of the second argument."], "issubclass_": ["Determine if a class is a subclass of a second class."], "numpy.issubclass_": ["Determine if a class is a subclass of a second class."], "find_common_type": ["Determine common type following standard coercion rules."], "numpy.find_common_type": ["Determine common type following standard coercion rules."], "typename": ["Return a description for the given data type code."], "numpy.typename": ["Return a description for the given data type code."], "sctype2char": ["Return the string representation of a scalar dtype."], "numpy.sctype2char": ["Return the string representation of a scalar dtype."], "maximum_sctype": ["Return the scalar type of highest precision of the same kind as the input."], "numpy.maximum_sctype": ["Return the scalar type of highest precision of the same kind as the input."], "fft2": ["Compute the 2-dimensional discrete Fourier Transform."], "fft.fft2": ["Compute the 2-dimensional discrete Fourier Transform."], "numpy.fft.fft2": ["Compute the 2-dimensional discrete Fourier Transform."], "ifft2": ["Compute the 2-dimensional inverse discrete Fourier Transform."], "fft.ifft2": ["Compute the 2-dimensional inverse discrete Fourier Transform."], "numpy.fft.ifft2": ["Compute the 2-dimensional inverse discrete Fourier Transform."], "fftn": ["Compute the N-dimensional discrete Fourier Transform."], "fft.fftn": ["Compute the N-dimensional discrete Fourier Transform."], "numpy.fft.fftn": ["Compute the N-dimensional discrete Fourier Transform."], "ifftn": ["Compute the N-dimensional inverse discrete Fourier Transform."], "fft.ifftn": ["Compute the N-dimensional inverse discrete Fourier Transform."], "numpy.fft.ifftn": ["Compute the N-dimensional inverse discrete Fourier Transform."], "rfft": ["Compute the one-dimensional discrete Fourier Transform for real input."], "fft.rfft": ["Compute the one-dimensional discrete Fourier Transform for real input."], "numpy.fft.rfft": ["Compute the one-dimensional discrete Fourier Transform for real input."], "irfft": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft.html#numpy.fft.rfft\" title=\"numpy.fft.rfft\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft</span></code></a>."], "fft.irfft": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft.html#numpy.fft.rfft\" title=\"numpy.fft.rfft\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft</span></code></a>."], "numpy.fft.irfft": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft.html#numpy.fft.rfft\" title=\"numpy.fft.rfft\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft</span></code></a>."], "rfft2": ["Compute the 2-dimensional FFT of a real array."], "fft.rfft2": ["Compute the 2-dimensional FFT of a real array."], "numpy.fft.rfft2": ["Compute the 2-dimensional FFT of a real array."], "irfft2": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft2.html#numpy.fft.rfft2\" title=\"numpy.fft.rfft2\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft2</span></code></a>."], "fft.irfft2": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft2.html#numpy.fft.rfft2\" title=\"numpy.fft.rfft2\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft2</span></code></a>."], "numpy.fft.irfft2": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfft2.html#numpy.fft.rfft2\" title=\"numpy.fft.rfft2\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfft2</span></code></a>."], "rfftn": ["Compute the N-dimensional discrete Fourier Transform for real input."], "fft.rfftn": ["Compute the N-dimensional discrete Fourier Transform for real input."], "numpy.fft.rfftn": ["Compute the N-dimensional discrete Fourier Transform for real input."], "irfftn": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfftn.html#numpy.fft.rfftn\" title=\"numpy.fft.rfftn\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfftn</span></code></a>."], "fft.irfftn": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfftn.html#numpy.fft.rfftn\" title=\"numpy.fft.rfftn\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfftn</span></code></a>."], "numpy.fft.irfftn": ["Computes the inverse of <a class=\"reference internal\" href=\"numpy.fft.rfftn.html#numpy.fft.rfftn\" title=\"numpy.fft.rfftn\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">rfftn</span></code></a>."], "ihfft": ["Compute the inverse FFT of a signal that has Hermitian symmetry."], "fft.ihfft": ["Compute the inverse FFT of a signal that has Hermitian symmetry."], "numpy.fft.ihfft": ["Compute the inverse FFT of a signal that has Hermitian symmetry."], "fftfreq": ["Return the Discrete Fourier Transform sample frequencies."], "fft.fftfreq": ["Return the Discrete Fourier Transform sample frequencies."], "numpy.fft.fftfreq": ["Return the Discrete Fourier Transform sample frequencies."], "fftshift": ["Shift the zero-frequency component to the center of the spectrum."], "fft.fftshift": ["Shift the zero-frequency component to the center of the spectrum."], "numpy.fft.fftshift": ["Shift the zero-frequency component to the center of the spectrum."], "savez": ["Save several arrays into a single file in uncompressed <code class=\"docutils literal notranslate\"><span class=\"pre\">.npz</span></code> format."], "numpy.savez": ["Save several arrays into a single file in uncompressed <code class=\"docutils literal notranslate\"><span class=\"pre\">.npz</span></code> format."], "savez_compressed": ["Save several arrays into a single file in compressed <code class=\"docutils literal notranslate\"><span class=\"pre\">.npz</span></code> format."], "numpy.savez_compressed": ["Save several arrays into a single file in compressed <code class=\"docutils literal notranslate\"><span class=\"pre\">.npz</span></code> format."], "savetxt": ["Save an array to a text file."], "numpy.savetxt": ["Save an array to a text file."], "genfromtxt": ["Load data from a text file, with missing values handled as specified."], "numpy.genfromtxt": ["Load data from a text file, with missing values handled as specified."], "fromregex": ["Construct an array from a text file, using regular expression parsing."], "numpy.fromregex": ["Construct an array from a text file, using regular expression parsing."], "array2string": ["Return a string representation of an array."], "numpy.array2string": ["Return a string representation of an array."], "array_repr": ["Return the string representation of an array."], "numpy.array_repr": ["Return the string representation of an array."], "array_str": ["Return a string representation of the data in an array."], "numpy.array_str": ["Return a string representation of the data in an array."], "format_float_positional": ["Format a floating-point scalar as a decimal string in positional notation."], "numpy.format_float_positional": ["Format a floating-point scalar as a decimal string in positional notation."], "format_float_scientific": ["Format a floating-point scalar as a decimal string in scientific notation."], "numpy.format_float_scientific": ["Format a floating-point scalar as a decimal string in scientific notation."], "memmap": ["Create a memory-map to an array stored in a <em>binary</em> file on disk."], "numpy.memmap": ["Create a memory-map to an array stored in a <em>binary</em> file on disk."], "open_memmap": ["Open a .npy file as a memory-mapped array."], "format.open_memmap": ["Open a .npy file as a memory-mapped array."], "lib.format.open_memmap": ["Open a .npy file as a memory-mapped array."], "numpy.lib.format.open_memmap": ["Open a .npy file as a memory-mapped array."], "set_printoptions": ["Set printing options."], "numpy.set_printoptions": ["Set printing options."], "get_printoptions": ["Return the current print options."], "numpy.get_printoptions": ["Return the current print options."], "set_string_function": ["Set a Python function to be used when pretty printing arrays."], "numpy.set_string_function": ["Set a Python function to be used when pretty printing arrays."], "printoptions": ["Context manager for setting print options."], "numpy.printoptions": ["Context manager for setting print options."], "base_repr": ["Return a string representation of a number in the given base system."], "numpy.base_repr": ["Return a string representation of a number in the given base system."], "DataSource": ["A generic data source file (file, http, ftp, \u2026)."], "numpy.DataSource": ["A generic data source file (file, http, ftp, \u2026)."], "lib.format": ["Binary serialization"], "numpy.lib.format": ["Binary serialization"], "BaseEstimator": ["Base class for all estimators in scikit-learn."], "base.BaseEstimator": ["Base class for all estimators in scikit-learn."], "sklearn.base.BaseEstimator": ["Base class for all estimators in scikit-learn."], "BiclusterMixin": ["Mixin class for all bicluster estimators in scikit-learn."], "base.BiclusterMixin": ["Mixin class for all bicluster estimators in scikit-learn."], "sklearn.base.BiclusterMixin": ["Mixin class for all bicluster estimators in scikit-learn."], "ClassifierMixin": ["Mixin class for all classifiers in scikit-learn."], "base.ClassifierMixin": ["Mixin class for all classifiers in scikit-learn."], "sklearn.base.ClassifierMixin": ["Mixin class for all classifiers in scikit-learn."], "ClusterMixin": ["Mixin class for all cluster estimators in scikit-learn."], "base.ClusterMixin": ["Mixin class for all cluster estimators in scikit-learn."], "sklearn.base.ClusterMixin": ["Mixin class for all cluster estimators in scikit-learn."], "DensityMixin": ["Mixin class for all density estimators in scikit-learn."], "base.DensityMixin": ["Mixin class for all density estimators in scikit-learn."], "sklearn.base.DensityMixin": ["Mixin class for all density estimators in scikit-learn."], "RegressorMixin": ["Mixin class for all regression estimators in scikit-learn."], "base.RegressorMixin": ["Mixin class for all regression estimators in scikit-learn."], "sklearn.base.RegressorMixin": ["Mixin class for all regression estimators in scikit-learn."], "TransformerMixin": ["Mixin class for all transformers in scikit-learn."], "base.TransformerMixin": ["Mixin class for all transformers in scikit-learn."], "sklearn.base.TransformerMixin": ["Mixin class for all transformers in scikit-learn."], "SelectorMixin": ["Transformer mixin that performs feature selection given a support mask"], "feature_selection.SelectorMixin": ["Transformer mixin that performs feature selection given a support mask"], "sklearn.feature_selection.SelectorMixin": ["Transformer mixin that performs feature selection given a support mask"], "clone": ["Construct a new unfitted estimator with the same parameters."], "base.clone": ["Construct a new unfitted estimator with the same parameters."], "sklearn.base.clone": ["Construct a new unfitted estimator with the same parameters."], "is_classifier": ["Return True if the given estimator is (probably) a classifier."], "base.is_classifier": ["Return True if the given estimator is (probably) a classifier."], "sklearn.base.is_classifier": ["Return True if the given estimator is (probably) a classifier."], "is_regressor": ["Return True if the given estimator is (probably) a regressor."], "base.is_regressor": ["Return True if the given estimator is (probably) a regressor."], "sklearn.base.is_regressor": ["Return True if the given estimator is (probably) a regressor."], "config_context": ["Context manager for global scikit-learn configuration."], "sklearn.config_context": ["Context manager for global scikit-learn configuration."], "set_config": ["Set global scikit-learn configuration"], "sklearn.set_config": ["Set global scikit-learn configuration"], "sklearn.show_versions": ["Print useful debugging information\""], "CalibratedClassifierCV": ["Probability calibration with isotonic regression or logistic regression."], "calibration.CalibratedClassifierCV": ["Probability calibration with isotonic regression or logistic regression."], "sklearn.calibration.CalibratedClassifierCV": ["Probability calibration with isotonic regression or logistic regression."], "calibration_curve": ["Compute true and predicted probabilities for a calibration curve."], "calibration.calibration_curve": ["Compute true and predicted probabilities for a calibration curve."], "sklearn.calibration.calibration_curve": ["Compute true and predicted probabilities for a calibration curve."], "AffinityPropagation": ["Perform Affinity Propagation Clustering of data."], "cluster.AffinityPropagation": ["Perform Affinity Propagation Clustering of data."], "sklearn.cluster.AffinityPropagation": ["Perform Affinity Propagation Clustering of data."], "AgglomerativeClustering": ["Agglomerative Clustering."], "cluster.AgglomerativeClustering": ["Agglomerative Clustering."], "sklearn.cluster.AgglomerativeClustering": ["Agglomerative Clustering."], "Birch": ["Implements the BIRCH clustering algorithm."], "cluster.Birch": ["Implements the BIRCH clustering algorithm."], "sklearn.cluster.Birch": ["Implements the BIRCH clustering algorithm."], "DBSCAN": ["Perform DBSCAN clustering from vector array or distance matrix."], "cluster.DBSCAN": ["Perform DBSCAN clustering from vector array or distance matrix."], "sklearn.cluster.DBSCAN": ["Perform DBSCAN clustering from vector array or distance matrix."], "FeatureAgglomeration": ["Agglomerate features."], "cluster.FeatureAgglomeration": ["Agglomerate features."], "sklearn.cluster.FeatureAgglomeration": ["Agglomerate features."], "KMeans": ["K-Means clustering."], "cluster.KMeans": ["K-Means clustering."], "sklearn.cluster.KMeans": ["K-Means clustering."], "BisectingKMeans": ["Bisecting K-Means clustering."], "cluster.BisectingKMeans": ["Bisecting K-Means clustering."], "sklearn.cluster.BisectingKMeans": ["Bisecting K-Means clustering."], "MiniBatchKMeans": ["Mini-Batch K-Means clustering."], "cluster.MiniBatchKMeans": ["Mini-Batch K-Means clustering."], "sklearn.cluster.MiniBatchKMeans": ["Mini-Batch K-Means clustering."], "MeanShift": ["Mean shift clustering using a flat kernel."], "cluster.MeanShift": ["Mean shift clustering using a flat kernel."], "sklearn.cluster.MeanShift": ["Mean shift clustering using a flat kernel."], "OPTICS": ["Estimate clustering structure from vector array."], "cluster.OPTICS": ["Estimate clustering structure from vector array."], "sklearn.cluster.OPTICS": ["Estimate clustering structure from vector array."], "SpectralClustering": ["Apply clustering to a projection of the normalized Laplacian."], "cluster.SpectralClustering": ["Apply clustering to a projection of the normalized Laplacian."], "sklearn.cluster.SpectralClustering": ["Apply clustering to a projection of the normalized Laplacian."], "SpectralBiclustering": ["Spectral biclustering (Kluger, 2003)."], "cluster.SpectralBiclustering": ["Spectral biclustering (Kluger, 2003)."], "sklearn.cluster.SpectralBiclustering": ["Spectral biclustering (Kluger, 2003)."], "SpectralCoclustering": ["Spectral Co-Clustering algorithm (Dhillon, 2001)."], "cluster.SpectralCoclustering": ["Spectral Co-Clustering algorithm (Dhillon, 2001)."], "sklearn.cluster.SpectralCoclustering": ["Spectral Co-Clustering algorithm (Dhillon, 2001)."], "affinity_propagation": ["Perform Affinity Propagation Clustering of data."], "cluster.affinity_propagation": ["Perform Affinity Propagation Clustering of data."], "sklearn.cluster.affinity_propagation": ["Perform Affinity Propagation Clustering of data."], "cluster_optics_dbscan": ["Perform DBSCAN extraction for an arbitrary epsilon."], "cluster.cluster_optics_dbscan": ["Perform DBSCAN extraction for an arbitrary epsilon."], "sklearn.cluster.cluster_optics_dbscan": ["Perform DBSCAN extraction for an arbitrary epsilon."], "cluster_optics_xi": ["Automatically extract clusters according to the Xi-steep method."], "cluster.cluster_optics_xi": ["Automatically extract clusters according to the Xi-steep method."], "sklearn.cluster.cluster_optics_xi": ["Automatically extract clusters according to the Xi-steep method."], "compute_optics_graph": ["Compute the OPTICS reachability graph."], "cluster.compute_optics_graph": ["Compute the OPTICS reachability graph."], "sklearn.cluster.compute_optics_graph": ["Compute the OPTICS reachability graph."], "dbscan": ["Perform DBSCAN clustering from vector array or distance matrix."], "cluster.dbscan": ["Perform DBSCAN clustering from vector array or distance matrix."], "sklearn.cluster.dbscan": ["Perform DBSCAN clustering from vector array or distance matrix."], "estimate_bandwidth": ["Estimate the bandwidth to use with the mean-shift algorithm."], "cluster.estimate_bandwidth": ["Estimate the bandwidth to use with the mean-shift algorithm."], "sklearn.cluster.estimate_bandwidth": ["Estimate the bandwidth to use with the mean-shift algorithm."], "k_means": ["Perform K-means clustering algorithm."], "cluster.k_means": ["Perform K-means clustering algorithm."], "sklearn.cluster.k_means": ["Perform K-means clustering algorithm."], "kmeans_plusplus": ["Init n_clusters seeds according to k-means++."], "cluster.kmeans_plusplus": ["Init n_clusters seeds according to k-means++."], "sklearn.cluster.kmeans_plusplus": ["Init n_clusters seeds according to k-means++."], "mean_shift": ["Perform mean shift clustering of data using a flat kernel."], "cluster.mean_shift": ["Perform mean shift clustering of data using a flat kernel."], "sklearn.cluster.mean_shift": ["Perform mean shift clustering of data using a flat kernel."], "spectral_clustering": ["Apply clustering to a projection of the normalized Laplacian."], "cluster.spectral_clustering": ["Apply clustering to a projection of the normalized Laplacian."], "sklearn.cluster.spectral_clustering": ["Apply clustering to a projection of the normalized Laplacian."], "ward_tree": ["Ward clustering based on a Feature matrix."], "cluster.ward_tree": ["Ward clustering based on a Feature matrix."], "sklearn.cluster.ward_tree": ["Ward clustering based on a Feature matrix."], "ColumnTransformer": ["Applies transformers to columns of an array or pandas DataFrame."], "compose.ColumnTransformer": ["Applies transformers to columns of an array or pandas DataFrame."], "sklearn.compose.ColumnTransformer": ["Applies transformers to columns of an array or pandas DataFrame."], "TransformedTargetRegressor": ["Meta-estimator to regress on a transformed target."], "compose.TransformedTargetRegressor": ["Meta-estimator to regress on a transformed target."], "sklearn.compose.TransformedTargetRegressor": ["Meta-estimator to regress on a transformed target."], "make_column_transformer": ["Construct a ColumnTransformer from the given transformers."], "compose.make_column_transformer": ["Construct a ColumnTransformer from the given transformers."], "sklearn.compose.make_column_transformer": ["Construct a ColumnTransformer from the given transformers."], "make_column_selector": ["Create a callable to select columns to be used with ColumnTransformer."], "compose.make_column_selector": ["Create a callable to select columns to be used with ColumnTransformer."], "sklearn.compose.make_column_selector": ["Create a callable to select columns to be used with ColumnTransformer."], "EmpiricalCovariance": ["Maximum likelihood covariance estimator."], "covariance.EmpiricalCovariance": ["Maximum likelihood covariance estimator."], "sklearn.covariance.EmpiricalCovariance": ["Maximum likelihood covariance estimator."], "EllipticEnvelope": ["An object for detecting outliers in a Gaussian distributed dataset."], "covariance.EllipticEnvelope": ["An object for detecting outliers in a Gaussian distributed dataset."], "sklearn.covariance.EllipticEnvelope": ["An object for detecting outliers in a Gaussian distributed dataset."], "GraphicalLasso": ["Sparse inverse covariance estimation with an l1-penalized estimator."], "covariance.GraphicalLasso": ["Sparse inverse covariance estimation with an l1-penalized estimator."], "sklearn.covariance.GraphicalLasso": ["Sparse inverse covariance estimation with an l1-penalized estimator."], "GraphicalLassoCV": ["Sparse inverse covariance w/ cross-validated choice of the l1 penalty."], "covariance.GraphicalLassoCV": ["Sparse inverse covariance w/ cross-validated choice of the l1 penalty."], "sklearn.covariance.GraphicalLassoCV": ["Sparse inverse covariance w/ cross-validated choice of the l1 penalty."], "LedoitWolf": ["LedoitWolf Estimator."], "covariance.LedoitWolf": ["LedoitWolf Estimator."], "sklearn.covariance.LedoitWolf": ["LedoitWolf Estimator."], "MinCovDet": ["Minimum Covariance Determinant (MCD): robust estimator of covariance."], "covariance.MinCovDet": ["Minimum Covariance Determinant (MCD): robust estimator of covariance."], "sklearn.covariance.MinCovDet": ["Minimum Covariance Determinant (MCD): robust estimator of covariance."], "OAS": ["Oracle Approximating Shrinkage Estimator."], "covariance.OAS": ["Oracle Approximating Shrinkage Estimator."], "sklearn.covariance.OAS": ["Oracle Approximating Shrinkage Estimator."], "ShrunkCovariance": ["Covariance estimator with shrinkage."], "covariance.ShrunkCovariance": ["Covariance estimator with shrinkage."], "sklearn.covariance.ShrunkCovariance": ["Covariance estimator with shrinkage."], "empirical_covariance": ["Compute the Maximum likelihood covariance estimator."], "covariance.empirical_covariance": ["Compute the Maximum likelihood covariance estimator."], "sklearn.covariance.empirical_covariance": ["Compute the Maximum likelihood covariance estimator."], "graphical_lasso": ["L1-penalized covariance estimator."], "covariance.graphical_lasso": ["L1-penalized covariance estimator."], "sklearn.covariance.graphical_lasso": ["L1-penalized covariance estimator."], "ledoit_wolf": ["Estimate the shrunk Ledoit-Wolf covariance matrix."], "covariance.ledoit_wolf": ["Estimate the shrunk Ledoit-Wolf covariance matrix."], "sklearn.covariance.ledoit_wolf": ["Estimate the shrunk Ledoit-Wolf covariance matrix."], "oas": ["Estimate covariance with the Oracle Approximating Shrinkage algorithm."], "covariance.oas": ["Estimate covariance with the Oracle Approximating Shrinkage algorithm."], "sklearn.covariance.oas": ["Estimate covariance with the Oracle Approximating Shrinkage algorithm."], "shrunk_covariance": ["Calculate a covariance matrix shrunk on the diagonal."], "covariance.shrunk_covariance": ["Calculate a covariance matrix shrunk on the diagonal."], "sklearn.covariance.shrunk_covariance": ["Calculate a covariance matrix shrunk on the diagonal."], "CCA": ["Canonical Correlation Analysis, also known as \"Mode B\" PLS."], "cross_decomposition.CCA": ["Canonical Correlation Analysis, also known as \"Mode B\" PLS."], "sklearn.cross_decomposition.CCA": ["Canonical Correlation Analysis, also known as \"Mode B\" PLS."], "PLSCanonical": ["Partial Least Squares transformer and regressor."], "cross_decomposition.PLSCanonical": ["Partial Least Squares transformer and regressor."], "sklearn.cross_decomposition.PLSCanonical": ["Partial Least Squares transformer and regressor."], "PLSRegression": ["PLS regression."], "cross_decomposition.PLSRegression": ["PLS regression."], "sklearn.cross_decomposition.PLSRegression": ["PLS regression."], "PLSSVD": ["Partial Least Square SVD."], "cross_decomposition.PLSSVD": ["Partial Least Square SVD."], "sklearn.cross_decomposition.PLSSVD": ["Partial Least Square SVD."], "clear_data_home": ["Delete all the content of the data home cache."], "datasets.clear_data_home": ["Delete all the content of the data home cache."], "sklearn.datasets.clear_data_home": ["Delete all the content of the data home cache."], "dump_svmlight_file": ["Dump the dataset in svmlight / libsvm file format."], "datasets.dump_svmlight_file": ["Dump the dataset in svmlight / libsvm file format."], "sklearn.datasets.dump_svmlight_file": ["Dump the dataset in svmlight / libsvm file format."], "fetch_20newsgroups": ["Load the filenames and data from the 20 newsgroups dataset (classification)."], "datasets.fetch_20newsgroups": ["Load the filenames and data from the 20 newsgroups dataset (classification)."], "sklearn.datasets.fetch_20newsgroups": ["Load the filenames and data from the 20 newsgroups dataset (classification)."], "fetch_20newsgroups_vectorized": ["Load and vectorize the 20 newsgroups dataset (classification)."], "datasets.fetch_20newsgroups_vectorized": ["Load and vectorize the 20 newsgroups dataset (classification)."], "sklearn.datasets.fetch_20newsgroups_vectorized": ["Load and vectorize the 20 newsgroups dataset (classification)."], "fetch_california_housing": ["Load the California housing dataset (regression)."], "datasets.fetch_california_housing": ["Load the California housing dataset (regression)."], "sklearn.datasets.fetch_california_housing": ["Load the California housing dataset (regression)."], "fetch_covtype": ["Load the covertype dataset (classification)."], "datasets.fetch_covtype": ["Load the covertype dataset (classification)."], "sklearn.datasets.fetch_covtype": ["Load the covertype dataset (classification)."], "fetch_kddcup99": ["Load the kddcup99 dataset (classification)."], "datasets.fetch_kddcup99": ["Load the kddcup99 dataset (classification)."], "sklearn.datasets.fetch_kddcup99": ["Load the kddcup99 dataset (classification)."], "fetch_lfw_pairs": ["Load the Labeled Faces in the Wild (LFW) pairs dataset (classification)."], "datasets.fetch_lfw_pairs": ["Load the Labeled Faces in the Wild (LFW) pairs dataset (classification)."], "sklearn.datasets.fetch_lfw_pairs": ["Load the Labeled Faces in the Wild (LFW) pairs dataset (classification)."], "fetch_lfw_people": ["Load the Labeled Faces in the Wild (LFW) people dataset (classification)."], "datasets.fetch_lfw_people": ["Load the Labeled Faces in the Wild (LFW) people dataset (classification)."], "sklearn.datasets.fetch_lfw_people": ["Load the Labeled Faces in the Wild (LFW) people dataset (classification)."], "fetch_olivetti_faces": ["Load the Olivetti faces data-set from AT&T (classification)."], "datasets.fetch_olivetti_faces": ["Load the Olivetti faces data-set from AT&T (classification)."], "sklearn.datasets.fetch_olivetti_faces": ["Load the Olivetti faces data-set from AT&T (classification)."], "fetch_openml": ["Fetch dataset from openml by name or dataset id."], "datasets.fetch_openml": ["Fetch dataset from openml by name or dataset id."], "sklearn.datasets.fetch_openml": ["Fetch dataset from openml by name or dataset id."], "fetch_rcv1": ["Load the RCV1 multilabel dataset (classification)."], "datasets.fetch_rcv1": ["Load the RCV1 multilabel dataset (classification)."], "sklearn.datasets.fetch_rcv1": ["Load the RCV1 multilabel dataset (classification)."], "fetch_species_distributions": ["Loader for species distribution dataset from Phillips et."], "datasets.fetch_species_distributions": ["Loader for species distribution dataset from Phillips et."], "sklearn.datasets.fetch_species_distributions": ["Loader for species distribution dataset from Phillips et."], "get_data_home": ["Return the path of the scikit-learn data directory."], "datasets.get_data_home": ["Return the path of the scikit-learn data directory."], "sklearn.datasets.get_data_home": ["Return the path of the scikit-learn data directory."], "load_boston": ["DEPRECATED: load_boston is deprecated in 1.0 and will be removed in 1.2."], "datasets.load_boston": ["DEPRECATED: load_boston is deprecated in 1.0 and will be removed in 1.2."], "sklearn.datasets.load_boston": ["DEPRECATED: load_boston is deprecated in 1.0 and will be removed in 1.2."], "load_breast_cancer": ["Load and return the breast cancer wisconsin dataset (classification)."], "datasets.load_breast_cancer": ["Load and return the breast cancer wisconsin dataset (classification)."], "sklearn.datasets.load_breast_cancer": ["Load and return the breast cancer wisconsin dataset (classification)."], "load_diabetes": ["Load and return the diabetes dataset (regression)."], "datasets.load_diabetes": ["Load and return the diabetes dataset (regression)."], "sklearn.datasets.load_diabetes": ["Load and return the diabetes dataset (regression)."], "load_digits": ["Load and return the digits dataset (classification)."], "datasets.load_digits": ["Load and return the digits dataset (classification)."], "sklearn.datasets.load_digits": ["Load and return the digits dataset (classification)."], "load_files": ["Load text files with categories as subfolder names."], "datasets.load_files": ["Load text files with categories as subfolder names."], "sklearn.datasets.load_files": ["Load text files with categories as subfolder names."], "load_iris": ["Load and return the iris dataset (classification)."], "datasets.load_iris": ["Load and return the iris dataset (classification)."], "sklearn.datasets.load_iris": ["Load and return the iris dataset (classification)."], "load_linnerud": ["Load and return the physical exercise Linnerud dataset."], "datasets.load_linnerud": ["Load and return the physical exercise Linnerud dataset."], "sklearn.datasets.load_linnerud": ["Load and return the physical exercise Linnerud dataset."], "load_sample_image": ["Load the numpy array of a single sample image."], "datasets.load_sample_image": ["Load the numpy array of a single sample image."], "sklearn.datasets.load_sample_image": ["Load the numpy array of a single sample image."], "load_sample_images": ["Load sample images for image manipulation."], "datasets.load_sample_images": ["Load sample images for image manipulation."], "sklearn.datasets.load_sample_images": ["Load sample images for image manipulation."], "load_svmlight_file": ["Load datasets in the svmlight / libsvm format into sparse CSR matrix"], "datasets.load_svmlight_file": ["Load datasets in the svmlight / libsvm format into sparse CSR matrix"], "sklearn.datasets.load_svmlight_file": ["Load datasets in the svmlight / libsvm format into sparse CSR matrix"], "load_svmlight_files": ["Load dataset from multiple files in SVMlight format"], "datasets.load_svmlight_files": ["Load dataset from multiple files in SVMlight format"], "sklearn.datasets.load_svmlight_files": ["Load dataset from multiple files in SVMlight format"], "load_wine": ["Load and return the wine dataset (classification)."], "datasets.load_wine": ["Load and return the wine dataset (classification)."], "sklearn.datasets.load_wine": ["Load and return the wine dataset (classification)."], "make_biclusters": ["Generate a constant block diagonal structure array for biclustering."], "datasets.make_biclusters": ["Generate a constant block diagonal structure array for biclustering."], "sklearn.datasets.make_biclusters": ["Generate a constant block diagonal structure array for biclustering."], "make_blobs": ["Generate isotropic Gaussian blobs for clustering."], "datasets.make_blobs": ["Generate isotropic Gaussian blobs for clustering."], "sklearn.datasets.make_blobs": ["Generate isotropic Gaussian blobs for clustering."], "make_checkerboard": ["Generate an array with block checkerboard structure for biclustering."], "datasets.make_checkerboard": ["Generate an array with block checkerboard structure for biclustering."], "sklearn.datasets.make_checkerboard": ["Generate an array with block checkerboard structure for biclustering."], "make_circles": ["Make a large circle containing a smaller circle in 2d."], "datasets.make_circles": ["Make a large circle containing a smaller circle in 2d."], "sklearn.datasets.make_circles": ["Make a large circle containing a smaller circle in 2d."], "make_classification": ["Generate a random n-class classification problem."], "datasets.make_classification": ["Generate a random n-class classification problem."], "sklearn.datasets.make_classification": ["Generate a random n-class classification problem."], "make_friedman1": ["Generate the \"Friedman #1\" regression problem."], "datasets.make_friedman1": ["Generate the \"Friedman #1\" regression problem."], "sklearn.datasets.make_friedman1": ["Generate the \"Friedman #1\" regression problem."], "make_friedman2": ["Generate the \"Friedman #2\" regression problem."], "datasets.make_friedman2": ["Generate the \"Friedman #2\" regression problem."], "sklearn.datasets.make_friedman2": ["Generate the \"Friedman #2\" regression problem."], "make_friedman3": ["Generate the \"Friedman #3\" regression problem."], "datasets.make_friedman3": ["Generate the \"Friedman #3\" regression problem."], "sklearn.datasets.make_friedman3": ["Generate the \"Friedman #3\" regression problem."], "make_gaussian_quantiles": ["Generate isotropic Gaussian and label samples by quantile."], "datasets.make_gaussian_quantiles": ["Generate isotropic Gaussian and label samples by quantile."], "sklearn.datasets.make_gaussian_quantiles": ["Generate isotropic Gaussian and label samples by quantile."], "make_hastie_10_2": ["Generate data for binary classification used in Hastie et al. 2009, Example 10.2."], "datasets.make_hastie_10_2": ["Generate data for binary classification used in Hastie et al. 2009, Example 10.2."], "sklearn.datasets.make_hastie_10_2": ["Generate data for binary classification used in Hastie et al. 2009, Example 10.2."], "make_low_rank_matrix": ["Generate a mostly low rank matrix with bell-shaped singular values."], "datasets.make_low_rank_matrix": ["Generate a mostly low rank matrix with bell-shaped singular values."], "sklearn.datasets.make_low_rank_matrix": ["Generate a mostly low rank matrix with bell-shaped singular values."], "make_moons": ["Make two interleaving half circles."], "datasets.make_moons": ["Make two interleaving half circles."], "sklearn.datasets.make_moons": ["Make two interleaving half circles."], "make_multilabel_classification": ["Generate a random multilabel classification problem."], "datasets.make_multilabel_classification": ["Generate a random multilabel classification problem."], "sklearn.datasets.make_multilabel_classification": ["Generate a random multilabel classification problem."], "make_regression": ["Generate a random regression problem."], "datasets.make_regression": ["Generate a random regression problem."], "sklearn.datasets.make_regression": ["Generate a random regression problem."], "make_s_curve": ["Generate an S curve dataset."], "datasets.make_s_curve": ["Generate an S curve dataset."], "sklearn.datasets.make_s_curve": ["Generate an S curve dataset."], "make_sparse_coded_signal": ["Generate a signal as a sparse combination of dictionary elements."], "datasets.make_sparse_coded_signal": ["Generate a signal as a sparse combination of dictionary elements."], "sklearn.datasets.make_sparse_coded_signal": ["Generate a signal as a sparse combination of dictionary elements."], "make_sparse_spd_matrix": ["Generate a sparse symmetric definite positive matrix."], "datasets.make_sparse_spd_matrix": ["Generate a sparse symmetric definite positive matrix."], "sklearn.datasets.make_sparse_spd_matrix": ["Generate a sparse symmetric definite positive matrix."], "make_sparse_uncorrelated": ["Generate a random regression problem with sparse uncorrelated design."], "datasets.make_sparse_uncorrelated": ["Generate a random regression problem with sparse uncorrelated design."], "sklearn.datasets.make_sparse_uncorrelated": ["Generate a random regression problem with sparse uncorrelated design."], "make_spd_matrix": ["Generate a random symmetric, positive-definite matrix."], "datasets.make_spd_matrix": ["Generate a random symmetric, positive-definite matrix."], "sklearn.datasets.make_spd_matrix": ["Generate a random symmetric, positive-definite matrix."], "make_swiss_roll": ["Generate a swiss roll dataset."], "datasets.make_swiss_roll": ["Generate a swiss roll dataset."], "sklearn.datasets.make_swiss_roll": ["Generate a swiss roll dataset."], "DictionaryLearning": ["Dictionary learning."], "decomposition.DictionaryLearning": ["Dictionary learning."], "sklearn.decomposition.DictionaryLearning": ["Dictionary learning."], "FactorAnalysis": ["Factor Analysis (FA)."], "decomposition.FactorAnalysis": ["Factor Analysis (FA)."], "sklearn.decomposition.FactorAnalysis": ["Factor Analysis (FA)."], "FastICA": ["FastICA: a fast algorithm for Independent Component Analysis."], "decomposition.FastICA": ["FastICA: a fast algorithm for Independent Component Analysis."], "sklearn.decomposition.FastICA": ["FastICA: a fast algorithm for Independent Component Analysis."], "IncrementalPCA": ["Incremental principal components analysis (IPCA)."], "decomposition.IncrementalPCA": ["Incremental principal components analysis (IPCA)."], "sklearn.decomposition.IncrementalPCA": ["Incremental principal components analysis (IPCA)."], "LatentDirichletAllocation": ["Latent Dirichlet Allocation with online variational Bayes algorithm."], "decomposition.LatentDirichletAllocation": ["Latent Dirichlet Allocation with online variational Bayes algorithm."], "sklearn.decomposition.LatentDirichletAllocation": ["Latent Dirichlet Allocation with online variational Bayes algorithm."], "MiniBatchDictionaryLearning": ["Mini-batch dictionary learning."], "decomposition.MiniBatchDictionaryLearning": ["Mini-batch dictionary learning."], "sklearn.decomposition.MiniBatchDictionaryLearning": ["Mini-batch dictionary learning."], "MiniBatchSparsePCA": ["Mini-batch Sparse Principal Components Analysis."], "decomposition.MiniBatchSparsePCA": ["Mini-batch Sparse Principal Components Analysis."], "sklearn.decomposition.MiniBatchSparsePCA": ["Mini-batch Sparse Principal Components Analysis."], "NMF": ["Non-Negative Matrix Factorization (NMF)."], "decomposition.NMF": ["Non-Negative Matrix Factorization (NMF)."], "sklearn.decomposition.NMF": ["Non-Negative Matrix Factorization (NMF)."], "MiniBatchNMF": ["Mini-Batch Non-Negative Matrix Factorization (NMF)."], "decomposition.MiniBatchNMF": ["Mini-Batch Non-Negative Matrix Factorization (NMF)."], "sklearn.decomposition.MiniBatchNMF": ["Mini-Batch Non-Negative Matrix Factorization (NMF)."], "PCA": ["Principal component analysis (PCA)."], "decomposition.PCA": ["Principal component analysis (PCA)."], "sklearn.decomposition.PCA": ["Principal component analysis (PCA)."], "SparsePCA": ["Sparse Principal Components Analysis (SparsePCA)."], "decomposition.SparsePCA": ["Sparse Principal Components Analysis (SparsePCA)."], "sklearn.decomposition.SparsePCA": ["Sparse Principal Components Analysis (SparsePCA)."], "SparseCoder": ["Sparse coding."], "decomposition.SparseCoder": ["Sparse coding."], "sklearn.decomposition.SparseCoder": ["Sparse coding."], "TruncatedSVD": ["Dimensionality reduction using truncated SVD (aka LSA)."], "decomposition.TruncatedSVD": ["Dimensionality reduction using truncated SVD (aka LSA)."], "sklearn.decomposition.TruncatedSVD": ["Dimensionality reduction using truncated SVD (aka LSA)."], "dict_learning": ["Solves a dictionary learning matrix factorization problem."], "decomposition.dict_learning": ["Solves a dictionary learning matrix factorization problem."], "sklearn.decomposition.dict_learning": ["Solves a dictionary learning matrix factorization problem."], "dict_learning_online": ["Solves a dictionary learning matrix factorization problem online."], "decomposition.dict_learning_online": ["Solves a dictionary learning matrix factorization problem online."], "sklearn.decomposition.dict_learning_online": ["Solves a dictionary learning matrix factorization problem online."], "fastica": ["Perform Fast Independent Component Analysis."], "decomposition.fastica": ["Perform Fast Independent Component Analysis."], "sklearn.decomposition.fastica": ["Perform Fast Independent Component Analysis."], "non_negative_factorization": ["Compute Non-negative Matrix Factorization (NMF)."], "decomposition.non_negative_factorization": ["Compute Non-negative Matrix Factorization (NMF)."], "sklearn.decomposition.non_negative_factorization": ["Compute Non-negative Matrix Factorization (NMF)."], "sparse_encode": ["Sparse coding."], "decomposition.sparse_encode": ["Sparse coding."], "sklearn.decomposition.sparse_encode": ["Sparse coding."], "LinearDiscriminantAnalysis": ["Linear Discriminant Analysis."], "discriminant_analysis.LinearDiscriminantAnalysis": ["Linear Discriminant Analysis."], "sklearn.discriminant_analysis.LinearDiscriminantAnalysis": ["Linear Discriminant Analysis."], "QuadraticDiscriminantAnalysis": ["Quadratic Discriminant Analysis."], "discriminant_analysis.QuadraticDiscriminantAnalysis": ["Quadratic Discriminant Analysis."], "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis": ["Quadratic Discriminant Analysis."], "DummyClassifier": ["DummyClassifier makes predictions that ignore the input features."], "dummy.DummyClassifier": ["DummyClassifier makes predictions that ignore the input features."], "sklearn.dummy.DummyClassifier": ["DummyClassifier makes predictions that ignore the input features."], "DummyRegressor": ["Regressor that makes predictions using simple rules."], "dummy.DummyRegressor": ["Regressor that makes predictions using simple rules."], "sklearn.dummy.DummyRegressor": ["Regressor that makes predictions using simple rules."], "AdaBoostClassifier": ["An AdaBoost classifier."], "ensemble.AdaBoostClassifier": ["An AdaBoost classifier."], "sklearn.ensemble.AdaBoostClassifier": ["An AdaBoost classifier."], "AdaBoostRegressor": ["An AdaBoost regressor."], "ensemble.AdaBoostRegressor": ["An AdaBoost regressor."], "sklearn.ensemble.AdaBoostRegressor": ["An AdaBoost regressor."], "BaggingClassifier": ["A Bagging classifier."], "ensemble.BaggingClassifier": ["A Bagging classifier."], "sklearn.ensemble.BaggingClassifier": ["A Bagging classifier."], "BaggingRegressor": ["A Bagging regressor."], "ensemble.BaggingRegressor": ["A Bagging regressor."], "sklearn.ensemble.BaggingRegressor": ["A Bagging regressor."], "ExtraTreesClassifier": ["An extra-trees classifier."], "ensemble.ExtraTreesClassifier": ["An extra-trees classifier."], "sklearn.ensemble.ExtraTreesClassifier": ["An extra-trees classifier."], "ExtraTreesRegressor": ["An extra-trees regressor."], "ensemble.ExtraTreesRegressor": ["An extra-trees regressor."], "sklearn.ensemble.ExtraTreesRegressor": ["An extra-trees regressor."], "GradientBoostingClassifier": ["Gradient Boosting for classification."], "ensemble.GradientBoostingClassifier": ["Gradient Boosting for classification."], "sklearn.ensemble.GradientBoostingClassifier": ["Gradient Boosting for classification."], "GradientBoostingRegressor": ["Gradient Boosting for regression."], "ensemble.GradientBoostingRegressor": ["Gradient Boosting for regression."], "sklearn.ensemble.GradientBoostingRegressor": ["Gradient Boosting for regression."], "IsolationForest": ["Isolation Forest Algorithm."], "ensemble.IsolationForest": ["Isolation Forest Algorithm."], "sklearn.ensemble.IsolationForest": ["Isolation Forest Algorithm."], "RandomForestClassifier": ["A random forest classifier."], "ensemble.RandomForestClassifier": ["A random forest classifier."], "sklearn.ensemble.RandomForestClassifier": ["A random forest classifier."], "RandomForestRegressor": ["A random forest regressor."], "ensemble.RandomForestRegressor": ["A random forest regressor."], "sklearn.ensemble.RandomForestRegressor": ["A random forest regressor."], "RandomTreesEmbedding": ["An ensemble of totally random trees."], "ensemble.RandomTreesEmbedding": ["An ensemble of totally random trees."], "sklearn.ensemble.RandomTreesEmbedding": ["An ensemble of totally random trees."], "StackingClassifier": ["Stack of estimators with a final classifier."], "ensemble.StackingClassifier": ["Stack of estimators with a final classifier."], "sklearn.ensemble.StackingClassifier": ["Stack of estimators with a final classifier."], "StackingRegressor": ["Stack of estimators with a final regressor."], "ensemble.StackingRegressor": ["Stack of estimators with a final regressor."], "sklearn.ensemble.StackingRegressor": ["Stack of estimators with a final regressor."], "VotingClassifier": ["Soft Voting/Majority Rule classifier for unfitted estimators."], "ensemble.VotingClassifier": ["Soft Voting/Majority Rule classifier for unfitted estimators."], "sklearn.ensemble.VotingClassifier": ["Soft Voting/Majority Rule classifier for unfitted estimators."], "VotingRegressor": ["Prediction voting regressor for unfitted estimators."], "ensemble.VotingRegressor": ["Prediction voting regressor for unfitted estimators."], "sklearn.ensemble.VotingRegressor": ["Prediction voting regressor for unfitted estimators."], "HistGradientBoostingRegressor": ["Histogram-based Gradient Boosting Regression Tree."], "ensemble.HistGradientBoostingRegressor": ["Histogram-based Gradient Boosting Regression Tree."], "sklearn.ensemble.HistGradientBoostingRegressor": ["Histogram-based Gradient Boosting Regression Tree."], "HistGradientBoostingClassifier": ["Histogram-based Gradient Boosting Classification Tree."], "ensemble.HistGradientBoostingClassifier": ["Histogram-based Gradient Boosting Classification Tree."], "sklearn.ensemble.HistGradientBoostingClassifier": ["Histogram-based Gradient Boosting Classification Tree."], "ConvergenceWarning": ["Custom warning to capture convergence problems"], "exceptions.ConvergenceWarning": ["Custom warning to capture convergence problems"], "sklearn.exceptions.ConvergenceWarning": ["Custom warning to capture convergence problems"], "DataConversionWarning": ["Warning used to notify implicit data conversions happening in the code."], "exceptions.DataConversionWarning": ["Warning used to notify implicit data conversions happening in the code."], "sklearn.exceptions.DataConversionWarning": ["Warning used to notify implicit data conversions happening in the code."], "DataDimensionalityWarning": ["Custom warning to notify potential issues with data dimensionality."], "exceptions.DataDimensionalityWarning": ["Custom warning to notify potential issues with data dimensionality."], "sklearn.exceptions.DataDimensionalityWarning": ["Custom warning to notify potential issues with data dimensionality."], "EfficiencyWarning": ["Warning used to notify the user of inefficient computation."], "exceptions.EfficiencyWarning": ["Warning used to notify the user of inefficient computation."], "sklearn.exceptions.EfficiencyWarning": ["Warning used to notify the user of inefficient computation."], "FitFailedWarning": ["Warning class used if there is an error while fitting the estimator."], "exceptions.FitFailedWarning": ["Warning class used if there is an error while fitting the estimator."], "sklearn.exceptions.FitFailedWarning": ["Warning class used if there is an error while fitting the estimator."], "NotFittedError": ["Exception class to raise if estimator is used before fitting."], "exceptions.NotFittedError": ["Exception class to raise if estimator is used before fitting."], "sklearn.exceptions.NotFittedError": ["Exception class to raise if estimator is used before fitting."], "UndefinedMetricWarning": ["Warning used when the metric is invalid"], "exceptions.UndefinedMetricWarning": ["Warning used when the metric is invalid"], "sklearn.exceptions.UndefinedMetricWarning": ["Warning used when the metric is invalid"], "enable_hist_gradient_boosting": ["This is now a no-op and can be safely removed from your code."], "experimental.enable_hist_gradient_boosting": ["This is now a no-op and can be safely removed from your code."], "sklearn.experimental.enable_hist_gradient_boosting": ["This is now a no-op and can be safely removed from your code."], "enable_iterative_imputer": ["Enables IterativeImputer"], "experimental.enable_iterative_imputer": ["Enables IterativeImputer"], "sklearn.experimental.enable_iterative_imputer": ["Enables IterativeImputer"], "enable_halving_search_cv": ["Enables Successive Halving search-estimators"], "experimental.enable_halving_search_cv": ["Enables Successive Halving search-estimators"], "sklearn.experimental.enable_halving_search_cv": ["Enables Successive Halving search-estimators"], "DictVectorizer": ["Transforms lists of feature-value mappings to vectors."], "feature_extraction.DictVectorizer": ["Transforms lists of feature-value mappings to vectors."], "sklearn.feature_extraction.DictVectorizer": ["Transforms lists of feature-value mappings to vectors."], "FeatureHasher": ["Implements feature hashing, aka the hashing trick."], "feature_extraction.FeatureHasher": ["Implements feature hashing, aka the hashing trick."], "sklearn.feature_extraction.FeatureHasher": ["Implements feature hashing, aka the hashing trick."], "extract_patches_2d": ["Reshape a 2D image into a collection of patches"], "image.extract_patches_2d": ["Reshape a 2D image into a collection of patches"], "feature_extraction.image.extract_patches_2d": ["Reshape a 2D image into a collection of patches"], "sklearn.feature_extraction.image.extract_patches_2d": ["Reshape a 2D image into a collection of patches"], "grid_to_graph": ["Graph of the pixel-to-pixel connections."], "image.grid_to_graph": ["Graph of the pixel-to-pixel connections."], "feature_extraction.image.grid_to_graph": ["Graph of the pixel-to-pixel connections."], "sklearn.feature_extraction.image.grid_to_graph": ["Graph of the pixel-to-pixel connections."], "img_to_graph": ["Graph of the pixel-to-pixel gradient connections."], "image.img_to_graph": ["Graph of the pixel-to-pixel gradient connections."], "feature_extraction.image.img_to_graph": ["Graph of the pixel-to-pixel gradient connections."], "sklearn.feature_extraction.image.img_to_graph": ["Graph of the pixel-to-pixel gradient connections."], "reconstruct_from_patches_2d": ["Reconstruct the image from all of its patches."], "image.reconstruct_from_patches_2d": ["Reconstruct the image from all of its patches."], "feature_extraction.image.reconstruct_from_patches_2d": ["Reconstruct the image from all of its patches."], "sklearn.feature_extraction.image.reconstruct_from_patches_2d": ["Reconstruct the image from all of its patches."], "PatchExtractor": ["Extracts patches from a collection of images."], "image.PatchExtractor": ["Extracts patches from a collection of images."], "feature_extraction.image.PatchExtractor": ["Extracts patches from a collection of images."], "sklearn.feature_extraction.image.PatchExtractor": ["Extracts patches from a collection of images."], "CountVectorizer": ["Convert a collection of text documents to a matrix of token counts."], "text.CountVectorizer": ["Convert a collection of text documents to a matrix of token counts."], "feature_extraction.text.CountVectorizer": ["Convert a collection of text documents to a matrix of token counts."], "sklearn.feature_extraction.text.CountVectorizer": ["Convert a collection of text documents to a matrix of token counts."], "HashingVectorizer": ["Convert a collection of text documents to a matrix of token occurrences."], "text.HashingVectorizer": ["Convert a collection of text documents to a matrix of token occurrences."], "feature_extraction.text.HashingVectorizer": ["Convert a collection of text documents to a matrix of token occurrences."], "sklearn.feature_extraction.text.HashingVectorizer": ["Convert a collection of text documents to a matrix of token occurrences."], "TfidfTransformer": ["Transform a count matrix to a normalized tf or tf-idf representation."], "text.TfidfTransformer": ["Transform a count matrix to a normalized tf or tf-idf representation."], "feature_extraction.text.TfidfTransformer": ["Transform a count matrix to a normalized tf or tf-idf representation."], "sklearn.feature_extraction.text.TfidfTransformer": ["Transform a count matrix to a normalized tf or tf-idf representation."], "TfidfVectorizer": ["Convert a collection of raw documents to a matrix of TF-IDF features."], "text.TfidfVectorizer": ["Convert a collection of raw documents to a matrix of TF-IDF features."], "feature_extraction.text.TfidfVectorizer": ["Convert a collection of raw documents to a matrix of TF-IDF features."], "sklearn.feature_extraction.text.TfidfVectorizer": ["Convert a collection of raw documents to a matrix of TF-IDF features."], "GenericUnivariateSelect": ["Univariate feature selector with configurable strategy."], "feature_selection.GenericUnivariateSelect": ["Univariate feature selector with configurable strategy."], "sklearn.feature_selection.GenericUnivariateSelect": ["Univariate feature selector with configurable strategy."], "SelectPercentile": ["Select features according to a percentile of the highest scores."], "feature_selection.SelectPercentile": ["Select features according to a percentile of the highest scores."], "sklearn.feature_selection.SelectPercentile": ["Select features according to a percentile of the highest scores."], "SelectKBest": ["Select features according to the k highest scores."], "feature_selection.SelectKBest": ["Select features according to the k highest scores."], "sklearn.feature_selection.SelectKBest": ["Select features according to the k highest scores."], "SelectFpr": ["Filter: Select the pvalues below alpha based on a FPR test."], "feature_selection.SelectFpr": ["Filter: Select the pvalues below alpha based on a FPR test."], "sklearn.feature_selection.SelectFpr": ["Filter: Select the pvalues below alpha based on a FPR test."], "SelectFdr": ["Filter: Select the p-values for an estimated false discovery rate."], "feature_selection.SelectFdr": ["Filter: Select the p-values for an estimated false discovery rate."], "sklearn.feature_selection.SelectFdr": ["Filter: Select the p-values for an estimated false discovery rate."], "SelectFromModel": ["Meta-transformer for selecting features based on importance weights."], "feature_selection.SelectFromModel": ["Meta-transformer for selecting features based on importance weights."], "sklearn.feature_selection.SelectFromModel": ["Meta-transformer for selecting features based on importance weights."], "SelectFwe": ["Filter: Select the p-values corresponding to Family-wise error rate."], "feature_selection.SelectFwe": ["Filter: Select the p-values corresponding to Family-wise error rate."], "sklearn.feature_selection.SelectFwe": ["Filter: Select the p-values corresponding to Family-wise error rate."], "SequentialFeatureSelector": ["Transformer that performs Sequential Feature Selection."], "feature_selection.SequentialFeatureSelector": ["Transformer that performs Sequential Feature Selection."], "sklearn.feature_selection.SequentialFeatureSelector": ["Transformer that performs Sequential Feature Selection."], "RFE": ["Feature ranking with recursive feature elimination."], "feature_selection.RFE": ["Feature ranking with recursive feature elimination."], "sklearn.feature_selection.RFE": ["Feature ranking with recursive feature elimination."], "RFECV": ["Recursive feature elimination with cross-validation to select the number of features."], "feature_selection.RFECV": ["Recursive feature elimination with cross-validation to select the number of features."], "sklearn.feature_selection.RFECV": ["Recursive feature elimination with cross-validation to select the number of features."], "VarianceThreshold": ["Feature selector that removes all low-variance features."], "feature_selection.VarianceThreshold": ["Feature selector that removes all low-variance features."], "sklearn.feature_selection.VarianceThreshold": ["Feature selector that removes all low-variance features."], "chi2": ["Compute chi-squared stats between each non-negative feature and class."], "feature_selection.chi2": ["Compute chi-squared stats between each non-negative feature and class."], "sklearn.feature_selection.chi2": ["Compute chi-squared stats between each non-negative feature and class."], "f_classif": ["Compute the ANOVA F-value for the provided sample."], "feature_selection.f_classif": ["Compute the ANOVA F-value for the provided sample."], "sklearn.feature_selection.f_classif": ["Compute the ANOVA F-value for the provided sample."], "f_regression": ["Univariate linear regression tests returning F-statistic and p-values."], "feature_selection.f_regression": ["Univariate linear regression tests returning F-statistic and p-values."], "sklearn.feature_selection.f_regression": ["Univariate linear regression tests returning F-statistic and p-values."], "r_regression": ["Compute Pearson's r for each features and the target."], "feature_selection.r_regression": ["Compute Pearson's r for each features and the target."], "sklearn.feature_selection.r_regression": ["Compute Pearson's r for each features and the target."], "mutual_info_classif": ["Estimate mutual information for a discrete target variable."], "feature_selection.mutual_info_classif": ["Estimate mutual information for a discrete target variable."], "sklearn.feature_selection.mutual_info_classif": ["Estimate mutual information for a discrete target variable."], "mutual_info_regression": ["Estimate mutual information for a continuous target variable."], "feature_selection.mutual_info_regression": ["Estimate mutual information for a continuous target variable."], "sklearn.feature_selection.mutual_info_regression": ["Estimate mutual information for a continuous target variable."], "GaussianProcessClassifier": ["Gaussian process classification (GPC) based on Laplace approximation."], "gaussian_process.GaussianProcessClassifier": ["Gaussian process classification (GPC) based on Laplace approximation."], "sklearn.gaussian_process.GaussianProcessClassifier": ["Gaussian process classification (GPC) based on Laplace approximation."], "GaussianProcessRegressor": ["Gaussian process regression (GPR)."], "gaussian_process.GaussianProcessRegressor": ["Gaussian process regression (GPR)."], "sklearn.gaussian_process.GaussianProcessRegressor": ["Gaussian process regression (GPR)."], "CompoundKernel": ["Kernel which is composed of a set of other kernels."], "kernels.CompoundKernel": ["Kernel which is composed of a set of other kernels."], "gaussian_process.kernels.CompoundKernel": ["Kernel which is composed of a set of other kernels."], "sklearn.gaussian_process.kernels.CompoundKernel": ["Kernel which is composed of a set of other kernels."], "ConstantKernel": ["Constant kernel."], "kernels.ConstantKernel": ["Constant kernel."], "gaussian_process.kernels.ConstantKernel": ["Constant kernel."], "sklearn.gaussian_process.kernels.ConstantKernel": ["Constant kernel."], "DotProduct": ["Dot-Product kernel."], "kernels.DotProduct": ["Dot-Product kernel."], "gaussian_process.kernels.DotProduct": ["Dot-Product kernel."], "sklearn.gaussian_process.kernels.DotProduct": ["Dot-Product kernel."], "ExpSineSquared": ["Exp-Sine-Squared kernel (aka periodic kernel)."], "kernels.ExpSineSquared": ["Exp-Sine-Squared kernel (aka periodic kernel)."], "gaussian_process.kernels.ExpSineSquared": ["Exp-Sine-Squared kernel (aka periodic kernel)."], "sklearn.gaussian_process.kernels.ExpSineSquared": ["Exp-Sine-Squared kernel (aka periodic kernel)."], "Exponentiation": ["The Exponentiation kernel takes one base kernel and a scalar parameter \\(p\\) and combines them via"], "kernels.Exponentiation": ["The Exponentiation kernel takes one base kernel and a scalar parameter \\(p\\) and combines them via"], "gaussian_process.kernels.Exponentiation": ["The Exponentiation kernel takes one base kernel and a scalar parameter \\(p\\) and combines them via"], "sklearn.gaussian_process.kernels.Exponentiation": ["The Exponentiation kernel takes one base kernel and a scalar parameter \\(p\\) and combines them via"], "Hyperparameter": ["A kernel hyperparameter's specification in form of a namedtuple."], "kernels.Hyperparameter": ["A kernel hyperparameter's specification in form of a namedtuple."], "gaussian_process.kernels.Hyperparameter": ["A kernel hyperparameter's specification in form of a namedtuple."], "sklearn.gaussian_process.kernels.Hyperparameter": ["A kernel hyperparameter's specification in form of a namedtuple."], "Kernel": ["Base class for all kernels."], "kernels.Kernel": ["Base class for all kernels."], "gaussian_process.kernels.Kernel": ["Base class for all kernels."], "sklearn.gaussian_process.kernels.Kernel": ["Base class for all kernels."], "Matern": ["Matern kernel."], "kernels.Matern": ["Matern kernel."], "gaussian_process.kernels.Matern": ["Matern kernel."], "sklearn.gaussian_process.kernels.Matern": ["Matern kernel."], "PairwiseKernel": ["Wrapper for kernels in sklearn.metrics.pairwise."], "kernels.PairwiseKernel": ["Wrapper for kernels in sklearn.metrics.pairwise."], "gaussian_process.kernels.PairwiseKernel": ["Wrapper for kernels in sklearn.metrics.pairwise."], "sklearn.gaussian_process.kernels.PairwiseKernel": ["Wrapper for kernels in sklearn.metrics.pairwise."], "Product": ["The Product kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "kernels.Product": ["The Product kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "gaussian_process.kernels.Product": ["The Product kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "sklearn.gaussian_process.kernels.Product": ["The Product kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "RBF": ["Radial-basis function kernel (aka squared-exponential kernel)."], "kernels.RBF": ["Radial-basis function kernel (aka squared-exponential kernel)."], "gaussian_process.kernels.RBF": ["Radial-basis function kernel (aka squared-exponential kernel)."], "sklearn.gaussian_process.kernels.RBF": ["Radial-basis function kernel (aka squared-exponential kernel)."], "RationalQuadratic": ["Rational Quadratic kernel."], "kernels.RationalQuadratic": ["Rational Quadratic kernel."], "gaussian_process.kernels.RationalQuadratic": ["Rational Quadratic kernel."], "sklearn.gaussian_process.kernels.RationalQuadratic": ["Rational Quadratic kernel."], "Sum": ["The Sum kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "kernels.Sum": ["The Sum kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "gaussian_process.kernels.Sum": ["The Sum kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "sklearn.gaussian_process.kernels.Sum": ["The Sum kernel takes two kernels \\(k_1\\) and \\(k_2\\) and combines them via"], "WhiteKernel": ["White kernel."], "kernels.WhiteKernel": ["White kernel."], "gaussian_process.kernels.WhiteKernel": ["White kernel."], "sklearn.gaussian_process.kernels.WhiteKernel": ["White kernel."], "SimpleImputer": ["Imputation transformer for completing missing values."], "impute.SimpleImputer": ["Imputation transformer for completing missing values."], "sklearn.impute.SimpleImputer": ["Imputation transformer for completing missing values."], "IterativeImputer": ["Multivariate imputer that estimates each feature from all the others."], "impute.IterativeImputer": ["Multivariate imputer that estimates each feature from all the others."], "sklearn.impute.IterativeImputer": ["Multivariate imputer that estimates each feature from all the others."], "MissingIndicator": ["Binary indicators for missing values."], "impute.MissingIndicator": ["Binary indicators for missing values."], "sklearn.impute.MissingIndicator": ["Binary indicators for missing values."], "KNNImputer": ["Imputation for completing missing values using k-Nearest Neighbors."], "impute.KNNImputer": ["Imputation for completing missing values using k-Nearest Neighbors."], "sklearn.impute.KNNImputer": ["Imputation for completing missing values using k-Nearest Neighbors."], "partial_dependence": ["Partial dependence of features."], "inspection.partial_dependence": ["Partial dependence of features."], "sklearn.inspection.partial_dependence": ["Partial dependence of features."], "DecisionBoundaryDisplay": ["Decisions boundary visualization."], "inspection.DecisionBoundaryDisplay": ["Decisions boundary visualization."], "sklearn.inspection.DecisionBoundaryDisplay": ["Decisions boundary visualization."], "PartialDependenceDisplay": ["Partial Dependence Plot (PDP)."], "inspection.PartialDependenceDisplay": ["Partial Dependence Plot (PDP)."], "sklearn.inspection.PartialDependenceDisplay": ["Partial Dependence Plot (PDP)."], "plot_partial_dependence": ["DEPRECATED: Function plot_partial_dependence is deprecated in 1.0 and will be removed in 1.2."], "inspection.plot_partial_dependence": ["DEPRECATED: Function plot_partial_dependence is deprecated in 1.0 and will be removed in 1.2."], "sklearn.inspection.plot_partial_dependence": ["DEPRECATED: Function plot_partial_dependence is deprecated in 1.0 and will be removed in 1.2."], "IsotonicRegression": ["Isotonic regression model."], "isotonic.IsotonicRegression": ["Isotonic regression model."], "sklearn.isotonic.IsotonicRegression": ["Isotonic regression model."], "check_increasing": ["Determine whether y is monotonically correlated with x."], "isotonic.check_increasing": ["Determine whether y is monotonically correlated with x."], "sklearn.isotonic.check_increasing": ["Determine whether y is monotonically correlated with x."], "isotonic_regression": ["Solve the isotonic regression model."], "isotonic.isotonic_regression": ["Solve the isotonic regression model."], "sklearn.isotonic.isotonic_regression": ["Solve the isotonic regression model."], "AdditiveChi2Sampler": ["Approximate feature map for additive chi2 kernel."], "kernel_approximation.AdditiveChi2Sampler": ["Approximate feature map for additive chi2 kernel."], "sklearn.kernel_approximation.AdditiveChi2Sampler": ["Approximate feature map for additive chi2 kernel."], "Nystroem": ["Approximate a kernel map using a subset of the training data."], "kernel_approximation.Nystroem": ["Approximate a kernel map using a subset of the training data."], "sklearn.kernel_approximation.Nystroem": ["Approximate a kernel map using a subset of the training data."], "PolynomialCountSketch": ["Polynomial kernel approximation via Tensor Sketch."], "kernel_approximation.PolynomialCountSketch": ["Polynomial kernel approximation via Tensor Sketch."], "sklearn.kernel_approximation.PolynomialCountSketch": ["Polynomial kernel approximation via Tensor Sketch."], "RBFSampler": ["Approximate a RBF kernel feature map using random Fourier features."], "kernel_approximation.RBFSampler": ["Approximate a RBF kernel feature map using random Fourier features."], "sklearn.kernel_approximation.RBFSampler": ["Approximate a RBF kernel feature map using random Fourier features."], "SkewedChi2Sampler": ["Approximate feature map for \"skewed chi-squared\" kernel."], "kernel_approximation.SkewedChi2Sampler": ["Approximate feature map for \"skewed chi-squared\" kernel."], "sklearn.kernel_approximation.SkewedChi2Sampler": ["Approximate feature map for \"skewed chi-squared\" kernel."], "KernelRidge": ["Kernel ridge regression."], "kernel_ridge.KernelRidge": ["Kernel ridge regression."], "sklearn.kernel_ridge.KernelRidge": ["Kernel ridge regression."], "LogisticRegression": ["Logistic Regression (aka logit, MaxEnt) classifier."], "linear_model.LogisticRegression": ["Logistic Regression (aka logit, MaxEnt) classifier."], "sklearn.linear_model.LogisticRegression": ["Logistic Regression (aka logit, MaxEnt) classifier."], "LogisticRegressionCV": ["Logistic Regression CV (aka logit, MaxEnt) classifier."], "linear_model.LogisticRegressionCV": ["Logistic Regression CV (aka logit, MaxEnt) classifier."], "sklearn.linear_model.LogisticRegressionCV": ["Logistic Regression CV (aka logit, MaxEnt) classifier."], "PassiveAggressiveClassifier": ["Passive Aggressive Classifier."], "linear_model.PassiveAggressiveClassifier": ["Passive Aggressive Classifier."], "sklearn.linear_model.PassiveAggressiveClassifier": ["Passive Aggressive Classifier."], "Perceptron": ["Linear perceptron classifier."], "linear_model.Perceptron": ["Linear perceptron classifier."], "sklearn.linear_model.Perceptron": ["Linear perceptron classifier."], "RidgeClassifier": ["Classifier using Ridge regression."], "linear_model.RidgeClassifier": ["Classifier using Ridge regression."], "sklearn.linear_model.RidgeClassifier": ["Classifier using Ridge regression."], "RidgeClassifierCV": ["Ridge classifier with built-in cross-validation."], "linear_model.RidgeClassifierCV": ["Ridge classifier with built-in cross-validation."], "sklearn.linear_model.RidgeClassifierCV": ["Ridge classifier with built-in cross-validation."], "SGDClassifier": ["Linear classifiers (SVM, logistic regression, etc.) with SGD training."], "linear_model.SGDClassifier": ["Linear classifiers (SVM, logistic regression, etc.) with SGD training."], "sklearn.linear_model.SGDClassifier": ["Linear classifiers (SVM, logistic regression, etc.) with SGD training."], "SGDOneClassSVM": ["Solves linear One-Class SVM using Stochastic Gradient Descent."], "linear_model.SGDOneClassSVM": ["Solves linear One-Class SVM using Stochastic Gradient Descent."], "sklearn.linear_model.SGDOneClassSVM": ["Solves linear One-Class SVM using Stochastic Gradient Descent."], "LinearRegression": ["Ordinary least squares Linear Regression."], "linear_model.LinearRegression": ["Ordinary least squares Linear Regression."], "sklearn.linear_model.LinearRegression": ["Ordinary least squares Linear Regression."], "Ridge": ["Linear least squares with l2 regularization."], "linear_model.Ridge": ["Linear least squares with l2 regularization."], "sklearn.linear_model.Ridge": ["Linear least squares with l2 regularization."], "RidgeCV": ["Ridge regression with built-in cross-validation."], "linear_model.RidgeCV": ["Ridge regression with built-in cross-validation."], "sklearn.linear_model.RidgeCV": ["Ridge regression with built-in cross-validation."], "SGDRegressor": ["Linear model fitted by minimizing a regularized empirical loss with SGD."], "linear_model.SGDRegressor": ["Linear model fitted by minimizing a regularized empirical loss with SGD."], "sklearn.linear_model.SGDRegressor": ["Linear model fitted by minimizing a regularized empirical loss with SGD."], "ElasticNet": ["Linear regression with combined L1 and L2 priors as regularizer."], "linear_model.ElasticNet": ["Linear regression with combined L1 and L2 priors as regularizer."], "sklearn.linear_model.ElasticNet": ["Linear regression with combined L1 and L2 priors as regularizer."], "ElasticNetCV": ["Elastic Net model with iterative fitting along a regularization path."], "linear_model.ElasticNetCV": ["Elastic Net model with iterative fitting along a regularization path."], "sklearn.linear_model.ElasticNetCV": ["Elastic Net model with iterative fitting along a regularization path."], "Lars": ["Least Angle Regression model a.k.a."], "linear_model.Lars": ["Least Angle Regression model a.k.a."], "sklearn.linear_model.Lars": ["Least Angle Regression model a.k.a."], "LarsCV": ["Cross-validated Least Angle Regression model."], "linear_model.LarsCV": ["Cross-validated Least Angle Regression model."], "sklearn.linear_model.LarsCV": ["Cross-validated Least Angle Regression model."], "Lasso": ["Linear Model trained with L1 prior as regularizer (aka the Lasso)."], "linear_model.Lasso": ["Linear Model trained with L1 prior as regularizer (aka the Lasso)."], "sklearn.linear_model.Lasso": ["Linear Model trained with L1 prior as regularizer (aka the Lasso)."], "LassoCV": ["Lasso linear model with iterative fitting along a regularization path."], "linear_model.LassoCV": ["Lasso linear model with iterative fitting along a regularization path."], "sklearn.linear_model.LassoCV": ["Lasso linear model with iterative fitting along a regularization path."], "LassoLars": ["Lasso model fit with Least Angle Regression a.k.a."], "linear_model.LassoLars": ["Lasso model fit with Least Angle Regression a.k.a."], "sklearn.linear_model.LassoLars": ["Lasso model fit with Least Angle Regression a.k.a."], "LassoLarsCV": ["Cross-validated Lasso, using the LARS algorithm."], "linear_model.LassoLarsCV": ["Cross-validated Lasso, using the LARS algorithm."], "sklearn.linear_model.LassoLarsCV": ["Cross-validated Lasso, using the LARS algorithm."], "LassoLarsIC": ["Lasso model fit with Lars using BIC or AIC for model selection."], "linear_model.LassoLarsIC": ["Lasso model fit with Lars using BIC or AIC for model selection."], "sklearn.linear_model.LassoLarsIC": ["Lasso model fit with Lars using BIC or AIC for model selection."], "OrthogonalMatchingPursuit": ["Orthogonal Matching Pursuit model (OMP)."], "linear_model.OrthogonalMatchingPursuit": ["Orthogonal Matching Pursuit model (OMP)."], "sklearn.linear_model.OrthogonalMatchingPursuit": ["Orthogonal Matching Pursuit model (OMP)."], "OrthogonalMatchingPursuitCV": ["Cross-validated Orthogonal Matching Pursuit model (OMP)."], "linear_model.OrthogonalMatchingPursuitCV": ["Cross-validated Orthogonal Matching Pursuit model (OMP)."], "sklearn.linear_model.OrthogonalMatchingPursuitCV": ["Cross-validated Orthogonal Matching Pursuit model (OMP)."], "ARDRegression": ["Bayesian ARD regression."], "linear_model.ARDRegression": ["Bayesian ARD regression."], "sklearn.linear_model.ARDRegression": ["Bayesian ARD regression."], "BayesianRidge": ["Bayesian ridge regression."], "linear_model.BayesianRidge": ["Bayesian ridge regression."], "sklearn.linear_model.BayesianRidge": ["Bayesian ridge regression."], "MultiTaskElasticNet": ["Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer."], "linear_model.MultiTaskElasticNet": ["Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer."], "sklearn.linear_model.MultiTaskElasticNet": ["Multi-task ElasticNet model trained with L1/L2 mixed-norm as regularizer."], "MultiTaskElasticNetCV": ["Multi-task L1/L2 ElasticNet with built-in cross-validation."], "linear_model.MultiTaskElasticNetCV": ["Multi-task L1/L2 ElasticNet with built-in cross-validation."], "sklearn.linear_model.MultiTaskElasticNetCV": ["Multi-task L1/L2 ElasticNet with built-in cross-validation."], "MultiTaskLasso": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "linear_model.MultiTaskLasso": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "sklearn.linear_model.MultiTaskLasso": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "MultiTaskLassoCV": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "linear_model.MultiTaskLassoCV": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "sklearn.linear_model.MultiTaskLassoCV": ["Multi-task Lasso model trained with L1/L2 mixed-norm as regularizer."], "HuberRegressor": ["Linear regression model that is robust to outliers."], "linear_model.HuberRegressor": ["Linear regression model that is robust to outliers."], "sklearn.linear_model.HuberRegressor": ["Linear regression model that is robust to outliers."], "QuantileRegressor": ["Linear regression model that predicts conditional quantiles."], "linear_model.QuantileRegressor": ["Linear regression model that predicts conditional quantiles."], "sklearn.linear_model.QuantileRegressor": ["Linear regression model that predicts conditional quantiles."], "RANSACRegressor": ["RANSAC (RANdom SAmple Consensus) algorithm."], "linear_model.RANSACRegressor": ["RANSAC (RANdom SAmple Consensus) algorithm."], "sklearn.linear_model.RANSACRegressor": ["RANSAC (RANdom SAmple Consensus) algorithm."], "TheilSenRegressor": ["Theil-Sen Estimator: robust multivariate regression model."], "linear_model.TheilSenRegressor": ["Theil-Sen Estimator: robust multivariate regression model."], "sklearn.linear_model.TheilSenRegressor": ["Theil-Sen Estimator: robust multivariate regression model."], "PoissonRegressor": ["Generalized Linear Model with a Poisson distribution."], "linear_model.PoissonRegressor": ["Generalized Linear Model with a Poisson distribution."], "sklearn.linear_model.PoissonRegressor": ["Generalized Linear Model with a Poisson distribution."], "TweedieRegressor": ["Generalized Linear Model with a Tweedie distribution."], "linear_model.TweedieRegressor": ["Generalized Linear Model with a Tweedie distribution."], "sklearn.linear_model.TweedieRegressor": ["Generalized Linear Model with a Tweedie distribution."], "GammaRegressor": ["Generalized Linear Model with a Gamma distribution."], "linear_model.GammaRegressor": ["Generalized Linear Model with a Gamma distribution."], "sklearn.linear_model.GammaRegressor": ["Generalized Linear Model with a Gamma distribution."], "PassiveAggressiveRegressor": ["Passive Aggressive Regressor."], "linear_model.PassiveAggressiveRegressor": ["Passive Aggressive Regressor."], "sklearn.linear_model.PassiveAggressiveRegressor": ["Passive Aggressive Regressor."], "enet_path": ["Compute elastic net path with coordinate descent."], "linear_model.enet_path": ["Compute elastic net path with coordinate descent."], "sklearn.linear_model.enet_path": ["Compute elastic net path with coordinate descent."], "lars_path": ["Compute Least Angle Regression or Lasso path using LARS algorithm [1]."], "linear_model.lars_path": ["Compute Least Angle Regression or Lasso path using LARS algorithm [1]."], "sklearn.linear_model.lars_path": ["Compute Least Angle Regression or Lasso path using LARS algorithm [1]."], "lars_path_gram": ["lars_path in the sufficient stats mode [1]"], "linear_model.lars_path_gram": ["lars_path in the sufficient stats mode [1]"], "sklearn.linear_model.lars_path_gram": ["lars_path in the sufficient stats mode [1]"], "lasso_path": ["Compute Lasso path with coordinate descent."], "linear_model.lasso_path": ["Compute Lasso path with coordinate descent."], "sklearn.linear_model.lasso_path": ["Compute Lasso path with coordinate descent."], "orthogonal_mp": ["Orthogonal Matching Pursuit (OMP)."], "linear_model.orthogonal_mp": ["Orthogonal Matching Pursuit (OMP)."], "sklearn.linear_model.orthogonal_mp": ["Orthogonal Matching Pursuit (OMP)."], "orthogonal_mp_gram": ["Gram Orthogonal Matching Pursuit (OMP)."], "linear_model.orthogonal_mp_gram": ["Gram Orthogonal Matching Pursuit (OMP)."], "sklearn.linear_model.orthogonal_mp_gram": ["Gram Orthogonal Matching Pursuit (OMP)."], "ridge_regression": ["Solve the ridge equation by the method of normal equations."], "linear_model.ridge_regression": ["Solve the ridge equation by the method of normal equations."], "sklearn.linear_model.ridge_regression": ["Solve the ridge equation by the method of normal equations."], "Isomap": ["Isomap Embedding."], "manifold.Isomap": ["Isomap Embedding."], "sklearn.manifold.Isomap": ["Isomap Embedding."], "LocallyLinearEmbedding": ["Locally Linear Embedding."], "manifold.LocallyLinearEmbedding": ["Locally Linear Embedding."], "sklearn.manifold.LocallyLinearEmbedding": ["Locally Linear Embedding."], "MDS": ["Multidimensional scaling."], "manifold.MDS": ["Multidimensional scaling."], "sklearn.manifold.MDS": ["Multidimensional scaling."], "SpectralEmbedding": ["Spectral embedding for non-linear dimensionality reduction."], "manifold.SpectralEmbedding": ["Spectral embedding for non-linear dimensionality reduction."], "sklearn.manifold.SpectralEmbedding": ["Spectral embedding for non-linear dimensionality reduction."], "TSNE": ["T-distributed Stochastic Neighbor Embedding."], "manifold.TSNE": ["T-distributed Stochastic Neighbor Embedding."], "sklearn.manifold.TSNE": ["T-distributed Stochastic Neighbor Embedding."], "locally_linear_embedding": ["Perform a Locally Linear Embedding analysis on the data."], "manifold.locally_linear_embedding": ["Perform a Locally Linear Embedding analysis on the data."], "sklearn.manifold.locally_linear_embedding": ["Perform a Locally Linear Embedding analysis on the data."], "smacof": ["Compute multidimensional scaling using the SMACOF algorithm."], "manifold.smacof": ["Compute multidimensional scaling using the SMACOF algorithm."], "sklearn.manifold.smacof": ["Compute multidimensional scaling using the SMACOF algorithm."], "spectral_embedding": ["Project the sample on the first eigenvectors of the graph Laplacian."], "manifold.spectral_embedding": ["Project the sample on the first eigenvectors of the graph Laplacian."], "sklearn.manifold.spectral_embedding": ["Project the sample on the first eigenvectors of the graph Laplacian."], "trustworthiness": ["Expresses to what extent the local structure is retained."], "manifold.trustworthiness": ["Expresses to what extent the local structure is retained."], "sklearn.manifold.trustworthiness": ["Expresses to what extent the local structure is retained."], "check_scoring": ["Determine scorer from user options."], "metrics.check_scoring": ["Determine scorer from user options."], "sklearn.metrics.check_scoring": ["Determine scorer from user options."], "get_scorer": ["Get a scorer from string."], "metrics.get_scorer": ["Get a scorer from string."], "sklearn.metrics.get_scorer": ["Get a scorer from string."], "get_scorer_names": ["Get the names of all available scorers."], "metrics.get_scorer_names": ["Get the names of all available scorers."], "sklearn.metrics.get_scorer_names": ["Get the names of all available scorers."], "make_scorer": ["Make a scorer from a performance metric or loss function."], "metrics.make_scorer": ["Make a scorer from a performance metric or loss function."], "sklearn.metrics.make_scorer": ["Make a scorer from a performance metric or loss function."], "accuracy_score": ["Accuracy classification score."], "metrics.accuracy_score": ["Accuracy classification score."], "sklearn.metrics.accuracy_score": ["Accuracy classification score."], "auc": ["Compute Area Under the Curve (AUC) using the trapezoidal rule."], "metrics.auc": ["Compute Area Under the Curve (AUC) using the trapezoidal rule."], "sklearn.metrics.auc": ["Compute Area Under the Curve (AUC) using the trapezoidal rule."], "average_precision_score": ["Compute average precision (AP) from prediction scores."], "metrics.average_precision_score": ["Compute average precision (AP) from prediction scores."], "sklearn.metrics.average_precision_score": ["Compute average precision (AP) from prediction scores."], "balanced_accuracy_score": ["Compute the balanced accuracy."], "metrics.balanced_accuracy_score": ["Compute the balanced accuracy."], "sklearn.metrics.balanced_accuracy_score": ["Compute the balanced accuracy."], "brier_score_loss": ["Compute the Brier score loss."], "metrics.brier_score_loss": ["Compute the Brier score loss."], "sklearn.metrics.brier_score_loss": ["Compute the Brier score loss."], "classification_report": ["Build a text report showing the main classification metrics."], "metrics.classification_report": ["Build a text report showing the main classification metrics."], "sklearn.metrics.classification_report": ["Build a text report showing the main classification metrics."], "cohen_kappa_score": ["Cohen's kappa: a statistic that measures inter-annotator agreement."], "metrics.cohen_kappa_score": ["Cohen's kappa: a statistic that measures inter-annotator agreement."], "sklearn.metrics.cohen_kappa_score": ["Cohen's kappa: a statistic that measures inter-annotator agreement."], "confusion_matrix": ["Compute confusion matrix to evaluate the accuracy of a classification."], "metrics.confusion_matrix": ["Compute confusion matrix to evaluate the accuracy of a classification."], "sklearn.metrics.confusion_matrix": ["Compute confusion matrix to evaluate the accuracy of a classification."], "dcg_score": ["Compute Discounted Cumulative Gain."], "metrics.dcg_score": ["Compute Discounted Cumulative Gain."], "sklearn.metrics.dcg_score": ["Compute Discounted Cumulative Gain."], "det_curve": ["Compute error rates for different probability thresholds."], "metrics.det_curve": ["Compute error rates for different probability thresholds."], "sklearn.metrics.det_curve": ["Compute error rates for different probability thresholds."], "f1_score": ["Compute the F1 score, also known as balanced F-score or F-measure."], "metrics.f1_score": ["Compute the F1 score, also known as balanced F-score or F-measure."], "sklearn.metrics.f1_score": ["Compute the F1 score, also known as balanced F-score or F-measure."], "fbeta_score": ["Compute the F-beta score."], "metrics.fbeta_score": ["Compute the F-beta score."], "sklearn.metrics.fbeta_score": ["Compute the F-beta score."], "hamming_loss": ["Compute the average Hamming loss."], "metrics.hamming_loss": ["Compute the average Hamming loss."], "sklearn.metrics.hamming_loss": ["Compute the average Hamming loss."], "hinge_loss": ["Average hinge loss (non-regularized)."], "metrics.hinge_loss": ["Average hinge loss (non-regularized)."], "sklearn.metrics.hinge_loss": ["Average hinge loss (non-regularized)."], "jaccard_score": ["Jaccard similarity coefficient score."], "metrics.jaccard_score": ["Jaccard similarity coefficient score."], "sklearn.metrics.jaccard_score": ["Jaccard similarity coefficient score."], "log_loss": ["Log loss, aka logistic loss or cross-entropy loss."], "metrics.log_loss": ["Log loss, aka logistic loss or cross-entropy loss."], "sklearn.metrics.log_loss": ["Log loss, aka logistic loss or cross-entropy loss."], "matthews_corrcoef": ["Compute the Matthews correlation coefficient (MCC)."], "metrics.matthews_corrcoef": ["Compute the Matthews correlation coefficient (MCC)."], "sklearn.metrics.matthews_corrcoef": ["Compute the Matthews correlation coefficient (MCC)."], "multilabel_confusion_matrix": ["Compute a confusion matrix for each class or sample."], "metrics.multilabel_confusion_matrix": ["Compute a confusion matrix for each class or sample."], "sklearn.metrics.multilabel_confusion_matrix": ["Compute a confusion matrix for each class or sample."], "ndcg_score": ["Compute Normalized Discounted Cumulative Gain."], "metrics.ndcg_score": ["Compute Normalized Discounted Cumulative Gain."], "sklearn.metrics.ndcg_score": ["Compute Normalized Discounted Cumulative Gain."], "precision_recall_curve": ["Compute precision-recall pairs for different probability thresholds."], "metrics.precision_recall_curve": ["Compute precision-recall pairs for different probability thresholds."], "sklearn.metrics.precision_recall_curve": ["Compute precision-recall pairs for different probability thresholds."], "precision_recall_fscore_support": ["Compute precision, recall, F-measure and support for each class."], "metrics.precision_recall_fscore_support": ["Compute precision, recall, F-measure and support for each class."], "sklearn.metrics.precision_recall_fscore_support": ["Compute precision, recall, F-measure and support for each class."], "precision_score": ["Compute the precision."], "metrics.precision_score": ["Compute the precision."], "sklearn.metrics.precision_score": ["Compute the precision."], "recall_score": ["Compute the recall."], "metrics.recall_score": ["Compute the recall."], "sklearn.metrics.recall_score": ["Compute the recall."], "roc_auc_score": ["Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores."], "metrics.roc_auc_score": ["Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores."], "sklearn.metrics.roc_auc_score": ["Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores."], "roc_curve": ["Compute Receiver operating characteristic (ROC)."], "metrics.roc_curve": ["Compute Receiver operating characteristic (ROC)."], "sklearn.metrics.roc_curve": ["Compute Receiver operating characteristic (ROC)."], "top_k_accuracy_score": ["Top-k Accuracy classification score."], "metrics.top_k_accuracy_score": ["Top-k Accuracy classification score."], "sklearn.metrics.top_k_accuracy_score": ["Top-k Accuracy classification score."], "zero_one_loss": ["Zero-one classification loss."], "metrics.zero_one_loss": ["Zero-one classification loss."], "sklearn.metrics.zero_one_loss": ["Zero-one classification loss."], "explained_variance_score": ["Explained variance regression score function."], "metrics.explained_variance_score": ["Explained variance regression score function."], "sklearn.metrics.explained_variance_score": ["Explained variance regression score function."], "max_error": ["The max_error metric calculates the maximum residual error."], "metrics.max_error": ["The max_error metric calculates the maximum residual error."], "sklearn.metrics.max_error": ["The max_error metric calculates the maximum residual error."], "mean_absolute_error": ["Mean absolute error regression loss."], "metrics.mean_absolute_error": ["Mean absolute error regression loss."], "sklearn.metrics.mean_absolute_error": ["Mean absolute error regression loss."], "mean_squared_error": ["Mean squared error regression loss."], "metrics.mean_squared_error": ["Mean squared error regression loss."], "sklearn.metrics.mean_squared_error": ["Mean squared error regression loss."], "mean_squared_log_error": ["Mean squared logarithmic error regression loss."], "metrics.mean_squared_log_error": ["Mean squared logarithmic error regression loss."], "sklearn.metrics.mean_squared_log_error": ["Mean squared logarithmic error regression loss."], "median_absolute_error": ["Median absolute error regression loss."], "metrics.median_absolute_error": ["Median absolute error regression loss."], "sklearn.metrics.median_absolute_error": ["Median absolute error regression loss."], "mean_absolute_percentage_error": ["Mean absolute percentage error (MAPE) regression loss."], "metrics.mean_absolute_percentage_error": ["Mean absolute percentage error (MAPE) regression loss."], "sklearn.metrics.mean_absolute_percentage_error": ["Mean absolute percentage error (MAPE) regression loss."], "r2_score": ["\\(R^2\\) (coefficient of determination) regression score function."], "metrics.r2_score": ["\\(R^2\\) (coefficient of determination) regression score function."], "sklearn.metrics.r2_score": ["\\(R^2\\) (coefficient of determination) regression score function."], "mean_poisson_deviance": ["Mean Poisson deviance regression loss."], "metrics.mean_poisson_deviance": ["Mean Poisson deviance regression loss."], "sklearn.metrics.mean_poisson_deviance": ["Mean Poisson deviance regression loss."], "mean_gamma_deviance": ["Mean Gamma deviance regression loss."], "metrics.mean_gamma_deviance": ["Mean Gamma deviance regression loss."], "sklearn.metrics.mean_gamma_deviance": ["Mean Gamma deviance regression loss."], "mean_tweedie_deviance": ["Mean Tweedie deviance regression loss."], "metrics.mean_tweedie_deviance": ["Mean Tweedie deviance regression loss."], "sklearn.metrics.mean_tweedie_deviance": ["Mean Tweedie deviance regression loss."], "d2_tweedie_score": ["D^2 regression score function, fraction of Tweedie deviance explained."], "metrics.d2_tweedie_score": ["D^2 regression score function, fraction of Tweedie deviance explained."], "sklearn.metrics.d2_tweedie_score": ["D^2 regression score function, fraction of Tweedie deviance explained."], "mean_pinball_loss": ["Pinball loss for quantile regression."], "metrics.mean_pinball_loss": ["Pinball loss for quantile regression."], "sklearn.metrics.mean_pinball_loss": ["Pinball loss for quantile regression."], "d2_pinball_score": ["\\(D^2\\) regression score function, fraction of pinball loss explained."], "metrics.d2_pinball_score": ["\\(D^2\\) regression score function, fraction of pinball loss explained."], "sklearn.metrics.d2_pinball_score": ["\\(D^2\\) regression score function, fraction of pinball loss explained."], "d2_absolute_error_score": ["\\(D^2\\) regression score function,     fraction of absolute error explained."], "metrics.d2_absolute_error_score": ["\\(D^2\\) regression score function,     fraction of absolute error explained."], "sklearn.metrics.d2_absolute_error_score": ["\\(D^2\\) regression score function,     fraction of absolute error explained."], "coverage_error": ["Coverage error measure."], "metrics.coverage_error": ["Coverage error measure."], "sklearn.metrics.coverage_error": ["Coverage error measure."], "label_ranking_average_precision_score": ["Compute ranking-based average precision."], "metrics.label_ranking_average_precision_score": ["Compute ranking-based average precision."], "sklearn.metrics.label_ranking_average_precision_score": ["Compute ranking-based average precision."], "label_ranking_loss": ["Compute Ranking loss measure."], "metrics.label_ranking_loss": ["Compute Ranking loss measure."], "sklearn.metrics.label_ranking_loss": ["Compute Ranking loss measure."], "adjusted_mutual_info_score": ["Adjusted Mutual Information between two clusterings."], "metrics.adjusted_mutual_info_score": ["Adjusted Mutual Information between two clusterings."], "sklearn.metrics.adjusted_mutual_info_score": ["Adjusted Mutual Information between two clusterings."], "adjusted_rand_score": ["Rand index adjusted for chance."], "metrics.adjusted_rand_score": ["Rand index adjusted for chance."], "sklearn.metrics.adjusted_rand_score": ["Rand index adjusted for chance."], "calinski_harabasz_score": ["Compute the Calinski and Harabasz score."], "metrics.calinski_harabasz_score": ["Compute the Calinski and Harabasz score."], "sklearn.metrics.calinski_harabasz_score": ["Compute the Calinski and Harabasz score."], "davies_bouldin_score": ["Compute the Davies-Bouldin score."], "metrics.davies_bouldin_score": ["Compute the Davies-Bouldin score."], "sklearn.metrics.davies_bouldin_score": ["Compute the Davies-Bouldin score."], "completeness_score": ["Compute completeness metric of a cluster labeling given a ground truth."], "metrics.completeness_score": ["Compute completeness metric of a cluster labeling given a ground truth."], "sklearn.metrics.completeness_score": ["Compute completeness metric of a cluster labeling given a ground truth."], "contingency_matrix": ["Build a contingency matrix describing the relationship between labels."], "cluster.contingency_matrix": ["Build a contingency matrix describing the relationship between labels."], "metrics.cluster.contingency_matrix": ["Build a contingency matrix describing the relationship between labels."], "sklearn.metrics.cluster.contingency_matrix": ["Build a contingency matrix describing the relationship between labels."], "pair_confusion_matrix": ["Pair confusion matrix arising from two clusterings."], "cluster.pair_confusion_matrix": ["Pair confusion matrix arising from two clusterings."], "metrics.cluster.pair_confusion_matrix": ["Pair confusion matrix arising from two clusterings."], "sklearn.metrics.cluster.pair_confusion_matrix": ["Pair confusion matrix arising from two clusterings."], "fowlkes_mallows_score": ["Measure the similarity of two clusterings of a set of points."], "metrics.fowlkes_mallows_score": ["Measure the similarity of two clusterings of a set of points."], "sklearn.metrics.fowlkes_mallows_score": ["Measure the similarity of two clusterings of a set of points."], "homogeneity_completeness_v_measure": ["Compute the homogeneity and completeness and V-Measure scores at once."], "metrics.homogeneity_completeness_v_measure": ["Compute the homogeneity and completeness and V-Measure scores at once."], "sklearn.metrics.homogeneity_completeness_v_measure": ["Compute the homogeneity and completeness and V-Measure scores at once."], "homogeneity_score": ["Homogeneity metric of a cluster labeling given a ground truth."], "metrics.homogeneity_score": ["Homogeneity metric of a cluster labeling given a ground truth."], "sklearn.metrics.homogeneity_score": ["Homogeneity metric of a cluster labeling given a ground truth."], "mutual_info_score": ["Mutual Information between two clusterings."], "metrics.mutual_info_score": ["Mutual Information between two clusterings."], "sklearn.metrics.mutual_info_score": ["Mutual Information between two clusterings."], "normalized_mutual_info_score": ["Normalized Mutual Information between two clusterings."], "metrics.normalized_mutual_info_score": ["Normalized Mutual Information between two clusterings."], "sklearn.metrics.normalized_mutual_info_score": ["Normalized Mutual Information between two clusterings."], "rand_score": ["Rand index."], "metrics.rand_score": ["Rand index."], "sklearn.metrics.rand_score": ["Rand index."], "silhouette_score": ["Compute the mean Silhouette Coefficient of all samples."], "metrics.silhouette_score": ["Compute the mean Silhouette Coefficient of all samples."], "sklearn.metrics.silhouette_score": ["Compute the mean Silhouette Coefficient of all samples."], "silhouette_samples": ["Compute the Silhouette Coefficient for each sample."], "metrics.silhouette_samples": ["Compute the Silhouette Coefficient for each sample."], "sklearn.metrics.silhouette_samples": ["Compute the Silhouette Coefficient for each sample."], "v_measure_score": ["V-measure cluster labeling given a ground truth."], "metrics.v_measure_score": ["V-measure cluster labeling given a ground truth."], "sklearn.metrics.v_measure_score": ["V-measure cluster labeling given a ground truth."], "consensus_score": ["The similarity of two sets of biclusters."], "metrics.consensus_score": ["The similarity of two sets of biclusters."], "sklearn.metrics.consensus_score": ["The similarity of two sets of biclusters."], "DistanceMetric": ["DistanceMetric class"], "metrics.DistanceMetric": ["DistanceMetric class"], "sklearn.metrics.DistanceMetric": ["DistanceMetric class"], "additive_chi2_kernel": ["Computes the additive chi-squared kernel between observations in X and Y."], "pairwise.additive_chi2_kernel": ["Computes the additive chi-squared kernel between observations in X and Y."], "metrics.pairwise.additive_chi2_kernel": ["Computes the additive chi-squared kernel between observations in X and Y."], "sklearn.metrics.pairwise.additive_chi2_kernel": ["Computes the additive chi-squared kernel between observations in X and Y."], "chi2_kernel": ["Computes the exponential chi-squared kernel X and Y."], "pairwise.chi2_kernel": ["Computes the exponential chi-squared kernel X and Y."], "metrics.pairwise.chi2_kernel": ["Computes the exponential chi-squared kernel X and Y."], "sklearn.metrics.pairwise.chi2_kernel": ["Computes the exponential chi-squared kernel X and Y."], "cosine_similarity": ["Compute cosine similarity between samples in X and Y."], "pairwise.cosine_similarity": ["Compute cosine similarity between samples in X and Y."], "metrics.pairwise.cosine_similarity": ["Compute cosine similarity between samples in X and Y."], "sklearn.metrics.pairwise.cosine_similarity": ["Compute cosine similarity between samples in X and Y."], "cosine_distances": ["Compute cosine distance between samples in X and Y."], "pairwise.cosine_distances": ["Compute cosine distance between samples in X and Y."], "metrics.pairwise.cosine_distances": ["Compute cosine distance between samples in X and Y."], "sklearn.metrics.pairwise.cosine_distances": ["Compute cosine distance between samples in X and Y."], "distance_metrics": ["Valid metrics for pairwise_distances."], "pairwise.distance_metrics": ["Valid metrics for pairwise_distances."], "metrics.pairwise.distance_metrics": ["Valid metrics for pairwise_distances."], "sklearn.metrics.pairwise.distance_metrics": ["Valid metrics for pairwise_distances."], "euclidean_distances": ["Compute the distance matrix between each pair from a vector array X and Y."], "pairwise.euclidean_distances": ["Compute the distance matrix between each pair from a vector array X and Y."], "metrics.pairwise.euclidean_distances": ["Compute the distance matrix between each pair from a vector array X and Y."], "sklearn.metrics.pairwise.euclidean_distances": ["Compute the distance matrix between each pair from a vector array X and Y."], "haversine_distances": ["Compute the Haversine distance between samples in X and Y."], "pairwise.haversine_distances": ["Compute the Haversine distance between samples in X and Y."], "metrics.pairwise.haversine_distances": ["Compute the Haversine distance between samples in X and Y."], "sklearn.metrics.pairwise.haversine_distances": ["Compute the Haversine distance between samples in X and Y."], "kernel_metrics": ["Valid metrics for pairwise_kernels."], "pairwise.kernel_metrics": ["Valid metrics for pairwise_kernels."], "metrics.pairwise.kernel_metrics": ["Valid metrics for pairwise_kernels."], "sklearn.metrics.pairwise.kernel_metrics": ["Valid metrics for pairwise_kernels."], "laplacian_kernel": ["Compute the laplacian kernel between X and Y."], "pairwise.laplacian_kernel": ["Compute the laplacian kernel between X and Y."], "metrics.pairwise.laplacian_kernel": ["Compute the laplacian kernel between X and Y."], "sklearn.metrics.pairwise.laplacian_kernel": ["Compute the laplacian kernel between X and Y."], "linear_kernel": ["Compute the linear kernel between X and Y."], "pairwise.linear_kernel": ["Compute the linear kernel between X and Y."], "metrics.pairwise.linear_kernel": ["Compute the linear kernel between X and Y."], "sklearn.metrics.pairwise.linear_kernel": ["Compute the linear kernel between X and Y."], "manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "pairwise.manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "metrics.pairwise.manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "sklearn.metrics.pairwise.manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "nan_euclidean_distances": ["Calculate the euclidean distances in the presence of missing values."], "pairwise.nan_euclidean_distances": ["Calculate the euclidean distances in the presence of missing values."], "metrics.pairwise.nan_euclidean_distances": ["Calculate the euclidean distances in the presence of missing values."], "sklearn.metrics.pairwise.nan_euclidean_distances": ["Calculate the euclidean distances in the presence of missing values."], "pairwise_kernels": ["Compute the kernel between arrays X and optional array Y."], "pairwise.pairwise_kernels": ["Compute the kernel between arrays X and optional array Y."], "metrics.pairwise.pairwise_kernels": ["Compute the kernel between arrays X and optional array Y."], "sklearn.metrics.pairwise.pairwise_kernels": ["Compute the kernel between arrays X and optional array Y."], "polynomial_kernel": ["Compute the polynomial kernel between X and Y."], "pairwise.polynomial_kernel": ["Compute the polynomial kernel between X and Y."], "metrics.pairwise.polynomial_kernel": ["Compute the polynomial kernel between X and Y."], "sklearn.metrics.pairwise.polynomial_kernel": ["Compute the polynomial kernel between X and Y."], "rbf_kernel": ["Compute the rbf (gaussian) kernel between X and Y."], "pairwise.rbf_kernel": ["Compute the rbf (gaussian) kernel between X and Y."], "metrics.pairwise.rbf_kernel": ["Compute the rbf (gaussian) kernel between X and Y."], "sklearn.metrics.pairwise.rbf_kernel": ["Compute the rbf (gaussian) kernel between X and Y."], "sigmoid_kernel": ["Compute the sigmoid kernel between X and Y."], "pairwise.sigmoid_kernel": ["Compute the sigmoid kernel between X and Y."], "metrics.pairwise.sigmoid_kernel": ["Compute the sigmoid kernel between X and Y."], "sklearn.metrics.pairwise.sigmoid_kernel": ["Compute the sigmoid kernel between X and Y."], "paired_euclidean_distances": ["Compute the paired euclidean distances between X and Y."], "pairwise.paired_euclidean_distances": ["Compute the paired euclidean distances between X and Y."], "metrics.pairwise.paired_euclidean_distances": ["Compute the paired euclidean distances between X and Y."], "sklearn.metrics.pairwise.paired_euclidean_distances": ["Compute the paired euclidean distances between X and Y."], "paired_manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "pairwise.paired_manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "metrics.pairwise.paired_manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "sklearn.metrics.pairwise.paired_manhattan_distances": ["Compute the L1 distances between the vectors in X and Y."], "paired_cosine_distances": ["Compute the paired cosine distances between X and Y."], "pairwise.paired_cosine_distances": ["Compute the paired cosine distances between X and Y."], "metrics.pairwise.paired_cosine_distances": ["Compute the paired cosine distances between X and Y."], "sklearn.metrics.pairwise.paired_cosine_distances": ["Compute the paired cosine distances between X and Y."], "paired_distances": ["Compute the paired distances between X and Y."], "pairwise.paired_distances": ["Compute the paired distances between X and Y."], "metrics.pairwise.paired_distances": ["Compute the paired distances between X and Y."], "sklearn.metrics.pairwise.paired_distances": ["Compute the paired distances between X and Y."], "pairwise_distances": ["Compute the distance matrix from a vector array X and optional Y."], "metrics.pairwise_distances": ["Compute the distance matrix from a vector array X and optional Y."], "sklearn.metrics.pairwise_distances": ["Compute the distance matrix from a vector array X and optional Y."], "pairwise_distances_argmin": ["Compute minimum distances between one point and a set of points."], "metrics.pairwise_distances_argmin": ["Compute minimum distances between one point and a set of points."], "sklearn.metrics.pairwise_distances_argmin": ["Compute minimum distances between one point and a set of points."], "pairwise_distances_argmin_min": ["Compute minimum distances between one point and a set of points."], "metrics.pairwise_distances_argmin_min": ["Compute minimum distances between one point and a set of points."], "sklearn.metrics.pairwise_distances_argmin_min": ["Compute minimum distances between one point and a set of points."], "pairwise_distances_chunked": ["Generate a distance matrix chunk by chunk with optional reduction."], "metrics.pairwise_distances_chunked": ["Generate a distance matrix chunk by chunk with optional reduction."], "sklearn.metrics.pairwise_distances_chunked": ["Generate a distance matrix chunk by chunk with optional reduction."], "plot_confusion_matrix": ["DEPRECATED: Function plot_confusion_matrix is deprecated in 1.0 and will be removed in 1.2."], "metrics.plot_confusion_matrix": ["DEPRECATED: Function plot_confusion_matrix is deprecated in 1.0 and will be removed in 1.2."], "sklearn.metrics.plot_confusion_matrix": ["DEPRECATED: Function plot_confusion_matrix is deprecated in 1.0 and will be removed in 1.2."], "plot_det_curve": ["DEPRECATED: Function plot_det_curve is deprecated in 1.0 and will be removed in 1.2."], "metrics.plot_det_curve": ["DEPRECATED: Function plot_det_curve is deprecated in 1.0 and will be removed in 1.2."], "sklearn.metrics.plot_det_curve": ["DEPRECATED: Function plot_det_curve is deprecated in 1.0 and will be removed in 1.2."], "plot_precision_recall_curve": ["DEPRECATED: Function plot_precision_recall_curve is deprecated in 1.0 and will be removed in 1.2."], "metrics.plot_precision_recall_curve": ["DEPRECATED: Function plot_precision_recall_curve is deprecated in 1.0 and will be removed in 1.2."], "sklearn.metrics.plot_precision_recall_curve": ["DEPRECATED: Function plot_precision_recall_curve is deprecated in 1.0 and will be removed in 1.2."], "plot_roc_curve": ["DEPRECATED: Function plot_roc_curve is deprecated in 1.0 and will be removed in 1.2."], "metrics.plot_roc_curve": ["DEPRECATED: Function plot_roc_curve is deprecated in 1.0 and will be removed in 1.2."], "sklearn.metrics.plot_roc_curve": ["DEPRECATED: Function plot_roc_curve is deprecated in 1.0 and will be removed in 1.2."], "ConfusionMatrixDisplay": ["Confusion Matrix visualization."], "metrics.ConfusionMatrixDisplay": ["Confusion Matrix visualization."], "sklearn.metrics.ConfusionMatrixDisplay": ["Confusion Matrix visualization."], "DetCurveDisplay": ["DET curve visualization."], "metrics.DetCurveDisplay": ["DET curve visualization."], "sklearn.metrics.DetCurveDisplay": ["DET curve visualization."], "PrecisionRecallDisplay": ["Precision Recall visualization."], "metrics.PrecisionRecallDisplay": ["Precision Recall visualization."], "sklearn.metrics.PrecisionRecallDisplay": ["Precision Recall visualization."], "RocCurveDisplay": ["ROC Curve visualization."], "metrics.RocCurveDisplay": ["ROC Curve visualization."], "sklearn.metrics.RocCurveDisplay": ["ROC Curve visualization."], "CalibrationDisplay": ["Calibration curve (also known as reliability diagram) visualization."], "calibration.CalibrationDisplay": ["Calibration curve (also known as reliability diagram) visualization."], "sklearn.calibration.CalibrationDisplay": ["Calibration curve (also known as reliability diagram) visualization."], "BayesianGaussianMixture": ["Variational Bayesian estimation of a Gaussian mixture."], "mixture.BayesianGaussianMixture": ["Variational Bayesian estimation of a Gaussian mixture."], "sklearn.mixture.BayesianGaussianMixture": ["Variational Bayesian estimation of a Gaussian mixture."], "GaussianMixture": ["Gaussian Mixture."], "mixture.GaussianMixture": ["Gaussian Mixture."], "sklearn.mixture.GaussianMixture": ["Gaussian Mixture."], "GroupKFold": ["K-fold iterator variant with non-overlapping groups."], "model_selection.GroupKFold": ["K-fold iterator variant with non-overlapping groups."], "sklearn.model_selection.GroupKFold": ["K-fold iterator variant with non-overlapping groups."], "GroupShuffleSplit": ["Shuffle-Group(s)-Out cross-validation iterator"], "model_selection.GroupShuffleSplit": ["Shuffle-Group(s)-Out cross-validation iterator"], "sklearn.model_selection.GroupShuffleSplit": ["Shuffle-Group(s)-Out cross-validation iterator"], "KFold": ["K-Folds cross-validator"], "model_selection.KFold": ["K-Folds cross-validator"], "sklearn.model_selection.KFold": ["K-Folds cross-validator"], "LeaveOneGroupOut": ["Leave One Group Out cross-validator"], "model_selection.LeaveOneGroupOut": ["Leave One Group Out cross-validator"], "sklearn.model_selection.LeaveOneGroupOut": ["Leave One Group Out cross-validator"], "LeavePGroupsOut": ["Leave P Group(s) Out cross-validator"], "model_selection.LeavePGroupsOut": ["Leave P Group(s) Out cross-validator"], "sklearn.model_selection.LeavePGroupsOut": ["Leave P Group(s) Out cross-validator"], "LeaveOneOut": ["Leave-One-Out cross-validator"], "model_selection.LeaveOneOut": ["Leave-One-Out cross-validator"], "sklearn.model_selection.LeaveOneOut": ["Leave-One-Out cross-validator"], "LeavePOut": ["Leave-P-Out cross-validator"], "model_selection.LeavePOut": ["Leave-P-Out cross-validator"], "sklearn.model_selection.LeavePOut": ["Leave-P-Out cross-validator"], "PredefinedSplit": ["Predefined split cross-validator"], "model_selection.PredefinedSplit": ["Predefined split cross-validator"], "sklearn.model_selection.PredefinedSplit": ["Predefined split cross-validator"], "RepeatedKFold": ["Repeated K-Fold cross validator."], "model_selection.RepeatedKFold": ["Repeated K-Fold cross validator."], "sklearn.model_selection.RepeatedKFold": ["Repeated K-Fold cross validator."], "RepeatedStratifiedKFold": ["Repeated Stratified K-Fold cross validator."], "model_selection.RepeatedStratifiedKFold": ["Repeated Stratified K-Fold cross validator."], "sklearn.model_selection.RepeatedStratifiedKFold": ["Repeated Stratified K-Fold cross validator."], "ShuffleSplit": ["Random permutation cross-validator"], "model_selection.ShuffleSplit": ["Random permutation cross-validator"], "sklearn.model_selection.ShuffleSplit": ["Random permutation cross-validator"], "StratifiedKFold": ["Stratified K-Folds cross-validator."], "model_selection.StratifiedKFold": ["Stratified K-Folds cross-validator."], "sklearn.model_selection.StratifiedKFold": ["Stratified K-Folds cross-validator."], "StratifiedShuffleSplit": ["Stratified ShuffleSplit cross-validator"], "model_selection.StratifiedShuffleSplit": ["Stratified ShuffleSplit cross-validator"], "sklearn.model_selection.StratifiedShuffleSplit": ["Stratified ShuffleSplit cross-validator"], "StratifiedGroupKFold": ["Stratified K-Folds iterator variant with non-overlapping groups."], "model_selection.StratifiedGroupKFold": ["Stratified K-Folds iterator variant with non-overlapping groups."], "sklearn.model_selection.StratifiedGroupKFold": ["Stratified K-Folds iterator variant with non-overlapping groups."], "TimeSeriesSplit": ["Time Series cross-validator"], "model_selection.TimeSeriesSplit": ["Time Series cross-validator"], "sklearn.model_selection.TimeSeriesSplit": ["Time Series cross-validator"], "check_cv": ["Input checker utility for building a cross-validator."], "model_selection.check_cv": ["Input checker utility for building a cross-validator."], "sklearn.model_selection.check_cv": ["Input checker utility for building a cross-validator."], "train_test_split": ["Split arrays or matrices into random train and test subsets."], "model_selection.train_test_split": ["Split arrays or matrices into random train and test subsets."], "sklearn.model_selection.train_test_split": ["Split arrays or matrices into random train and test subsets."], "GridSearchCV": ["Exhaustive search over specified parameter values for an estimator."], "model_selection.GridSearchCV": ["Exhaustive search over specified parameter values for an estimator."], "sklearn.model_selection.GridSearchCV": ["Exhaustive search over specified parameter values for an estimator."], "HalvingGridSearchCV": ["Search over specified parameter values with successive halving."], "model_selection.HalvingGridSearchCV": ["Search over specified parameter values with successive halving."], "sklearn.model_selection.HalvingGridSearchCV": ["Search over specified parameter values with successive halving."], "ParameterGrid": ["Grid of parameters with a discrete number of values for each."], "model_selection.ParameterGrid": ["Grid of parameters with a discrete number of values for each."], "sklearn.model_selection.ParameterGrid": ["Grid of parameters with a discrete number of values for each."], "ParameterSampler": ["Generator on parameters sampled from given distributions."], "model_selection.ParameterSampler": ["Generator on parameters sampled from given distributions."], "sklearn.model_selection.ParameterSampler": ["Generator on parameters sampled from given distributions."], "RandomizedSearchCV": ["Randomized search on hyper parameters."], "model_selection.RandomizedSearchCV": ["Randomized search on hyper parameters."], "sklearn.model_selection.RandomizedSearchCV": ["Randomized search on hyper parameters."], "HalvingRandomSearchCV": ["Randomized search on hyper parameters."], "model_selection.HalvingRandomSearchCV": ["Randomized search on hyper parameters."], "sklearn.model_selection.HalvingRandomSearchCV": ["Randomized search on hyper parameters."], "cross_validate": ["Evaluate metric(s) by cross-validation and also record fit/score times."], "model_selection.cross_validate": ["Evaluate metric(s) by cross-validation and also record fit/score times."], "sklearn.model_selection.cross_validate": ["Evaluate metric(s) by cross-validation and also record fit/score times."], "cross_val_predict": ["Generate cross-validated estimates for each input data point."], "model_selection.cross_val_predict": ["Generate cross-validated estimates for each input data point."], "sklearn.model_selection.cross_val_predict": ["Generate cross-validated estimates for each input data point."], "cross_val_score": ["Evaluate a score by cross-validation."], "model_selection.cross_val_score": ["Evaluate a score by cross-validation."], "sklearn.model_selection.cross_val_score": ["Evaluate a score by cross-validation."], "learning_curve": ["Learning curve."], "model_selection.learning_curve": ["Learning curve."], "sklearn.model_selection.learning_curve": ["Learning curve."], "permutation_test_score": ["Evaluate the significance of a cross-validated score with permutations"], "model_selection.permutation_test_score": ["Evaluate the significance of a cross-validated score with permutations"], "sklearn.model_selection.permutation_test_score": ["Evaluate the significance of a cross-validated score with permutations"], "validation_curve": ["Validation curve."], "model_selection.validation_curve": ["Validation curve."], "sklearn.model_selection.validation_curve": ["Validation curve."], "OneVsRestClassifier": ["One-vs-the-rest (OvR) multiclass strategy."], "multiclass.OneVsRestClassifier": ["One-vs-the-rest (OvR) multiclass strategy."], "sklearn.multiclass.OneVsRestClassifier": ["One-vs-the-rest (OvR) multiclass strategy."], "OneVsOneClassifier": ["One-vs-one multiclass strategy."], "multiclass.OneVsOneClassifier": ["One-vs-one multiclass strategy."], "sklearn.multiclass.OneVsOneClassifier": ["One-vs-one multiclass strategy."], "OutputCodeClassifier": ["(Error-Correcting) Output-Code multiclass strategy."], "multiclass.OutputCodeClassifier": ["(Error-Correcting) Output-Code multiclass strategy."], "sklearn.multiclass.OutputCodeClassifier": ["(Error-Correcting) Output-Code multiclass strategy."], "ClassifierChain": ["A multi-label model that arranges binary classifiers into a chain."], "multioutput.ClassifierChain": ["A multi-label model that arranges binary classifiers into a chain."], "sklearn.multioutput.ClassifierChain": ["A multi-label model that arranges binary classifiers into a chain."], "MultiOutputRegressor": ["Multi target regression."], "multioutput.MultiOutputRegressor": ["Multi target regression."], "sklearn.multioutput.MultiOutputRegressor": ["Multi target regression."], "MultiOutputClassifier": ["Multi target classification."], "multioutput.MultiOutputClassifier": ["Multi target classification."], "sklearn.multioutput.MultiOutputClassifier": ["Multi target classification."], "RegressorChain": ["A multi-label model that arranges regressions into a chain."], "multioutput.RegressorChain": ["A multi-label model that arranges regressions into a chain."], "sklearn.multioutput.RegressorChain": ["A multi-label model that arranges regressions into a chain."], "BernoulliNB": ["Naive Bayes classifier for multivariate Bernoulli models."], "naive_bayes.BernoulliNB": ["Naive Bayes classifier for multivariate Bernoulli models."], "sklearn.naive_bayes.BernoulliNB": ["Naive Bayes classifier for multivariate Bernoulli models."], "CategoricalNB": ["Naive Bayes classifier for categorical features."], "naive_bayes.CategoricalNB": ["Naive Bayes classifier for categorical features."], "sklearn.naive_bayes.CategoricalNB": ["Naive Bayes classifier for categorical features."], "ComplementNB": ["The Complement Naive Bayes classifier described in Rennie et al. (2003)."], "naive_bayes.ComplementNB": ["The Complement Naive Bayes classifier described in Rennie et al. (2003)."], "sklearn.naive_bayes.ComplementNB": ["The Complement Naive Bayes classifier described in Rennie et al. (2003)."], "GaussianNB": ["Gaussian Naive Bayes (GaussianNB)."], "naive_bayes.GaussianNB": ["Gaussian Naive Bayes (GaussianNB)."], "sklearn.naive_bayes.GaussianNB": ["Gaussian Naive Bayes (GaussianNB)."], "MultinomialNB": ["Naive Bayes classifier for multinomial models."], "naive_bayes.MultinomialNB": ["Naive Bayes classifier for multinomial models."], "sklearn.naive_bayes.MultinomialNB": ["Naive Bayes classifier for multinomial models."], "BallTree": ["BallTree for fast generalized N-point problems"], "neighbors.BallTree": ["BallTree for fast generalized N-point problems"], "sklearn.neighbors.BallTree": ["BallTree for fast generalized N-point problems"], "KDTree": ["KDTree for fast generalized N-point problems"], "neighbors.KDTree": ["KDTree for fast generalized N-point problems"], "sklearn.neighbors.KDTree": ["KDTree for fast generalized N-point problems"], "KernelDensity": ["Kernel Density Estimation."], "neighbors.KernelDensity": ["Kernel Density Estimation."], "sklearn.neighbors.KernelDensity": ["Kernel Density Estimation."], "KNeighborsClassifier": ["Classifier implementing the k-nearest neighbors vote."], "neighbors.KNeighborsClassifier": ["Classifier implementing the k-nearest neighbors vote."], "sklearn.neighbors.KNeighborsClassifier": ["Classifier implementing the k-nearest neighbors vote."], "KNeighborsRegressor": ["Regression based on k-nearest neighbors."], "neighbors.KNeighborsRegressor": ["Regression based on k-nearest neighbors."], "sklearn.neighbors.KNeighborsRegressor": ["Regression based on k-nearest neighbors."], "KNeighborsTransformer": ["Transform X into a (weighted) graph of k nearest neighbors."], "neighbors.KNeighborsTransformer": ["Transform X into a (weighted) graph of k nearest neighbors."], "sklearn.neighbors.KNeighborsTransformer": ["Transform X into a (weighted) graph of k nearest neighbors."], "LocalOutlierFactor": ["Unsupervised Outlier Detection using the Local Outlier Factor (LOF)."], "neighbors.LocalOutlierFactor": ["Unsupervised Outlier Detection using the Local Outlier Factor (LOF)."], "sklearn.neighbors.LocalOutlierFactor": ["Unsupervised Outlier Detection using the Local Outlier Factor (LOF)."], "RadiusNeighborsClassifier": ["Classifier implementing a vote among neighbors within a given radius."], "neighbors.RadiusNeighborsClassifier": ["Classifier implementing a vote among neighbors within a given radius."], "sklearn.neighbors.RadiusNeighborsClassifier": ["Classifier implementing a vote among neighbors within a given radius."], "RadiusNeighborsRegressor": ["Regression based on neighbors within a fixed radius."], "neighbors.RadiusNeighborsRegressor": ["Regression based on neighbors within a fixed radius."], "sklearn.neighbors.RadiusNeighborsRegressor": ["Regression based on neighbors within a fixed radius."], "RadiusNeighborsTransformer": ["Transform X into a (weighted) graph of neighbors nearer than a radius."], "neighbors.RadiusNeighborsTransformer": ["Transform X into a (weighted) graph of neighbors nearer than a radius."], "sklearn.neighbors.RadiusNeighborsTransformer": ["Transform X into a (weighted) graph of neighbors nearer than a radius."], "NearestCentroid": ["Nearest centroid classifier."], "neighbors.NearestCentroid": ["Nearest centroid classifier."], "sklearn.neighbors.NearestCentroid": ["Nearest centroid classifier."], "NearestNeighbors": ["Unsupervised learner for implementing neighbor searches."], "neighbors.NearestNeighbors": ["Unsupervised learner for implementing neighbor searches."], "sklearn.neighbors.NearestNeighbors": ["Unsupervised learner for implementing neighbor searches."], "NeighborhoodComponentsAnalysis": ["Neighborhood Components Analysis."], "neighbors.NeighborhoodComponentsAnalysis": ["Neighborhood Components Analysis."], "sklearn.neighbors.NeighborhoodComponentsAnalysis": ["Neighborhood Components Analysis."], "kneighbors_graph": ["Compute the (weighted) graph of k-Neighbors for points in X."], "neighbors.kneighbors_graph": ["Compute the (weighted) graph of k-Neighbors for points in X."], "sklearn.neighbors.kneighbors_graph": ["Compute the (weighted) graph of k-Neighbors for points in X."], "radius_neighbors_graph": ["Compute the (weighted) graph of Neighbors for points in X."], "neighbors.radius_neighbors_graph": ["Compute the (weighted) graph of Neighbors for points in X."], "sklearn.neighbors.radius_neighbors_graph": ["Compute the (weighted) graph of Neighbors for points in X."], "BernoulliRBM": ["Bernoulli Restricted Boltzmann Machine (RBM)."], "neural_network.BernoulliRBM": ["Bernoulli Restricted Boltzmann Machine (RBM)."], "sklearn.neural_network.BernoulliRBM": ["Bernoulli Restricted Boltzmann Machine (RBM)."], "MLPClassifier": ["Multi-layer Perceptron classifier."], "neural_network.MLPClassifier": ["Multi-layer Perceptron classifier."], "sklearn.neural_network.MLPClassifier": ["Multi-layer Perceptron classifier."], "MLPRegressor": ["Multi-layer Perceptron regressor."], "neural_network.MLPRegressor": ["Multi-layer Perceptron regressor."], "sklearn.neural_network.MLPRegressor": ["Multi-layer Perceptron regressor."], "FeatureUnion": ["Concatenates results of multiple transformer objects."], "pipeline.FeatureUnion": ["Concatenates results of multiple transformer objects."], "sklearn.pipeline.FeatureUnion": ["Concatenates results of multiple transformer objects."], "Pipeline": ["Pipeline of transforms with a final estimator."], "pipeline.Pipeline": ["Pipeline of transforms with a final estimator."], "sklearn.pipeline.Pipeline": ["Pipeline of transforms with a final estimator."], "make_pipeline": ["Construct a Pipeline from the given estimators."], "pipeline.make_pipeline": ["Construct a Pipeline from the given estimators."], "sklearn.pipeline.make_pipeline": ["Construct a Pipeline from the given estimators."], "make_union": ["Construct a FeatureUnion from the given transformers."], "pipeline.make_union": ["Construct a FeatureUnion from the given transformers."], "sklearn.pipeline.make_union": ["Construct a FeatureUnion from the given transformers."], "Binarizer": ["Binarize data (set feature values to 0 or 1) according to a threshold."], "preprocessing.Binarizer": ["Binarize data (set feature values to 0 or 1) according to a threshold."], "sklearn.preprocessing.Binarizer": ["Binarize data (set feature values to 0 or 1) according to a threshold."], "FunctionTransformer": ["Constructs a transformer from an arbitrary callable."], "preprocessing.FunctionTransformer": ["Constructs a transformer from an arbitrary callable."], "sklearn.preprocessing.FunctionTransformer": ["Constructs a transformer from an arbitrary callable."], "KBinsDiscretizer": ["Bin continuous data into intervals."], "preprocessing.KBinsDiscretizer": ["Bin continuous data into intervals."], "sklearn.preprocessing.KBinsDiscretizer": ["Bin continuous data into intervals."], "KernelCenterer": ["Center an arbitrary kernel matrix \\(K\\)."], "preprocessing.KernelCenterer": ["Center an arbitrary kernel matrix \\(K\\)."], "sklearn.preprocessing.KernelCenterer": ["Center an arbitrary kernel matrix \\(K\\)."], "LabelBinarizer": ["Binarize labels in a one-vs-all fashion."], "preprocessing.LabelBinarizer": ["Binarize labels in a one-vs-all fashion."], "sklearn.preprocessing.LabelBinarizer": ["Binarize labels in a one-vs-all fashion."], "LabelEncoder": ["Encode target labels with value between 0 and n_classes-1."], "preprocessing.LabelEncoder": ["Encode target labels with value between 0 and n_classes-1."], "sklearn.preprocessing.LabelEncoder": ["Encode target labels with value between 0 and n_classes-1."], "MultiLabelBinarizer": ["Transform between iterable of iterables and a multilabel format."], "preprocessing.MultiLabelBinarizer": ["Transform between iterable of iterables and a multilabel format."], "sklearn.preprocessing.MultiLabelBinarizer": ["Transform between iterable of iterables and a multilabel format."], "MaxAbsScaler": ["Scale each feature by its maximum absolute value."], "preprocessing.MaxAbsScaler": ["Scale each feature by its maximum absolute value."], "sklearn.preprocessing.MaxAbsScaler": ["Scale each feature by its maximum absolute value."], "MinMaxScaler": ["Transform features by scaling each feature to a given range."], "preprocessing.MinMaxScaler": ["Transform features by scaling each feature to a given range."], "sklearn.preprocessing.MinMaxScaler": ["Transform features by scaling each feature to a given range."], "Normalizer": ["Normalize samples individually to unit norm."], "preprocessing.Normalizer": ["Normalize samples individually to unit norm."], "sklearn.preprocessing.Normalizer": ["Normalize samples individually to unit norm."], "OneHotEncoder": ["Encode categorical features as a one-hot numeric array."], "preprocessing.OneHotEncoder": ["Encode categorical features as a one-hot numeric array."], "sklearn.preprocessing.OneHotEncoder": ["Encode categorical features as a one-hot numeric array."], "OrdinalEncoder": ["Encode categorical features as an integer array."], "preprocessing.OrdinalEncoder": ["Encode categorical features as an integer array."], "sklearn.preprocessing.OrdinalEncoder": ["Encode categorical features as an integer array."], "PolynomialFeatures": ["Generate polynomial and interaction features."], "preprocessing.PolynomialFeatures": ["Generate polynomial and interaction features."], "sklearn.preprocessing.PolynomialFeatures": ["Generate polynomial and interaction features."], "PowerTransformer": ["Apply a power transform featurewise to make data more Gaussian-like."], "preprocessing.PowerTransformer": ["Apply a power transform featurewise to make data more Gaussian-like."], "sklearn.preprocessing.PowerTransformer": ["Apply a power transform featurewise to make data more Gaussian-like."], "QuantileTransformer": ["Transform features using quantiles information."], "preprocessing.QuantileTransformer": ["Transform features using quantiles information."], "sklearn.preprocessing.QuantileTransformer": ["Transform features using quantiles information."], "RobustScaler": ["Scale features using statistics that are robust to outliers."], "preprocessing.RobustScaler": ["Scale features using statistics that are robust to outliers."], "sklearn.preprocessing.RobustScaler": ["Scale features using statistics that are robust to outliers."], "SplineTransformer": ["Generate univariate B-spline bases for features."], "preprocessing.SplineTransformer": ["Generate univariate B-spline bases for features."], "sklearn.preprocessing.SplineTransformer": ["Generate univariate B-spline bases for features."], "StandardScaler": ["Standardize features by removing the mean and scaling to unit variance."], "preprocessing.StandardScaler": ["Standardize features by removing the mean and scaling to unit variance."], "sklearn.preprocessing.StandardScaler": ["Standardize features by removing the mean and scaling to unit variance."], "add_dummy_feature": ["Augment dataset with an additional dummy feature."], "preprocessing.add_dummy_feature": ["Augment dataset with an additional dummy feature."], "sklearn.preprocessing.add_dummy_feature": ["Augment dataset with an additional dummy feature."], "binarize": ["Boolean thresholding of array-like or scipy.sparse matrix."], "preprocessing.binarize": ["Boolean thresholding of array-like or scipy.sparse matrix."], "sklearn.preprocessing.binarize": ["Boolean thresholding of array-like or scipy.sparse matrix."], "label_binarize": ["Binarize labels in a one-vs-all fashion."], "preprocessing.label_binarize": ["Binarize labels in a one-vs-all fashion."], "sklearn.preprocessing.label_binarize": ["Binarize labels in a one-vs-all fashion."], "maxabs_scale": ["Scale each feature to the [-1, 1] range without breaking the sparsity."], "preprocessing.maxabs_scale": ["Scale each feature to the [-1, 1] range without breaking the sparsity."], "sklearn.preprocessing.maxabs_scale": ["Scale each feature to the [-1, 1] range without breaking the sparsity."], "minmax_scale": ["Transform features by scaling each feature to a given range."], "preprocessing.minmax_scale": ["Transform features by scaling each feature to a given range."], "sklearn.preprocessing.minmax_scale": ["Transform features by scaling each feature to a given range."], "preprocessing.normalize": ["Scale input vectors individually to unit norm (vector length)."], "sklearn.preprocessing.normalize": ["Scale input vectors individually to unit norm (vector length)."], "quantile_transform": ["Transform features using quantiles information."], "preprocessing.quantile_transform": ["Transform features using quantiles information."], "sklearn.preprocessing.quantile_transform": ["Transform features using quantiles information."], "robust_scale": ["Standardize a dataset along any axis."], "preprocessing.robust_scale": ["Standardize a dataset along any axis."], "sklearn.preprocessing.robust_scale": ["Standardize a dataset along any axis."], "scale": ["Standardize a dataset along any axis."], "preprocessing.scale": ["Standardize a dataset along any axis."], "sklearn.preprocessing.scale": ["Standardize a dataset along any axis."], "power_transform": ["Parametric, monotonic transformation to make data more Gaussian-like."], "preprocessing.power_transform": ["Parametric, monotonic transformation to make data more Gaussian-like."], "sklearn.preprocessing.power_transform": ["Parametric, monotonic transformation to make data more Gaussian-like."], "GaussianRandomProjection": ["Reduce dimensionality through Gaussian random projection."], "random_projection.GaussianRandomProjection": ["Reduce dimensionality through Gaussian random projection."], "sklearn.random_projection.GaussianRandomProjection": ["Reduce dimensionality through Gaussian random projection."], "SparseRandomProjection": ["Reduce dimensionality through sparse random projection."], "random_projection.SparseRandomProjection": ["Reduce dimensionality through sparse random projection."], "sklearn.random_projection.SparseRandomProjection": ["Reduce dimensionality through sparse random projection."], "johnson_lindenstrauss_min_dim": ["Find a 'safe' number of components to randomly project to."], "random_projection.johnson_lindenstrauss_min_dim": ["Find a 'safe' number of components to randomly project to."], "sklearn.random_projection.johnson_lindenstrauss_min_dim": ["Find a 'safe' number of components to randomly project to."], "LabelPropagation": ["Label Propagation classifier."], "semi_supervised.LabelPropagation": ["Label Propagation classifier."], "sklearn.semi_supervised.LabelPropagation": ["Label Propagation classifier."], "LabelSpreading": ["LabelSpreading model for semi-supervised learning."], "semi_supervised.LabelSpreading": ["LabelSpreading model for semi-supervised learning."], "sklearn.semi_supervised.LabelSpreading": ["LabelSpreading model for semi-supervised learning."], "SelfTrainingClassifier": ["Self-training classifier."], "semi_supervised.SelfTrainingClassifier": ["Self-training classifier."], "sklearn.semi_supervised.SelfTrainingClassifier": ["Self-training classifier."], "LinearSVC": ["Linear Support Vector Classification."], "svm.LinearSVC": ["Linear Support Vector Classification."], "sklearn.svm.LinearSVC": ["Linear Support Vector Classification."], "LinearSVR": ["Linear Support Vector Regression."], "svm.LinearSVR": ["Linear Support Vector Regression."], "sklearn.svm.LinearSVR": ["Linear Support Vector Regression."], "NuSVC": ["Nu-Support Vector Classification."], "svm.NuSVC": ["Nu-Support Vector Classification."], "sklearn.svm.NuSVC": ["Nu-Support Vector Classification."], "NuSVR": ["Nu Support Vector Regression."], "svm.NuSVR": ["Nu Support Vector Regression."], "sklearn.svm.NuSVR": ["Nu Support Vector Regression."], "OneClassSVM": ["Unsupervised Outlier Detection."], "svm.OneClassSVM": ["Unsupervised Outlier Detection."], "sklearn.svm.OneClassSVM": ["Unsupervised Outlier Detection."], "SVC": ["C-Support Vector Classification."], "svm.SVC": ["C-Support Vector Classification."], "sklearn.svm.SVC": ["C-Support Vector Classification."], "SVR": ["Epsilon-Support Vector Regression."], "svm.SVR": ["Epsilon-Support Vector Regression."], "sklearn.svm.SVR": ["Epsilon-Support Vector Regression."], "l1_min_c": ["Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty."], "svm.l1_min_c": ["Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty."], "sklearn.svm.l1_min_c": ["Return the lowest bound for C such that for C in (l1_min_C, infinity) the model is guaranteed not to be empty."], "DecisionTreeClassifier": ["A decision tree classifier."], "tree.DecisionTreeClassifier": ["A decision tree classifier."], "sklearn.tree.DecisionTreeClassifier": ["A decision tree classifier."], "DecisionTreeRegressor": ["A decision tree regressor."], "tree.DecisionTreeRegressor": ["A decision tree regressor."], "sklearn.tree.DecisionTreeRegressor": ["A decision tree regressor."], "ExtraTreeClassifier": ["An extremely randomized tree classifier."], "tree.ExtraTreeClassifier": ["An extremely randomized tree classifier."], "sklearn.tree.ExtraTreeClassifier": ["An extremely randomized tree classifier."], "ExtraTreeRegressor": ["An extremely randomized tree regressor."], "tree.ExtraTreeRegressor": ["An extremely randomized tree regressor."], "sklearn.tree.ExtraTreeRegressor": ["An extremely randomized tree regressor."], "export_graphviz": ["Export a decision tree in DOT format."], "tree.export_graphviz": ["Export a decision tree in DOT format."], "sklearn.tree.export_graphviz": ["Export a decision tree in DOT format."], "export_text": ["Build a text report showing the rules of a decision tree."], "tree.export_text": ["Build a text report showing the rules of a decision tree."], "sklearn.tree.export_text": ["Build a text report showing the rules of a decision tree."], "plot_tree": ["Plot a decision tree."], "tree.plot_tree": ["Plot a decision tree."], "sklearn.tree.plot_tree": ["Plot a decision tree."], "Bunch": ["Container object exposing keys as attributes."], "utils.Bunch": ["Container object exposing keys as attributes."], "sklearn.utils.Bunch": ["Container object exposing keys as attributes."], "min_pos": ["Find the minimum value of an array over positive values"], "arrayfuncs.min_pos": ["Find the minimum value of an array over positive values"], "utils.arrayfuncs.min_pos": ["Find the minimum value of an array over positive values"], "sklearn.utils.arrayfuncs.min_pos": ["Find the minimum value of an array over positive values"], "as_float_array": ["Convert an array-like to an array of floats."], "utils.as_float_array": ["Convert an array-like to an array of floats."], "sklearn.utils.as_float_array": ["Convert an array-like to an array of floats."], "assert_all_finite": ["Throw a ValueError if X contains NaN or infinity."], "utils.assert_all_finite": ["Throw a ValueError if X contains NaN or infinity."], "sklearn.utils.assert_all_finite": ["Throw a ValueError if X contains NaN or infinity."], "check_X_y": ["Input validation for standard estimators."], "utils.check_X_y": ["Input validation for standard estimators."], "sklearn.utils.check_X_y": ["Input validation for standard estimators."], "check_array": ["Input validation on an array, list, sparse matrix or similar."], "utils.check_array": ["Input validation on an array, list, sparse matrix or similar."], "sklearn.utils.check_array": ["Input validation on an array, list, sparse matrix or similar."], "check_scalar": ["Validate scalar parameters type and value."], "utils.check_scalar": ["Validate scalar parameters type and value."], "sklearn.utils.check_scalar": ["Validate scalar parameters type and value."], "check_consistent_length": ["Check that all arrays have consistent first dimensions."], "utils.check_consistent_length": ["Check that all arrays have consistent first dimensions."], "sklearn.utils.check_consistent_length": ["Check that all arrays have consistent first dimensions."], "check_random_state": ["Turn seed into a np.random.RandomState instance."], "utils.check_random_state": ["Turn seed into a np.random.RandomState instance."], "sklearn.utils.check_random_state": ["Turn seed into a np.random.RandomState instance."], "compute_class_weight": ["Estimate class weights for unbalanced datasets."], "class_weight.compute_class_weight": ["Estimate class weights for unbalanced datasets."], "utils.class_weight.compute_class_weight": ["Estimate class weights for unbalanced datasets."], "sklearn.utils.class_weight.compute_class_weight": ["Estimate class weights for unbalanced datasets."], "compute_sample_weight": ["Estimate sample weights by class for unbalanced datasets."], "class_weight.compute_sample_weight": ["Estimate sample weights by class for unbalanced datasets."], "utils.class_weight.compute_sample_weight": ["Estimate sample weights by class for unbalanced datasets."], "sklearn.utils.class_weight.compute_sample_weight": ["Estimate sample weights by class for unbalanced datasets."], "deprecated": ["Decorator to mark a function or class as deprecated."], "utils.deprecated": ["Decorator to mark a function or class as deprecated."], "sklearn.utils.deprecated": ["Decorator to mark a function or class as deprecated."], "check_estimator": ["Check if estimator adheres to scikit-learn conventions."], "estimator_checks.check_estimator": ["Check if estimator adheres to scikit-learn conventions."], "utils.estimator_checks.check_estimator": ["Check if estimator adheres to scikit-learn conventions."], "sklearn.utils.estimator_checks.check_estimator": ["Check if estimator adheres to scikit-learn conventions."], "parametrize_with_checks": ["Pytest specific decorator for parametrizing estimator checks."], "estimator_checks.parametrize_with_checks": ["Pytest specific decorator for parametrizing estimator checks."], "utils.estimator_checks.parametrize_with_checks": ["Pytest specific decorator for parametrizing estimator checks."], "sklearn.utils.estimator_checks.parametrize_with_checks": ["Pytest specific decorator for parametrizing estimator checks."], "estimator_html_repr": ["Build a HTML representation of an estimator."], "utils.estimator_html_repr": ["Build a HTML representation of an estimator."], "sklearn.utils.estimator_html_repr": ["Build a HTML representation of an estimator."], "safe_sparse_dot": ["Dot product that handle the sparse matrix case correctly."], "extmath.safe_sparse_dot": ["Dot product that handle the sparse matrix case correctly."], "utils.extmath.safe_sparse_dot": ["Dot product that handle the sparse matrix case correctly."], "sklearn.utils.extmath.safe_sparse_dot": ["Dot product that handle the sparse matrix case correctly."], "randomized_range_finder": ["Compute an orthonormal matrix whose range approximates the range of A."], "extmath.randomized_range_finder": ["Compute an orthonormal matrix whose range approximates the range of A."], "utils.extmath.randomized_range_finder": ["Compute an orthonormal matrix whose range approximates the range of A."], "sklearn.utils.extmath.randomized_range_finder": ["Compute an orthonormal matrix whose range approximates the range of A."], "randomized_svd": ["Computes a truncated randomized SVD."], "extmath.randomized_svd": ["Computes a truncated randomized SVD."], "utils.extmath.randomized_svd": ["Computes a truncated randomized SVD."], "sklearn.utils.extmath.randomized_svd": ["Computes a truncated randomized SVD."], "fast_logdet": ["Compute log(det(A)) for A symmetric."], "extmath.fast_logdet": ["Compute log(det(A)) for A symmetric."], "utils.extmath.fast_logdet": ["Compute log(det(A)) for A symmetric."], "sklearn.utils.extmath.fast_logdet": ["Compute log(det(A)) for A symmetric."], "extmath.density": ["Compute density of a sparse vector."], "utils.extmath.density": ["Compute density of a sparse vector."], "sklearn.utils.extmath.density": ["Compute density of a sparse vector."], "weighted_mode": ["Returns an array of the weighted modal (most common) value in a."], "extmath.weighted_mode": ["Returns an array of the weighted modal (most common) value in a."], "utils.extmath.weighted_mode": ["Returns an array of the weighted modal (most common) value in a."], "sklearn.utils.extmath.weighted_mode": ["Returns an array of the weighted modal (most common) value in a."], "gen_batches": ["Generator to create slices containing batch_size elements, from 0 to n."], "utils.gen_batches": ["Generator to create slices containing batch_size elements, from 0 to n."], "sklearn.utils.gen_batches": ["Generator to create slices containing batch_size elements, from 0 to n."], "gen_even_slices": ["Generator to create n_packs slices going up to n."], "utils.gen_even_slices": ["Generator to create n_packs slices going up to n."], "sklearn.utils.gen_even_slices": ["Generator to create n_packs slices going up to n."], "single_source_shortest_path_length": ["Return the shortest path length from source to all reachable nodes."], "graph.single_source_shortest_path_length": ["Return the shortest path length from source to all reachable nodes."], "utils.graph.single_source_shortest_path_length": ["Return the shortest path length from source to all reachable nodes."], "sklearn.utils.graph.single_source_shortest_path_length": ["Return the shortest path length from source to all reachable nodes."], "indexable": ["Make arrays indexable for cross-validation."], "utils.indexable": ["Make arrays indexable for cross-validation."], "sklearn.utils.indexable": ["Make arrays indexable for cross-validation."], "available_if": ["An attribute that is available only if check returns a truthy value"], "metaestimators.available_if": ["An attribute that is available only if check returns a truthy value"], "utils.metaestimators.available_if": ["An attribute that is available only if check returns a truthy value"], "sklearn.utils.metaestimators.available_if": ["An attribute that is available only if check returns a truthy value"], "type_of_target": ["Determine the type of data indicated by the target."], "multiclass.type_of_target": ["Determine the type of data indicated by the target."], "utils.multiclass.type_of_target": ["Determine the type of data indicated by the target."], "sklearn.utils.multiclass.type_of_target": ["Determine the type of data indicated by the target."], "is_multilabel": ["Check if y is in a multilabel format."], "multiclass.is_multilabel": ["Check if y is in a multilabel format."], "utils.multiclass.is_multilabel": ["Check if y is in a multilabel format."], "sklearn.utils.multiclass.is_multilabel": ["Check if y is in a multilabel format."], "unique_labels": ["Extract an ordered array of unique labels."], "multiclass.unique_labels": ["Extract an ordered array of unique labels."], "utils.multiclass.unique_labels": ["Extract an ordered array of unique labels."], "sklearn.utils.multiclass.unique_labels": ["Extract an ordered array of unique labels."], "murmurhash3_32": ["Compute the 32bit murmurhash3 of key at seed."], "utils.murmurhash3_32": ["Compute the 32bit murmurhash3 of key at seed."], "sklearn.utils.murmurhash3_32": ["Compute the 32bit murmurhash3 of key at seed."], "utils.resample": ["Resample arrays or sparse matrices in a consistent way."], "sklearn.utils.resample": ["Resample arrays or sparse matrices in a consistent way."], "_safe_indexing": ["Return rows, items or columns of X using indices."], "utils._safe_indexing": ["Return rows, items or columns of X using indices."], "sklearn.utils._safe_indexing": ["Return rows, items or columns of X using indices."], "safe_mask": ["Return a mask which is safe to use on X."], "utils.safe_mask": ["Return a mask which is safe to use on X."], "sklearn.utils.safe_mask": ["Return a mask which is safe to use on X."], "safe_sqr": ["Element wise squaring of array-likes and sparse matrices."], "utils.safe_sqr": ["Element wise squaring of array-likes and sparse matrices."], "sklearn.utils.safe_sqr": ["Element wise squaring of array-likes and sparse matrices."], "shuffle": ["Shuffle arrays or sparse matrices in a consistent way."], "utils.shuffle": ["Shuffle arrays or sparse matrices in a consistent way."], "sklearn.utils.shuffle": ["Shuffle arrays or sparse matrices in a consistent way."], "incr_mean_variance_axis": ["Compute incremental mean and variance along an axis on a CSR or CSC matrix."], "sparsefuncs.incr_mean_variance_axis": ["Compute incremental mean and variance along an axis on a CSR or CSC matrix."], "utils.sparsefuncs.incr_mean_variance_axis": ["Compute incremental mean and variance along an axis on a CSR or CSC matrix."], "sklearn.utils.sparsefuncs.incr_mean_variance_axis": ["Compute incremental mean and variance along an axis on a CSR or CSC matrix."], "inplace_column_scale": ["Inplace column scaling of a CSC/CSR matrix."], "sparsefuncs.inplace_column_scale": ["Inplace column scaling of a CSC/CSR matrix."], "utils.sparsefuncs.inplace_column_scale": ["Inplace column scaling of a CSC/CSR matrix."], "sklearn.utils.sparsefuncs.inplace_column_scale": ["Inplace column scaling of a CSC/CSR matrix."], "inplace_row_scale": ["Inplace row scaling of a CSR or CSC matrix."], "sparsefuncs.inplace_row_scale": ["Inplace row scaling of a CSR or CSC matrix."], "utils.sparsefuncs.inplace_row_scale": ["Inplace row scaling of a CSR or CSC matrix."], "sklearn.utils.sparsefuncs.inplace_row_scale": ["Inplace row scaling of a CSR or CSC matrix."], "inplace_swap_row": ["Swaps two rows of a CSC/CSR matrix in-place."], "sparsefuncs.inplace_swap_row": ["Swaps two rows of a CSC/CSR matrix in-place."], "utils.sparsefuncs.inplace_swap_row": ["Swaps two rows of a CSC/CSR matrix in-place."], "sklearn.utils.sparsefuncs.inplace_swap_row": ["Swaps two rows of a CSC/CSR matrix in-place."], "inplace_swap_column": ["Swaps two columns of a CSC/CSR matrix in-place."], "sparsefuncs.inplace_swap_column": ["Swaps two columns of a CSC/CSR matrix in-place."], "utils.sparsefuncs.inplace_swap_column": ["Swaps two columns of a CSC/CSR matrix in-place."], "sklearn.utils.sparsefuncs.inplace_swap_column": ["Swaps two columns of a CSC/CSR matrix in-place."], "mean_variance_axis": ["Compute mean and variance along an axis on a CSR or CSC matrix."], "sparsefuncs.mean_variance_axis": ["Compute mean and variance along an axis on a CSR or CSC matrix."], "utils.sparsefuncs.mean_variance_axis": ["Compute mean and variance along an axis on a CSR or CSC matrix."], "sklearn.utils.sparsefuncs.mean_variance_axis": ["Compute mean and variance along an axis on a CSR or CSC matrix."], "inplace_csr_column_scale": ["Inplace column scaling of a CSR matrix."], "sparsefuncs.inplace_csr_column_scale": ["Inplace column scaling of a CSR matrix."], "utils.sparsefuncs.inplace_csr_column_scale": ["Inplace column scaling of a CSR matrix."], "sklearn.utils.sparsefuncs.inplace_csr_column_scale": ["Inplace column scaling of a CSR matrix."], "inplace_csr_row_normalize_l1": ["Inplace row normalize using the l1 norm"], "sparsefuncs_fast.inplace_csr_row_normalize_l1": ["Inplace row normalize using the l1 norm"], "utils.sparsefuncs_fast.inplace_csr_row_normalize_l1": ["Inplace row normalize using the l1 norm"], "sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l1": ["Inplace row normalize using the l1 norm"], "inplace_csr_row_normalize_l2": ["Inplace row normalize using the l2 norm"], "sparsefuncs_fast.inplace_csr_row_normalize_l2": ["Inplace row normalize using the l2 norm"], "utils.sparsefuncs_fast.inplace_csr_row_normalize_l2": ["Inplace row normalize using the l2 norm"], "sklearn.utils.sparsefuncs_fast.inplace_csr_row_normalize_l2": ["Inplace row normalize using the l2 norm"], "sample_without_replacement": ["Sample integers without replacement."], "random.sample_without_replacement": ["Sample integers without replacement."], "utils.random.sample_without_replacement": ["Sample integers without replacement."], "sklearn.utils.random.sample_without_replacement": ["Sample integers without replacement."], "check_is_fitted": ["Perform is_fitted validation for estimator."], "validation.check_is_fitted": ["Perform is_fitted validation for estimator."], "utils.validation.check_is_fitted": ["Perform is_fitted validation for estimator."], "sklearn.utils.validation.check_is_fitted": ["Perform is_fitted validation for estimator."], "check_memory": ["Check that memory is joblib.Memory-like."], "validation.check_memory": ["Check that memory is joblib.Memory-like."], "utils.validation.check_memory": ["Check that memory is joblib.Memory-like."], "sklearn.utils.validation.check_memory": ["Check that memory is joblib.Memory-like."], "check_symmetric": ["Make sure that array is 2D, square and symmetric."], "validation.check_symmetric": ["Make sure that array is 2D, square and symmetric."], "utils.validation.check_symmetric": ["Make sure that array is 2D, square and symmetric."], "sklearn.utils.validation.check_symmetric": ["Make sure that array is 2D, square and symmetric."], "column_or_1d": ["Ravel column or 1d numpy array, else raises an error."], "validation.column_or_1d": ["Ravel column or 1d numpy array, else raises an error."], "utils.validation.column_or_1d": ["Ravel column or 1d numpy array, else raises an error."], "sklearn.utils.validation.column_or_1d": ["Ravel column or 1d numpy array, else raises an error."], "has_fit_parameter": ["Check whether the estimator's fit method supports the given parameter."], "validation.has_fit_parameter": ["Check whether the estimator's fit method supports the given parameter."], "utils.validation.has_fit_parameter": ["Check whether the estimator's fit method supports the given parameter."], "sklearn.utils.validation.has_fit_parameter": ["Check whether the estimator's fit method supports the given parameter."], "all_estimators": ["Get a list of all estimators from sklearn."], "utils.all_estimators": ["Get a list of all estimators from sklearn."], "sklearn.utils.all_estimators": ["Get a list of all estimators from sklearn."], "parallel_backend": ["Change the default backend used by Parallel inside a with block."], "utils.parallel_backend": ["Change the default backend used by Parallel inside a with block."], "sklearn.utils.parallel_backend": ["Change the default backend used by Parallel inside a with block."], "register_parallel_backend": ["Register a new Parallel backend factory."], "utils.register_parallel_backend": ["Register a new Parallel backend factory."], "sklearn.utils.register_parallel_backend": ["Register a new Parallel backend factory."], "if_delegate_has_method": ["Create a decorator for methods that are delegated to a sub-estimator"], "metaestimators.if_delegate_has_method": ["Create a decorator for methods that are delegated to a sub-estimator"], "utils.metaestimators.if_delegate_has_method": ["Create a decorator for methods that are delegated to a sub-estimator"], "sklearn.utils.metaestimators.if_delegate_has_method": ["Create a decorator for methods that are delegated to a sub-estimator"]}